{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/micromamba/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label', 'filename'],\n",
      "        num_rows: 16200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label', 'filename'],\n",
      "        num_rows: 5400\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label', 'filename'],\n",
      "        num_rows: 5400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "dataName = \"blanchon/EuroSAT_RGB\"\n",
    "dataPath = Path(dataName)\n",
    "if dataPath.exists() is False:\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    ds: DatasetDict = load_dataset(dataName)  # type: ignore\n",
    "    ds.save_to_disk(dataPath)  # type: ignore\n",
    "\n",
    "else:\n",
    "    from datasets import load_from_disk\n",
    "\n",
    "    ds: DatasetDict = load_from_disk(dataPath)  # type: ignore\n",
    "\n",
    "num_classes = len(ds[\"train\"].unique(\"label\"))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCmA2DxVPUCfJAx/FWd58o/5aN+dPWVpOHYt9aOWxu5JqxC1IKsFBjpTNvOABn6UzHkY2nscAfSpoUT70i5UdccUyXYW3KMKQMCgq1iMGjtShRnFK+FUDFAkyLjHTmpIRwajNTwgbfxqmUtx3f2prDB4qXAFJgZqSiPbgFjyx4okwCFIPQVI33aay5cZ6AUImS0IwBk4okHAqZVRs561FcAKQB6UCsaer2sUNvA6RKjMzdO4GKy1cIMAD8q1dbbKWw9m4/GscmlD4dTSppLQlEuTyBUgG4cGqwqxGfl/GqaITJPK96ZcEKw4qYNkVBcDLYzSRT2I/NVT939abJKkhB5GKjYZPWmYqrEG3rvE0Kbs4U/zrHOa0tVnW5uVdeAFxis5jzUw+FF1NZMBU6cL+NQgZ71KDhRVMhE6c/U1BOf3hqWFsSLkVHMnzn1qepXQrN1pKlKHNN2VRJ//9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][16199][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDy4dDUO4k8dPWpBwtNAANbnKGM96AeeuaVlIAzxmkGAKYBjuetB7lj2oJHHP4UrKQB6HvQAwU7j1H0puQKWgB5Hy0wdae33aaKQAe5oJwByORQcnvxSHg4pgHekOcjmjrSUALz7UtJSigBznJxTaXFJigBPw4oNKSd3tRkUDEpQKSl7UCExThxk02nqM0AIelJ2pzelMoGL3pPYUE4FA/WgAo60tOVM0gGgc1IOKUADimsewoEf//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][900][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size = (64, 64)\n",
      "Mode = RGB\n",
      "Format = PNG\n"
     ]
    }
   ],
   "source": [
    "img = ds[\"train\"][0][\"image\"]\n",
    "\n",
    "print(f\"Size = {img.size}\")\n",
    "print(f\"Mode = {img.mode}\")\n",
    "print(f\"Format = {img.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Prepare data for training and evaluating.\n",
    "\n",
    "Also augment the train data by introduce random effects like cropting, rotating, flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import functional as ImgF\n",
    "\n",
    "\n",
    "# ds[\"train\"][0][\"image\"] is a PIL.JpegImagePlugin.JpegImageFile\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of images and its labels. Return image and label. If transform is provided, apply it to the image.\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    IMG_SIZE = 64, 64\n",
    "\n",
    "    def _transformBuild(self):\n",
    "        transformations = []\n",
    "        transformations.append(v2.Resize(size=ImageDataset.IMG_SIZE))\n",
    "        if self.randRot:\n",
    "            transformations.append(v2.RandomRotation(15))  # type: ignore\n",
    "        if self.randCrop:\n",
    "            transformations.append(\n",
    "                v2.RandomResizedCrop(size=ImageDataset.IMG_SIZE, scale=(0.8, 1.0))\n",
    "            )\n",
    "        if self.randFlipH:\n",
    "            transformations.append(v2.RandomHorizontalFlip())\n",
    "        if self.randFlipV:\n",
    "            transformations.append(v2.RandomVerticalFlip())\n",
    "\n",
    "        transformations.append(v2.ToImage())\n",
    "        transformations.append(v2.ToDtype(torch.float32, True))\n",
    "\n",
    "        return v2.Compose(transformations)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        randCrop=False,\n",
    "        randRot=False,\n",
    "        randFlipH=False,\n",
    "        randFlipV=False,\n",
    "    ):\n",
    "        self.randCrop = randCrop\n",
    "        self.randRot = randRot\n",
    "        self.randFlipH = randFlipH\n",
    "        self.randFlipV = randFlipV\n",
    "\n",
    "        self.length = len(data)\n",
    "        self.imgSize = self.IMG_SIZE\n",
    "\n",
    "        self.images = [d[\"image\"] for d in data]\n",
    "        self.labels = [d[\"label\"] for d in data]\n",
    "\n",
    "        # build the transformer\n",
    "        self.imgTransformer = self._transformBuild()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx\n",
    "\n",
    "        return self.imgTransformer(self.images[idx]), self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# test if augmentations are overdoing it\n",
    "trainSet = ImageDataset(ds[\"train\"], True, True, True, True)\n",
    "valSet = ImageDataset(ds[\"validation\"])\n",
    "testSet = ImageDataset(ds[\"test\"])\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "valLoader = DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "testLoader = DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = trainSet[0][0].size()\n",
    "sampleSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate if the image is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_np = trainSet[0][0].permute(1, 2, 0).cpu().numpy()\n",
    "plt.imshow(img_np)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtuklEQVR4nO2dXY7kSJadjaR7ZFaqpwEBg3nQArS82Ye2MXrVruZFwAhqdPVkZYY7f+YhCre7mueL4s2shoSe73tkMI1Go9FvOu7xc6bjOI4hIiIyxpj/X09ARET+/8GiICIihUVBREQKi4KIiBQWBRERKSwKIiJSWBRERKSwKIiISHG7euL/+Od/bg2cfhN3HFM8d5rz8WXk49uxn8ce+Td4E4wBp48dTp/C8S/7Gs/91z/8GI//+HjE4/OSLponAks4drofuv9xXsMJf8cIc4GL0hzT/0Hommm9aYy3cc73M0/53LjcY4wJbp/+55T3Cu3DPMoBN5qWZQrPbAye34fbPR5f5jzH5zNdNM9vhudGW2gP60KfB7SG8DGBz20P/+CAkydYE9r78OqPKd0njPFhLHnsLZ+/huc/07sJa/gv/+t/xuO/HFNERORnLAoiIlJYFEREpLAoiIhIYVEQEZHCoiAiIoVFQURECouCiIgUFgURESksCiIiUlgURESkuOx99Nyy7woSfGfIc2ZMeWz0i0l+HzQ99ArK3iAbDJNmsq55jBX9fOB+kuUMlGv25wEvmnx6XJfjuD6/d8emP6Tjzf+WkP/PO2ZJ52mQURQs+k6Lni6J5lnkiYSreAKXCp8PvVfZE2kbZ0OfG3oZZTY4fwmTpHdwhmdJjxhdi9Ka0zYhY6Xm3k9zTz5wY7zjY9Z494/g+fXz2XD81/GbgoiIFBYFEREpLAoiIlJYFEREpLjcaKagCGIOzTxqwC53CiCBuYSxuU+UGzEUbkI9xRgIQh3YZmBHmiL2aqmxhPff6BRSCBKtYbMDnUaZ2/oFauRenwc3CZtN7LBenBsDTVX8f1kKa6Fp5IvephziQnOJzxluiPYVCR7yOPncFMjz9gcIvMFrXg/2mfHBXQ+pejt6/T4XmDbk94z0f3gUE3x7n9lvCiIi8mcsCiIiUlgURESksCiIiEhhURARkeKy+mgm1QewB4UQ/aQfNBJjAzuCPSlwYH7blusezQU1CEFRRKoHsosYE5hohGF2UuXQ0DBzFMN0jqK1BqhB4KJp6k13AX5uHXUYzRvOJjFZGh4fPVodgLIrHGYdDKwJqXVA9pL20EFyPPKzoNM7aio4vqF9TGff9t57Ulmhqi8cJoVZWpMx3lFAxo89eoGu26ecxvzmfykiIn93WBRERKSwKIiISGFREBGRwqIgIiLFde8jCiah85Oihrx1YOyFPF3mcy3bQQ1xHFnx88QwkFwnkwIlKazGGJzU0wgVIdVHVNmMd0J5GkobVFTAcyCBA6lBsisMeehkWNmV5gGnYmgOKNVQORQUdk3RB3nxJJUVqvcoHAgFMhAwFZUzXT8oOnwe5wDdIfknUfgMeXClkK5O6NTbRekfXJ9L9kNilV5PM9jby1fwm4KIiBQWBRERKSwKIiJSWBRERKSwKIiISHFZffSy9OpHUhBMoDbYQbKBKoSg2FjIQAkkCxSytWDI1nkuS9MPilZwCRdl9Q0ogdAChZKZklwHxkAFRk85FEfA++k54yQBSrxHOHeMMRaUmjQUQt0Er4Y9EyqV4PgOsXaU+JU8xWgNe55aY4ygGOR0QdhXGOpGczwfX2Ezg0iRlXewAmmKFIBHnzXk+Rb3RGNvXsVvCiIiUlgURESksCiIiEhhURARkeJvFrKTfh7/A4yxw0+yV2i4PMLxGTrHn0KDawzOCCHripTV8+EJwT7UmaVrriGAhCwaoNtGzTmcSmjkcmuXwk3IQuN6k4saYtjIawT4cJRQrwGNdxMsN1AcQfPGRJXrvh3YmMVO5vX7R3cb+MNEnxNp7uSgQW1sstYA0v3QkrwTr0Wj57PD6QuKWuDzA66YBqf9sxuyIyIivwUWBRERKSwKIiJSWBRERKSwKIiISHFZffRvf/raGjipSj7e1nguKZs2UtQEZcYNxqCQEFIfkRpmC8d/euSxX0BN9aCQkDA2Bt6AGuIGIokdFA5rTLzJ90OKGlQfkeIpDNN1hSCrg+QkkEJW3sZA2Us+v2/qcB4ag2CuK2om2suobMp/eNBcwr6la2JADC1JfOFg/6D1CVi2wCWTWoeUcbRWaBMDl0zKtgUsgijQizx44mOjz8jGvvpr/KYgIiKFRUFERAqLgoiIFBYFEREpLAoiIlJcVh/97x8/twaOCiHowk9bdvtYQcWTeAH5DXqdgHyCYlb28JeP97x8n5aXePwGSR4x3ARUBTuFalCGCz7h4B8F22GFRUGPp/t1hQdZtOzwfA6QHyX10YIBJOCUFLyMxmAFWxK8zXNOVCF/Itj6YwpJOKSQIfXRxzk/z9fpFS563Q8L7YnQPyqFboFypmt9hAqcMzN9ppAasWe2Ff2M6NmvsJc52CiZU5Hq8tvxm4KIiBQWBRERKSwKIiJSWBRERKSwKIiISHFZffQM6WBdnjtILUCVw5KA86F9y6qPpBp6Dw53Ov9hgowk8j56iRqZ7KtE/kHLlMeYsq0U3v+RUpzIPwrUE89nvuYB9z8FhRiprNL8xnhHIZSUUBQbBvd5RyuavOZJaTKT71MeYvzu5R6Pf/pwVrC9TB/iuQ9QEy0gPXvAe7hu501Eb/3tBvsQ37egbCKFXTcdjVLgwvNZKIkRXjj6XzOJmNK2pTFuC2wKmMszbC70DvsO/KYgIiKFRUFERAqLgoiIFBYFEREpLAoiIlJcVh91SYlFqF/CFvp1VcHeVjCB/w2MktLHVoxvg7QmslFJigj0Vsl/oESpBdY2zXDayfsnQ0lYqPcKj+iA0XeS8cCaJwEKpZodoKR7wP3Q/vz4EuZOoW6wVe7wPD99OCuN/uEF1ERgTvXja5akka9U2kN3UMgsoOAimVX2EAI/KPDU2uh5wuKm/UnJfeSJRPeJHk/hPmcwYKP35DHlz7Ij/AvWVn67WtRvCiIiUlgURESksCiIiEhhURARkeJ6o5n9HyLpF+z0s3YMiMHEm/CTeWp8Ib2mYufn5PQzffhRewwgobAWcm4gFqr76flQmAzZX1BYDTSDk0CAAkUOSo7BtQ0hLs1QGgpUoXHWcM2PYP9Ax78Ea4kxxlg/n48/n9Agf36BsXsN2yXsuRvYQtC7ucGzT01fauIe9JCheQpTHOn/vGhbQR9CJA4hoUr4jJthEGqor3A89Z/p8yB9plzFbwoiIlJYFEREpLAoiIhIYVEQEZHCoiAiIsVl9dHU7GZP4XfgpD5i/4d8OKkT0HEiH+Y/NMZJVh5jjLGTzgjULSF7Bn9GjzTFV2l8Ens9t/yz+x1sMVixEcYgRRo8fNyHSdkEE7ktXRXc9YcBGUjjw0v+w9cvOano8frT6diPT1Awfc1j3OGa0y0/6ahUg424YkAOqI/SPBpWEW9jND8/Ls7jveO3phoxvSngcvGOJQrYYoTwHVyrplr0L/GbgoiIFBYFEREpLAoiIlJYFEREpLAoiIhIcVl9NHfMf8YYW/KiobEboR98nFQs0J2HaybV1M9/OB0ixdOdVFaocTiPjWE/WMZJsZFZkiQCcopIZMRcnwv5LZHShBRs9/B8ZlBgoG9NM/Tlw+08DqmmXiHY57/c8yu4BcXT58drPJeUQAtIociLJ6leKLxqBUUWreF8hLVKsrsxUE3EfksUanW+Jn2MpRCtMbKH2xj8TuxhLuS1ldREb9dEQ6MTqJjryhH/Ar8piIhIYVEQEZHCoiAiIoVFQURECouCiIgUl9VH5GnC/+B8CJVAOAipJMIYDc+Vt+NNtVKSLaB4gsYA+UQ4vGEyXK7jt6aiJnkOkdqL7oeSs0iysYX0LXo+IMwYN7om+BnFsXFT5D9Q+tin+8vp2Oc1T/ynIyes/dP9Qzz+p9ez6uf1CUlqoGy6vcDxJd/PlzjHxvswWK1zzOc/kHpvp/cEBic1WZohbh/4A/kQ3WBd9rC2pIKjhEZ6D9MdocURKiB/Hb8piIhIYVEQEZHCoiAiIoVFQUREisuN5q39s+n0m+zmCJ1QHmq0YogLXRP+EIa/QXoGNfKogZabdr3FIrsISjJJzVZYwrHg2kLIEE49jAPTXpbcmJ2h6bsnGwWYBa3VDM3GB9znH1/PthP/FwKJqLt9+wG7jef55TPHCs94hrcb+tJR3LDAKpLdCtpfhD2erDzG4OAlgsQU6fW8gVCDbXxITZIPp9E5QwzWluYSD1+3xLiK3xRERKSwKIiISGFREBGRwqIgIiKFRUFERIrL6iP8OTUQXSEwbIIumg/Tz8bjPKg537TtSPYKZC0xo2oqh54ktQX+7J4sNNAShKwBkg8JqYzi4XHAXOjppLtP9gdv18xr1RCHofIKFUww+gOsKz4/z8dW2MxwmxiQk1UsYHGSl2rcYb+9wv0k6wa0BIG1ZduF8yF6j3Evo/ULKQzP64XKJvw4oPNBTRaeEYXpUHgTLSKpAxPdz7e/xG8KIiJSWBRERKSwKIiISGFREBGRwqIgIiLFZfXR0vQjeUb1EYW1wCANxROHe9DQ4DsCc0w+JSD6QC8WmkxSCNGSkN8QiyoaJi1E07uFlA97NFyii14PGhkjKzPIg2mFNZxB3bLDg97DNX9/3OO5tPc/3fPgXx5nD6UJ1vV+g/cKHvI+gmxqjLGEF3EBK6d1z38ghVTan+SrhMqmpj9RWnIK2aG1pU0Ey5L3Pl2zZ1dGF8xjfIf5kd8URESksCiIiEhhURARkcKiICIihUVBRESKy+qj/sBBrQMKjPst16YNGuhfn+dULlITsbylZ7iUPHrIi4T7/uCXEu5/AVXBBsfJ04XmGAPCQA6RfJ/GYNVYzkzLK0tqr72hAhsjKzYwdY8MfWBtUfQS9sQPoCa6L/k42BDFBDPaVx/A4wj3Iaipkj/TRBFr5FtE6rhwPil+0D5pI+UZeJCF8el/wbQl2GaN7v98/GADqcbRvLYTqKNQTXUBvymIiEhhURARkcKiICIihUVBREQKi4KIiBSX1UfooUPnR+VHL2lpA3+VNDQnPvW68JS+lVQy6POCozfS1Ch9ie4HpFrkL5NWFv2TKAUN4sRoU+3zWT3xSj5EyVhocCLdFjRPpPogpRo9t4+gbjmW89xJrHPA83lsWat1BFkSqfFI3LJNoAMDxdPrGtQ6U34HyVcppZ2NMcYS9gq99/QcyMeM3qu0VehzYoLFJR+vGe4zKZ5IvQavFXsfBaXRscDnBBl/XcBvCiIiUlgURESksCiIiEhhURARkeJ6o7ndsD2zwRjbMzezNmhCphYKBttgB5oaZdd/er83f6ZOLbTUEN2hib2TjQCMvTWacNTI3CBS5IBmFtlixLmgtQSsFc7xDDVgKRwJ3CLQzmOZz4E6XSEAhbikud+wS0rNXRAIPPMeeoamN/UrKZDoBdZqTl1iasCi/QUF+JA4JI+foHeZNhw+imTvA4KMaDUzxljxs/Z8/2jl8u0uF35TEBGRP2NREBGRwqIgIiKFRUFERAqLgoiIFH+zkJ0YekJyEMrxAGVKspzYGqqhMfin52SBMCeFBwqewLqB7ifIJA4MAQJIrUTBPuGaIJIA7dE7KitUPiQbhXwm3T0ris73D+Kbd/4n1LMKScODMwurREg5dAtrBfuH1FEUSESH07PY4ZorrhUphK5dbwy2BKG9jO94Op9efNj8dD+0h6JlDfhzHDvscvxwCnsChqCQqiv4TUFERAqLgoiIFBYFEREpLAoiIlJYFEREpLisPiKVBJNkGDTG9WCbt8mEQ6h4oWCbztlZEDChuQqojMjnJ0gzDlKlwBVJ8UMKnKiygtsJQpi3sbtbIoxDyhkQcL3jiRSUGRT4gosIc4FnkaZCS7LhfiPVSziXVEa4+fNFP8CiP7eg4CK5FyYywVQCOxgrYaAX+X6BcujYz6tIY6+gsUvKwLdxMnN4KWZaK1IpwvPc0ul9CeCv4jcFEREpLAoiIlJYFEREpLAoiIhIYVEQEZHiuvronTyxRFTPNFOC2ELn/Bf2P8mQZwgpipIP00RqCLqfRhwS+kShbAoUXFD396B8wHQ9uCQlR5GpTUrOmjBlqzWVsQW3JPKgmkDDhV48cM0sg6N77yXm0XNLrLSXaU+AbGwJ7+wBL8q85zHoA2UJi0sisA28gih1EC3VkqcY7fFGAt4YAzdi+kw4SHUIQ9NrFT8/KBrvO/CbgoiIFBYFEREpLAoiIlJYFEREpLAoiIhIcV19RLFcwJFa6KjMgDHI5yZIAkgdhQFEcD9sZxT8iVCC8FsoAprpU2CMc8Bc5iloP0CZkZQ9b2PHw+MAlUj6B+R/g48B9sSS1GEwBm3lmJo1xthhpJRet0KaFrp+NZQpRzS/GWMDldWNlDaoGjuPs8M1b2Agdae9n+4TXjb6UALBE7LEJDk4GRRPtCdujbS7jory3X8Q1pDUa/hyXsBvCiIiUlgURESksCiIiEhhURARkeJyo7kb2pByPDCvA8amPkyuZdTgg0YeNcTQoiE1Mq+fO8YYqbc7xhh7WBi056Bpw/nHnruKqa+GFh+QEEMBMdScizPhhxzZoZGbGs1k58DBKdCUh7msYe4brMkd5nLA/ayhWb9Tk53uE/r9r3DN1FPeoWFJazJDB3ZKawWCBAw1omvCHJNtxx2e/dq0IcEXNFyTQp1WElk0A8N+a/ymICIihUVBREQKi4KIiBQWBRERKSwKIiJSXFYfUYcfSaeD/IiGTsE2Y7yjCEiXhOMTdP5p5JegqpjJhoNCPyjfIyzWkn6jPwZOkO6Tzk/KnIag4m0MUBlRQNCczRtg8CzZwOyhsOggykEVD4hyxh2eRQpswcAoeJyckZICfPKZpLIiy42VwodikFTznc2Hxz1I72YMQSK7kXyfLzeyojh/vJHo8AZj0PZ8brgRwzzy2K/PPMRGmyhdk95B/kT4VfymICIihUVBREQKi4KIiBQWBRERKSwKIiJSXFYfsUoik0QLkGMxSLNAp0dRBQa+kEoABkcJTjhEfjZr9hsiwULyaGHJDwUPgXcL3U84HW+dFDVNddgSlBJgq8TeT/Dgklprgg2HflBsOgOcr/lCewJGSP5JY+QwJQweIu8wCgeCNyuF9ax80Qz4GaXPD/KJmmFNFpj3DO9KUv3w653VbuRbtOBeOd//QUpH2vugdoueYt33/gJ+UxARkcKiICIihUVBREQKi4KIiBQWBRERKS6rj1DFQ+fHPn9PrUI+JbELDyfTGHQ3pAjYgmJlAcXCAV4nCxxPihpcbziOSi1QwyR1Cwc+kccT3D8Mcwv3udI1SVVB0XPhwZG6hdQdKb1tjPeexfnQDGM/aVWyECpCiXH0XpGA7QXUMK/h8AdS9sCLtQS/oTHG2FPyGsjxnrDeEyxW2stMT0a50T6kz5swl43uhz7fYF3IhypBvmSX/u03/0sREfm7w6IgIiKFRUFERAqLgoiIFJcbzVPTAiD9tJtbH70mcfwDBZBQEwrDUBqN2WYDifpEKWRnAjsLegw7WDpQszE1rSjchOwsyNKAbBdiUxmCVsi6gEQJyS6Czp03WhRoZMLapr4vBdtgM5RsLlJoEGwsbEDDbR7Q3E7jk5UL7k9qnoZ0JNonCxzfMVAGmvtruOYM+w3WakELHggCCntlBznFTolRcDzePooj8tBX8JuCiIgUFgURESksCiIiUlgURESksCiIiEhx3eaiWT+yegJORhsFUhukhJheuAmqlRrKoQe0+G9gdZCmPcYYR/z5Pqg+8hBjosHhcFQtwHPg2+n9lD6ptVDxxKlJ8XBSg0Q7lHcgMQitS1paELfg2KRKmoMcht4HvE04fwe7iLT3yXKCPg2eG0ibwjC0Jng7MJfHltU9ad/eJ7Bm2emOyM6Dnlv43EP1Hvr45NPTIn6HnQXhNwURESksCiIiUlgURESksCiIiEhhURARkeKy+ujTvVc/kr3MA8IjdpDIkAIlKTZuMMYOHX7yLqG7jOeTWgXu8yAfmUZICNgNjQP+sFPgT1AtkLpja3j/jPFOgFF4FhiwRAqZjk8WqIY2UMh01UpJsUL3Q34+E5pTpXNBlUI+UbBX0rMfIysGD5AIwRZvZdik670/BMyFwpTCuswUYDNB3NOc1UoD1Eppy030GURqP3ix0nKRx9H3aJL8piAiIoVFQURECouCiIgUFgURESksCiIiUlxWH/33f/x9b+BgPPKn12c891//8FM8/vkJyV5JxdL0Mup2/m/LWYVwX3JNRa8g8r9pqFgGeK6MI6sk2CvpzA18YWjetIak+ErSDFag5DFIabIHRREJeyAcDfcK+UpF7yNYq9sCiXGghEreR3d4W3+43ePxJz0feKCPLdwR+ZLlqaAcZguLTl5OmCQHTCPv2/QsQiDkGIMT1lDtBw96Cc9tO7KyKaVTvv0hH07vBKmPju/wRPKbgoiIFBYFEREpLAoiIlJYFEREpLAoiIhIcVl99N9+/7E3cPAM+d0/ZZXE1/X/xOOvf/wcj2+haw8iCVSxTFOWFZD6KB0nBcbXpOIYrGJJnjakzKCEOUrwOkBqkxQeN1JU0P8dyHPnAG+hMPwLSbXg/h8gB0mWNjOobGhPkOqF/ImSZxWpWFgFBt46yYcIFCULrOGd1nbN9/MMe+UFpjfBnphhjmt4J0jVttxotWAv4zsRxkYvMLgkPLkb+JilTzhKKKRQxBXe2SncJykAmwKuX/7bb/+nIiLy94ZFQURECouCiIgUFgURESkuN5o3aB4S6af0L7eXeG5wkHiDGmuhuQJ9HwaahxQe8u/P80/VKQjmQMsJaDjt53GoqXiDDhLZRZClQbr9G16z17BdyRogHKcGH11zBiuO6ZYSSBqBPO8cn8HOJFmRhEf58+BwP/mVyHOn5jtYZXyEecO2HbdwfNvoGUPTN2tJxkvat2TzAMcp7IluMwob4P/BJKY4qB1M4UPhoiSm+D34lnyFjfhcg/gAPpdRZHABvymIiEhhURARkcKiICIihUVBREQKi4KIiBSX1UeP0Pl+j3/44Tz0T08KGskd/gM6/LGSQceefnY/wOYCf74flB+ksmn/xjzZXIBaZYM1oakQKQzkIDURKJvQRoJUPLfzNZPFx9vx/BxIfTXN5xVIz+y9+WFSExBVLxhK05xLuH9S/FDwEGRU4V5Jc1lBjrfB58FGFi/huZF6jcBAJjie1G5flxz01RRADrK/OKIVBSi16DML/queLEeOPcu9JvL9uYDfFEREpLAoiIhIYVEQEZHCoiAiIoVFQUREisvqI/LQwYGD9wYpR6jbfpCqIHXtyYuEonCoOw8hLsnnhtRRY4dQFrJ6SYEqGMwB88PyDiqJoGTBABL4vwOpYRa60eRPRPfTNCiKUyfVFI2BgT80lRSO1NOBUVjLFuZOKrAJ/KBwf9J7FecBiidS71FwTlB2pZAimscYrD4ixVN6h6azhdkYg8ObSB1Hn01JvTjRniDlHbxv2zhPfgaV3gyeVVfwm4KIiBQWBRERKSwKIiJSWBRERKSwKIiISHFZffS7jxQRlfkUUoV+9yFf7kEeOqBDSOoRVCrRBMnnhhLMkvoIBTI91UvyboFpjKPpq0QqpiOkW9E19+ArNAarQWigaTurZEjdMTfVYelB09goMqLnCX/IYWKQGtY0p0rPjdaEtgS9E6QyG2tQ6zRFLHSfSb3XVR2SArKjVuLbgbGbFkJJfbaR7xUNvuQ0tSlIDFf0H9P7SEREfgMsCiIiUlgURESksCiIiEhxudH8bP58/x66edQU+ffX3FihTlTokTbjOvjn+DuMlJrEZKFB9gIbXDRdk3qBU7r5wbYD3DwO18ynYoMPnU8oZKfR+KOxqXmcO81wKt0pXBOb3sFeYjryXkZ9ABxfwiV3srPAbmjPoiGdj0IAmnjjMIXsoHsMiUnQySa8E83QHNzjpIOIw9C7Cc8HrDim8I5Ts3pvBkb9JX5TEBGRwqIgIiKFRUFERAqLgoiIFBYFEREpLquPtrX7s+lz9/sPX17jmc8n/KwbRp6TMoOUFjAGNednUhQ1gn1IVYE/pQ/ihJ0sDVD2kA+jVUiy1ujl2uA/QHVLUh+R9QfKw0jBdWaBMTAghe4HpENTuCot1Y3+AreZ1GSkPOvYwYwxxoNCacJGZLcEet8aY1//+BljsOJphWvG/fntopxfDt2wxWgKnqLybIwx5nA/G+1ZUCNewW8KIiJSWBRERKSwKIiISGFREBGRwqIgIiLF5fY/dduJNbTh/wQqoxuknryC4il5hkxQ3lhs0FO9pPsnlVFUKr1D8tZhy5WufKJj3kI+NxlSSE3gWUXhNnEMWMPOLkQBRpKvjTHAgYtVZkGVhJ5NjXCgMcaYw4beYIwZFhZDaWAq6XGirxC9b6CQOkJAzL5df9fejsM18fw0lzzxpI56F3rH05o3VXD0jm/x8HWvtqv4TUFERAqLgoiIFBYFEREpLAoiIlJYFEREpLisProvOfWJeATl0PrMHX5ulDfMeMjPpmc5M3ZM5UrSDBiEvFhoMg2lAKpBUIEBaotwmNLBOMWpG0uVjuf5kXqCFUIpZQuS+2ivgHJmJ2+hOHY8dSyY7EXyo/P90HOY4D7XHTzF4EGvYQlJCYRBcqioua6wQ9APq7M/QcFFajdMNmtcEljoswaeT1Kf0XuPRmYX8JuCiIgUFgURESksCiIiUlgURESksCiIiEhxWX2EKgnguZ6VD+QJ9CAPFGqsB+8anB6mbMH5MMesNuj52ZCfz97yXen5LaEGIa4L+Q31pBaUYLaF/4OgOgzSwTCpLcydtyzF7l332hojvxMzKUeSOmpkjyMam+cXD48D1EedZLyOMu7t9OveQl19DO0rIgavUVIZDpIPsx9YOkqqQ7oo7f3r5lRzkhdexG8KIiJSWBRERKSwKIiISGFREBGR4nKj+euGBgORH1IozQ2aatBUXPCn5+dj+PN6aM5Rw4ksDVJzDvtEFEBC3e10PxQCBGOjdQN21FPTt/dTf8yNgTVPt4TPmNaw0fjD9jg1q5v3k8JQdgqGgs2yUPJQEl9gVz4ff1ny603Cgf04v+Mb+jkAt3z+bT3PEfQluA9nEnaAA0+yLWnqZcZO3i9guJKtUuCzhvrPqDsJ/wDnp82FiIj8BlgURESksCiIiEhhURARkcKiICIixWX10dpUIbwEBcG+PfLJJM0AqUnHFYI6+agygmsmRUTXWgOvmZRAqGDqKVBIxYSihTh2cy44TApaIcVTT1WxkzIFzr5+dIy5oVTb4T2ZMaMqn7/M5w1AVhkLzPxY8iZ6kIVImMvCfjAwl3z8Ge6fVG2kJCT11Qz/t01nH2Qhka/4jkIoP9Ct8UpQbtkOarcUsvTtGiPGbwoiIlJYFEREpLAoiIhIYVEQEZHCoiAiIsVl9VFXaXIL6onPX1cYO4/RUhmhWAX+QLKCRm4O67EgaKQRVkP3vpEqCXUI11VjKPqg80mZQWveCCBBXyVQw2xJOZOHaCub6Lml47Rlp+b/v9LZK80Dht7WPJsNfMyeQZX0BIMiUq+R11Z0BAKlFim4SKlG4UPxqmQ/RvNu5BHRBcJH4c9ngmoKpIdzuB/8VP4OWZLfFEREpLAoiIhIYVEQEZHCoiAiIoVFQUREisvqozu10IH5dm5/rxDe1kk7I0iZgNYtDVUOgb4oNG9KMIvJa6BMQFsYUHI0VFkk4qCELJQ4NA6jwqyR3jZGXkNSGZGNF68hJbWFND4SyNAYcENbWBiad1KljDHGT3t+4eh9W+ODJoUQKLXw2QeFHSqBeiowVAyGNeTPiZ7fEq1hAtPrwJiNvLZIk5UH+dVpIX5TEBGRwqIgIiKFRUFERAqLgoiIFJcbzR8gsINIvZUb/DZ+545TPhyakNSUpiYcNq0wVOPyqe/0sH+DZBtqVlMqDw0T/9BrHLMXBdh8ZK+DeO6OwSnUKLy+tjPMm5ryB9xPagiSXQJaN0BD/dnweElN6bdrwnHq14a9xcuKG+vyYRq7qdNA0t3Tpxjak1x3psHDtDdpaGpiJyHEb2Fv89f4TUFERAqLgoiIFBYFEREpLAoiIlJYFEREpLisPqKAD+J1PZ//APkAiCQwyCOqJ6jD3xljjDHjj8lD/QTVBymbUDkTfkrPAiao4yCdmSk8JI5D90Nj56mQICIpcG4kmgLFz43mEuYOripjw/8L5X8xo+wl7Yl8JllokGouOVTcQAGIlgukVMMQmzA2vJvJtoJHefsXfw3ZOeykvKJQHnon0rnNzzFURuLnRDRzieeyBc91tRIq5ugD7gJ+UxARkcKiICIihUVBREQKi4KIiBQWBRERKS6rj75ct2IZY4zxYTv/g8/PNZ6LvjWoTLkeBtK1AKFgliQVwHPbHkLh1KbnDCmeUAsS/oCPmFRWID/aSFETjt9gC5JaZ4Gwp2daQ1Lf4F4Bz6bGIpKihjy4aCpLuhyquuCa8Hzo/lMQEKmMugE58R/A/OYdVFYUSoPrcm0aY7Cojxad1iVNEXOkaKnwcyKoFI+smGNPpF/HbwoiIlJYFEREpLAoiIhIYVEQEZHCoiAiIsVl9dEPzfKR1COPNXfKF0yfIm+U8zGaHoqPSCFDaoN0PqpbMq2MJBgb/ZPIL4VStoJMAgUYoMrh8LrrXkkHKJumPelvxti2fNEt7BXylllQrdLzforj8CLGw0Gk9zaXtPfh3Be4oVd4+Bt5CHX2OHo8wQJES6BmahgKasigqaHAoXQ98qzCyZyP32getEHh/Kga6yogL+A3BRERKSwKIiJSWBRERKSwKIiISGFREBGR4rL66L9+vLcG3pfQKQflCHmDUCpVp5KR58zOsUcwlyidySeTeoClUOdD4PHDqUzgFdRRYMAYlFY1U+wTWVmFuaRjY7AXzQH+N2kT0f5phmmNCUxq0kwope04spoKU8aCIo98lWi9H8+s9kPforAAB/kQwVs7wzs+heeGSiX8RKC9DOcnRRpqA0l5BjPp/KFne4UJc2nueyOl7Sp+UxARkcKiICIihUVBREQKi4KIiBSXG80f7r368XU9N24WaJStzYZy/Ik59uB6SRbY3w3Nnw0DOGAuHS8OzCrJDTGy50CiVUjPLGTCJvH1hig2lEkgwElA4XLQhMO+JF3z+l5hlweyysj/YAvhKTPYwdBeWTBkB4YJfWkMJEJblet7Bd9NWBNsM2/Xg3C4AYupQXD2dYuOg2xFYL/hW5hCdpphXFfwm4KIiBQWBRERKSwKIiJSWBRERKSwKIiISHFZffQj/GSeONZz93vFwAqAFDVJOdNzABgLhdXANdd4GJQWpBIBqUC+JqgeyEKim0sS7SKyFQPaXzTVV40MF7YjwICcoPogVQ6O3VOaRJsGGqNpq5IUT59estXMAyRZC0jpKGQnA3v8urPEGCOHBh1J7oRXhOChMcYB/7dFC5HABGuFOTioVkqKJ9o/MBn0YQk2MTQN+kC8gN8URESksCiIiEhhURARkcKiICIihUVBRESKy+qj/ejVj+TR82XLaoOUxzPGYP+fKAnoKWG49Z8VC8mnhZRKbEhCQR5BVQAjICCToJCh7C8D6jAQcXQUGD//gwBsQdwTeWWOEfYWSUfg+WzkwUWKmuS3BCI9Uh+RECjtrQVelPVJezaD4qPoTUX7p+dXltYqBlflabydT1Np7H30LIJF6ToIRT+npjKSQ5Aa82BTpF/FbwoiIlJYFEREpLAoiIhIYVEQEZHCoiAiIsVl9dHMkVeRLZlygDKDVDwQeBVFPDublGRI+QAXTUdJDXCAyogqcMNW6VukGZcPcyIZXJOg+LrkfUQeT6B6IaVJuqGFniU9CNqfy/UFQOEVXHOHf/Dhdv4HT1KlbPkP5FZG10zbFhUvNERjr9zove8mMdJeCePw9HopdQum9IWERlL14Uwovu+6/qhptfUL/KYgIiKFRUFERAqLgoiIFBYFEREpLAoiIlJcVh/9gJKNzI/783Ssm9bUSyDqpRuRWmlu+BlNlByF95mTzSZamDgIjU0KBxg7yERYsIDxTnAc0rrSsabRC/r2BHXcNOf1PihNDLyFyD8qW3D1PI7uoNR6Ceoj8rOhPUsJa6TuicPTGPiAIMEsrAsplciDihQ/G32ApGFASUZreOz5HV8bCinaP7gP8TOroYH8dusjvymIiMifsSiIiEhhURARkcKiICIixeVG873xU/8xxng+zw2aFTqw6afhY4x3fgceAju+p7Pyi7HhOHY40xDQWIL7P9LY1Dvre07Eo3toblNoDl1zxt/SN5r+tK+wf4aqhHC9XoMPO58UNNO45g5jL7fr9/8BGueP2xqPT2etxxiD7SWSXQSH0sBeRgFHGiMPTfsHPyZI2RF9VfIabhsFYFGz/rqFCu0ezoC6/nmIWWHf4XPhNwURESksCiIiUlgURESksCiIiEhhURARkeKy+uinPSsciDWc/oSOODbQobU+pxZ/FhWwVUZT8BTH6aoHGkPTvFE5Q8wQ+JNCduhJkEAGlENkx5BuCR0+4HniHIPlBto5gOwFXVWApIbBkB34AylqniE4Z3rJ9/6EQRaw0NgoBCoNA58Q854f0LpRtE8Yo2XnMAbJlWCLZ4UQqKZmmkzTWiQNg7YVaM/RUHAB35Gx4zcFERH5MxYFEREpLAoiIlJYFEREpLAoiIhIcVl99G9fwUgF2B5nFcIDlAkz1KYbqC2WoEBZKdiGjufDaMfS6eaz99H1UA2q1jQ/9kDJh5N6AoQZaE+UnsMYvFYpJAUEMrhWpBzag3RmJq+ppvKM5/L9irQHrPk9KOyedD/g23MDX6X9Sbvr/H5u4Nm0w1xQeRYuiXuZxoCQKhopiRTx2TeCocZg36+ojCRRH0rVrh9G2ydDdkRE5LfAoiAiIoVFQURECouCiIgUFgURESmuq4/++GgNnNKQ5iRBGGN8fMnHUyN/jDHW9aySmODkA8x1NlIbkNqiEXvEqoLriWTk+4QWT3CcPFqmYKQykaICnltSE40xxpPuPxrD5FNJgYJ+RuF4W0nWC4HLwV6oPoJLouTrvOYrqIzuS36N6TlMR/Yxm8M1px2S+9CzqvHsUWUEPlFwyX3K9x+TBGniqGyi/QZzSWl8PZERpwuG9+2IhlXvDH4BvymIiEhhURARkcKiICIihUVBRESKy43mLyk15x1CRkj+Cfh4J/QE8jpSs3HF+WEnE+bSOj2P0QwTOkLDDfM3YIYTNMqoeZyGmcm2Ateq3UELYzQ7Yh2PCmqywzUnECVgkziME5ubg8N0qFmfLQ3yC/GRwnSgMR1FEyPfz0wpSOSrAkkwUTjR7PhPdJ9zXpe0bY/QTB+DhR0UhMNrez7/RmtF+w2tedI4IEghlc4F/KYgIiKFRUFERAqLgoiIFBYFEREpLAoiIlL8zdRHSSixgXpiTVKlMcYCSobUhUdlD/wMvCHKwWuiEoisAVD1cX0mZPOwgFSLMziuh4GQ4mfnhJx4OGYskRUDDd0IMELrD1CrHPDcSH00hyt0LDHGyHYjY4yxBQnKDnYjKzz7FSwdyOLlCBIp3BJwHEnPBwYB0eFYyKICg3PCQfpMQfuUPDYp2Dr/y6b9xlLH9HxI7dV+QoXfFEREpLAoiIhIYVEQEZHCoiAiIoVFQUREiumgtruIiPynw28KIiJSWBRERKSwKIiISGFREBGRwqIgIiKFRUFERAqLgoiIFBYFEREpLAoiIlL8B39m1PBFYEwRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_np = ds[\"train\"][0][\"image\"]\n",
    "plt.imshow(img_np)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, device, dataLoader):\n",
    "    \"\"\"Infer the predictions.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to use for inference.\n",
    "        device (torch.device): The device to use.\n",
    "        dataLoader (DataLoader): The data to infer.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: The predictions and the actual labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    predProba = []\n",
    "    actual = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataLoader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            actual.append(labels)\n",
    "            predProba.append(outputs)\n",
    "\n",
    "    return torch.cat(predProba), torch.cat(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    device,\n",
    "    trainLoader,\n",
    "    valLoader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    n_epochs=100,\n",
    "    earlyStopping=10,\n",
    "):\n",
    "    \"\"\"Train the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        device (torch.device): The device to use.\n",
    "        trainLoader (DataLoader): The training data.\n",
    "        valLoader (DataLoader): The validation data.\n",
    "        criterion (_type_): The loss function.\n",
    "        optimizer (_type_): The optimizer.\n",
    "        n_epochs (int, optional): Number of epochs to train for. Defaults to 100.\n",
    "        earlyStopping (int, optional): Number of epochs to wait before stopping training if no improvement is made\n",
    "            on the validation loss. Defaults to 10.\n",
    "    \"\"\"\n",
    "\n",
    "    optimScheduler = ReduceLROnPlateau(optimizer, patience=3, factor=0.2)\n",
    "\n",
    "    # Training loop\n",
    "    earlyStopping = 10\n",
    "    bestValLoss = float(\"inf\")\n",
    "    bestModelState = None\n",
    "    patience = 0\n",
    "\n",
    "    trainLosses = []\n",
    "    valLosses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        trainLoss = 0\n",
    "        trainAcc = 0\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainLoader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            trainLoss += loss.item()\n",
    "            trainAcc += acc.item()\n",
    "\n",
    "            # Print every 100 batches\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch [{epoch+1}/{n_epochs}], Step [{batch_idx}/{len(trainLoader)}], Loss: {loss.item():.4f}, Accuracy: {acc.item():.4f}\"\n",
    "                )\n",
    "\n",
    "        trainLoss /= len(trainLoader)\n",
    "        trainAcc /= len(trainLoader)\n",
    "        trainLosses.append(trainLoss)\n",
    "\n",
    "        # Validation loss\n",
    "        pred, actual = infer(model, device, valLoader)\n",
    "        valLoss = criterion(pred, actual)\n",
    "        valAcc = (torch.argmax(pred, dim=1) == actual).float().mean()\n",
    "\n",
    "        valLosses.append(valLoss)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{n_epochs}], Train Loss: {trainLoss:.4f}, Val Loss: {valLoss:.4f}, Train Acc: {trainAcc:.4f}, Val Acc: {valAcc:.4f}\"\n",
    "        )\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Early stopping\n",
    "        if valLoss < bestValLoss:\n",
    "            bestValLoss = valLoss\n",
    "            bestModelState = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience > earlyStopping:\n",
    "                break\n",
    "\n",
    "        optimScheduler.step(valLoss)\n",
    "\n",
    "    # Save the model\n",
    "    # torch.save(bestModelState, \"model.pth\")\n",
    "    model.load_state_dict(bestModelState)  # type: ignore\n",
    "    \n",
    "    return trainLosses, valLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block with Conv2d, BatchNorm2d and activation function.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_chn, out_chn, activation, kernel_size=3, alpha=1, stride=1, group=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = (kernel_size - 1) // 2  # for same padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_chn,\n",
    "            out_chn,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "            groups=group,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_chn)\n",
    "        self.activate = activation() if activation else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.activate is not None:\n",
    "            x = self.activate(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeAndExcite(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, in_chn, reduction=4):\n",
    "        super().__init__()\n",
    "        reduction_chn = in_chn // reduction\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(\n",
    "                1\n",
    "            ),  # 1,16,x,y->1,1,16,1 each channel is reduce to one value\n",
    "            nn.Flatten(),  #  1,16\n",
    "            nn.Linear(in_chn, reduction_chn, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduction_chn, in_chn, bias=False),\n",
    "            nn.Hardsigmoid(),\n",
    "            nn.Unflatten(1, (in_chn, 1, 1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chn,\n",
    "        out_chn,\n",
    "        expansion_channel,\n",
    "        activation,\n",
    "        se_reduction=4,\n",
    "        se_flag=False,\n",
    "        kernel=3,\n",
    "        stride=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        #         expansion_channel=int(in_chn*expansiton_factor)\n",
    "        self.use_residual = (stride == 1) and (in_chn == out_chn)\n",
    "\n",
    "        self.residual_block_layers: list[nn.Module] = [\n",
    "            ConvBlock(\n",
    "                in_chn, expansion_channel, activation=activation, kernel_size=1\n",
    "            ),  # expansion_part\n",
    "            ConvBlock(\n",
    "                expansion_channel,\n",
    "                expansion_channel,\n",
    "                activation=activation,\n",
    "                group=expansion_channel,\n",
    "                stride=stride,\n",
    "                kernel_size=kernel,\n",
    "            ),  # depthwise conv\n",
    "        ]\n",
    "\n",
    "        if se_flag is True:\n",
    "            self.residual_block_layers.extend(\n",
    "                [SqueezeAndExcite(expansion_channel, reduction=se_reduction)]\n",
    "            )\n",
    "\n",
    "        self.residual_block_layers.extend(\n",
    "            [ConvBlock(expansion_channel, out_chn, activation=None, kernel_size=1)]\n",
    "        )\n",
    "\n",
    "        self.layers = nn.Sequential(*self.residual_block_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x) + x if self.use_residual else self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Hardswish, ReLU\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chn,\n",
    "        se_reduction=4,\n",
    "        mode=\"small\",\n",
    "        num_classes=10,\n",
    "        bn_eps=0.001,\n",
    "        bn_momentum=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if mode == \"large\":\n",
    "            layers_config = [\n",
    "                # kernel, exp, out, SE, NL, stride\n",
    "                [3, 16, 16, False, ReLU, 1],\n",
    "                [3, 64, 24, False, ReLU, 2],\n",
    "                [3, 72, 24, False, ReLU, 1],\n",
    "                [5, 72, 40, True, ReLU, 2],\n",
    "                [5, 120, 40, True, ReLU, 1],\n",
    "                [5, 120, 40, True, ReLU, 1],\n",
    "                [3, 240, 80, False, Hardswish, 2],\n",
    "                [3, 200, 80, False, Hardswish, 1],\n",
    "                [3, 184, 80, False, Hardswish, 1],\n",
    "                [3, 184, 80, False, Hardswish, 1],\n",
    "                [3, 480, 112, True, Hardswish, 1],\n",
    "                [3, 672, 112, True, Hardswish, 1],\n",
    "                [5, 672, 160, True, Hardswish, 2],\n",
    "                [5, 960, 160, True, Hardswish, 1],\n",
    "                [5, 960, 160, True, Hardswish, 1],\n",
    "            ]\n",
    "            last_channel = 1280\n",
    "\n",
    "            self.final_layers = [\n",
    "                ConvBlock(\n",
    "                    layers_config[-1][2], 960, activation=Hardswish, kernel_size=1\n",
    "                ),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(960, last_channel, 1),\n",
    "                Hardswish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(last_channel, num_classes),\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            # MobileNetV3-Small\n",
    "            layers_config = [\n",
    "                [3, 16, 16, True, ReLU, 2],\n",
    "                [3, 72, 24, False, ReLU, 2],\n",
    "                [3, 88, 24, False, ReLU, 1],\n",
    "                [5, 96, 40, True, Hardswish, 2],\n",
    "                [5, 240, 40, True, Hardswish, 1],\n",
    "                [5, 240, 40, True, Hardswish, 1],\n",
    "                [5, 120, 48, True, Hardswish, 1],\n",
    "                [5, 144, 48, True, Hardswish, 1],\n",
    "                [5, 288, 96, True, Hardswish, 2],\n",
    "                [5, 576, 96, True, Hardswish, 1],\n",
    "                [5, 576, 96, True, Hardswish, 1],\n",
    "            ]\n",
    "            last_channel = 1280\n",
    "            # final layer\n",
    "            self.final_layers = [\n",
    "                ConvBlock(\n",
    "                    layers_config[-1][2], 576, activation=Hardswish, kernel_size=1\n",
    "                ),\n",
    "                SqueezeAndExcite(576, se_reduction),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(576, last_channel, 1),\n",
    "                Hardswish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(last_channel, num_classes),\n",
    "            ]\n",
    "\n",
    "        # Initial layers\n",
    "        self.features: list[nn.Module] = [\n",
    "            ConvBlock(in_chn, 16, activation=Hardswish, kernel_size=3, stride=2)\n",
    "        ]\n",
    "        #         print(dir(self.features[-1]))\n",
    "\n",
    "        # Build main blocks\n",
    "\n",
    "        input_channel = 16\n",
    "        for kernel, exp, out, se, act, stride in layers_config:\n",
    "            self.features.append(\n",
    "                BottleNeck(\n",
    "                    in_chn=input_channel,\n",
    "                    out_chn=out,\n",
    "                    expansion_channel=exp,\n",
    "                    activation=act,\n",
    "                    kernel=kernel,\n",
    "                    se_flag=se,\n",
    "                    stride=stride,\n",
    "                )\n",
    "            )\n",
    "            input_channel = out\n",
    "\n",
    "        self.start = nn.Sequential(*self.features)\n",
    "        self.final = nn.Sequential(*self.final_layers)\n",
    "        \n",
    "        # modify batchnorm layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eps = bn_eps\n",
    "                m.momentum = bn_momentum\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device = \", device)\n",
    "n_epochs = 100\n",
    "earlyStopping = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting \n",
    "\n",
    "Due to high learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/254], Loss: 2.2964, Accuracy: 0.0625\n",
      "Epoch [1/100], Step [100/254], Loss: 2.2347, Accuracy: 0.2344\n",
      "Epoch [1/100], Step [200/254], Loss: 1.5120, Accuracy: 0.3594\n",
      "Epoch [1/100], Train Loss: 3.1375, Val Loss: 5.3135, Train Acc: 0.2870, Val Acc: 0.2299\n",
      "==================================================\n",
      "Epoch [2/100], Step [0/254], Loss: 1.9193, Accuracy: 0.2656\n",
      "Epoch [2/100], Step [100/254], Loss: 1.7059, Accuracy: 0.3750\n",
      "Epoch [2/100], Step [200/254], Loss: 1.6379, Accuracy: 0.4375\n",
      "Epoch [2/100], Train Loss: 1.5862, Val Loss: 6.3246, Train Acc: 0.4315, Val Acc: 0.2241\n",
      "==================================================\n",
      "Epoch [3/100], Step [0/254], Loss: 1.5092, Accuracy: 0.4062\n",
      "Epoch [3/100], Step [100/254], Loss: 2.0220, Accuracy: 0.2344\n",
      "Epoch [3/100], Step [200/254], Loss: 2.2077, Accuracy: 0.1875\n",
      "Epoch [3/100], Train Loss: 1.9332, Val Loss: 6.3059, Train Acc: 0.2825, Val Acc: 0.1114\n",
      "==================================================\n",
      "Epoch [4/100], Step [0/254], Loss: 2.2451, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [100/254], Loss: 1.9650, Accuracy: 0.2188\n",
      "Epoch [4/100], Step [200/254], Loss: 2.0492, Accuracy: 0.2656\n",
      "Epoch [4/100], Train Loss: 1.9982, Val Loss: 502.1431, Train Acc: 0.2618, Val Acc: 0.0736\n",
      "==================================================\n",
      "Epoch [5/100], Step [0/254], Loss: 1.9130, Accuracy: 0.2500\n",
      "Epoch [5/100], Step [100/254], Loss: 2.0290, Accuracy: 0.2812\n",
      "Epoch [5/100], Step [200/254], Loss: 2.2276, Accuracy: 0.2500\n",
      "Epoch [5/100], Train Loss: 2.1081, Val Loss: 15537.9961, Train Acc: 0.2355, Val Acc: 0.1128\n",
      "==================================================\n",
      "Epoch [6/100], Step [0/254], Loss: 2.0719, Accuracy: 0.1250\n",
      "Epoch [6/100], Step [100/254], Loss: 1.8519, Accuracy: 0.2344\n",
      "Epoch [6/100], Step [200/254], Loss: 1.7165, Accuracy: 0.3438\n",
      "Epoch [6/100], Train Loss: 1.8603, Val Loss: 1.9494, Train Acc: 0.2665, Val Acc: 0.2349\n",
      "==================================================\n",
      "Epoch [7/100], Step [0/254], Loss: 1.8001, Accuracy: 0.2500\n",
      "Epoch [7/100], Step [100/254], Loss: 1.4698, Accuracy: 0.4688\n",
      "Epoch [7/100], Step [200/254], Loss: 1.8581, Accuracy: 0.2656\n",
      "Epoch [7/100], Train Loss: 1.7249, Val Loss: 1.6978, Train Acc: 0.3296, Val Acc: 0.3272\n",
      "==================================================\n",
      "Epoch [8/100], Step [0/254], Loss: 1.6881, Accuracy: 0.3750\n",
      "Epoch [8/100], Step [100/254], Loss: 1.6347, Accuracy: 0.4375\n",
      "Epoch [8/100], Step [200/254], Loss: 1.6998, Accuracy: 0.2969\n",
      "Epoch [8/100], Train Loss: 1.6276, Val Loss: 1.7702, Train Acc: 0.3773, Val Acc: 0.3278\n",
      "==================================================\n",
      "Epoch [9/100], Step [0/254], Loss: 1.7060, Accuracy: 0.3281\n",
      "Epoch [9/100], Step [100/254], Loss: 1.5427, Accuracy: 0.4375\n",
      "Epoch [9/100], Step [200/254], Loss: 1.4880, Accuracy: 0.4844\n",
      "Epoch [9/100], Train Loss: 1.5495, Val Loss: 1.5776, Train Acc: 0.4114, Val Acc: 0.4165\n",
      "==================================================\n",
      "Epoch [10/100], Step [0/254], Loss: 1.4702, Accuracy: 0.3750\n",
      "Epoch [10/100], Step [100/254], Loss: 1.3763, Accuracy: 0.4688\n",
      "Epoch [10/100], Step [200/254], Loss: 1.6309, Accuracy: 0.4844\n",
      "Epoch [10/100], Train Loss: 1.4905, Val Loss: 1.4491, Train Acc: 0.4424, Val Acc: 0.4684\n",
      "==================================================\n",
      "Epoch [11/100], Step [0/254], Loss: 1.2144, Accuracy: 0.5312\n",
      "Epoch [11/100], Step [100/254], Loss: 1.2816, Accuracy: 0.5312\n",
      "Epoch [11/100], Step [200/254], Loss: 1.4061, Accuracy: 0.4375\n",
      "Epoch [11/100], Train Loss: 1.3719, Val Loss: 1.4623, Train Acc: 0.5007, Val Acc: 0.4951\n",
      "==================================================\n",
      "Epoch [12/100], Step [0/254], Loss: 1.2397, Accuracy: 0.5781\n",
      "Epoch [12/100], Step [100/254], Loss: 1.1928, Accuracy: 0.5625\n",
      "Epoch [12/100], Step [200/254], Loss: 1.3081, Accuracy: 0.5781\n",
      "Epoch [12/100], Train Loss: 1.2833, Val Loss: 2.0320, Train Acc: 0.5400, Val Acc: 0.4426\n",
      "==================================================\n",
      "Epoch [13/100], Step [0/254], Loss: 1.1432, Accuracy: 0.6719\n",
      "Epoch [13/100], Step [100/254], Loss: 1.0868, Accuracy: 0.6562\n",
      "Epoch [13/100], Step [200/254], Loss: 1.1088, Accuracy: 0.6094\n",
      "Epoch [13/100], Train Loss: 1.2184, Val Loss: 1.1540, Train Acc: 0.5601, Val Acc: 0.5869\n",
      "==================================================\n",
      "Epoch [14/100], Step [0/254], Loss: 1.3896, Accuracy: 0.4688\n",
      "Epoch [14/100], Step [100/254], Loss: 1.4014, Accuracy: 0.5156\n",
      "Epoch [14/100], Step [200/254], Loss: 1.3534, Accuracy: 0.5000\n",
      "Epoch [14/100], Train Loss: 1.3296, Val Loss: 1.2103, Train Acc: 0.5183, Val Acc: 0.5525\n",
      "==================================================\n",
      "Epoch [15/100], Step [0/254], Loss: 1.4055, Accuracy: 0.4844\n",
      "Epoch [15/100], Step [100/254], Loss: 1.5608, Accuracy: 0.4688\n",
      "Epoch [15/100], Step [200/254], Loss: 1.0293, Accuracy: 0.5938\n",
      "Epoch [15/100], Train Loss: 1.2255, Val Loss: 1.3248, Train Acc: 0.5436, Val Acc: 0.4972\n",
      "==================================================\n",
      "Epoch [16/100], Step [0/254], Loss: 0.9056, Accuracy: 0.7031\n",
      "Epoch [16/100], Step [100/254], Loss: 0.9688, Accuracy: 0.7031\n",
      "Epoch [16/100], Step [200/254], Loss: 0.8817, Accuracy: 0.6562\n",
      "Epoch [16/100], Train Loss: 1.1610, Val Loss: 1.1145, Train Acc: 0.5720, Val Acc: 0.5940\n",
      "==================================================\n",
      "Epoch [17/100], Step [0/254], Loss: 1.3216, Accuracy: 0.5469\n",
      "Epoch [17/100], Step [100/254], Loss: 1.2254, Accuracy: 0.5469\n",
      "Epoch [17/100], Step [200/254], Loss: 1.0461, Accuracy: 0.5156\n",
      "Epoch [17/100], Train Loss: 1.1335, Val Loss: 1.0535, Train Acc: 0.5834, Val Acc: 0.6143\n",
      "==================================================\n",
      "Epoch [18/100], Step [0/254], Loss: 1.1052, Accuracy: 0.5625\n",
      "Epoch [18/100], Step [100/254], Loss: 1.1130, Accuracy: 0.5781\n",
      "Epoch [18/100], Step [200/254], Loss: 1.1820, Accuracy: 0.6562\n",
      "Epoch [18/100], Train Loss: 1.0547, Val Loss: 1.2970, Train Acc: 0.6129, Val Acc: 0.5396\n",
      "==================================================\n",
      "Epoch [19/100], Step [0/254], Loss: 1.0087, Accuracy: 0.5781\n",
      "Epoch [19/100], Step [100/254], Loss: 1.2005, Accuracy: 0.5781\n",
      "Epoch [19/100], Step [200/254], Loss: 1.0576, Accuracy: 0.5625\n",
      "Epoch [19/100], Train Loss: 1.0389, Val Loss: 0.9626, Train Acc: 0.6228, Val Acc: 0.6462\n",
      "==================================================\n",
      "Epoch [20/100], Step [0/254], Loss: 1.0616, Accuracy: 0.6094\n",
      "Epoch [20/100], Step [100/254], Loss: 1.0359, Accuracy: 0.6875\n",
      "Epoch [20/100], Step [200/254], Loss: 1.4339, Accuracy: 0.5156\n",
      "Epoch [20/100], Train Loss: 1.2841, Val Loss: 2.8692, Train Acc: 0.5431, Val Acc: 0.3739\n",
      "==================================================\n",
      "Epoch [21/100], Step [0/254], Loss: 1.2954, Accuracy: 0.5312\n",
      "Epoch [21/100], Step [100/254], Loss: 1.3177, Accuracy: 0.5469\n",
      "Epoch [21/100], Step [200/254], Loss: 1.0123, Accuracy: 0.6719\n",
      "Epoch [21/100], Train Loss: 1.1770, Val Loss: 1.1851, Train Acc: 0.5746, Val Acc: 0.5691\n",
      "==================================================\n",
      "Epoch [22/100], Step [0/254], Loss: 1.3064, Accuracy: 0.5000\n",
      "Epoch [22/100], Step [100/254], Loss: 1.1828, Accuracy: 0.5625\n",
      "Epoch [22/100], Step [200/254], Loss: 1.0573, Accuracy: 0.7188\n",
      "Epoch [22/100], Train Loss: 1.0451, Val Loss: 1.7266, Train Acc: 0.6212, Val Acc: 0.4262\n",
      "==================================================\n",
      "Epoch [23/100], Step [0/254], Loss: 1.5580, Accuracy: 0.3438\n",
      "Epoch [23/100], Step [100/254], Loss: 1.5720, Accuracy: 0.4375\n",
      "Epoch [23/100], Step [200/254], Loss: 1.5045, Accuracy: 0.4844\n",
      "Epoch [23/100], Train Loss: 1.5081, Val Loss: 1.3816, Train Acc: 0.4627, Val Acc: 0.4939\n",
      "==================================================\n",
      "Epoch [24/100], Step [0/254], Loss: 1.1507, Accuracy: 0.5781\n",
      "Epoch [24/100], Step [100/254], Loss: 1.1354, Accuracy: 0.5469\n",
      "Epoch [24/100], Step [200/254], Loss: 1.1539, Accuracy: 0.5469\n",
      "Epoch [24/100], Train Loss: 1.1614, Val Loss: 1.0922, Train Acc: 0.5784, Val Acc: 0.5996\n",
      "==================================================\n",
      "Epoch [25/100], Step [0/254], Loss: 0.8753, Accuracy: 0.6875\n",
      "Epoch [25/100], Step [100/254], Loss: 1.2717, Accuracy: 0.5781\n",
      "Epoch [25/100], Step [200/254], Loss: 1.0574, Accuracy: 0.5625\n",
      "Epoch [25/100], Train Loss: 1.0867, Val Loss: 1.0710, Train Acc: 0.6083, Val Acc: 0.6136\n",
      "==================================================\n",
      "Epoch [26/100], Step [0/254], Loss: 1.1077, Accuracy: 0.5156\n",
      "Epoch [26/100], Step [100/254], Loss: 1.0211, Accuracy: 0.6562\n",
      "Epoch [26/100], Step [200/254], Loss: 0.9961, Accuracy: 0.6250\n",
      "Epoch [26/100], Train Loss: 1.0497, Val Loss: 0.9940, Train Acc: 0.6243, Val Acc: 0.6404\n",
      "==================================================\n",
      "Epoch [27/100], Step [0/254], Loss: 0.9495, Accuracy: 0.6250\n",
      "Epoch [27/100], Step [100/254], Loss: 0.9530, Accuracy: 0.6250\n",
      "Epoch [27/100], Step [200/254], Loss: 1.2842, Accuracy: 0.6094\n",
      "Epoch [27/100], Train Loss: 1.0149, Val Loss: 0.9109, Train Acc: 0.6369, Val Acc: 0.6731\n",
      "==================================================\n",
      "Epoch [28/100], Step [0/254], Loss: 0.8458, Accuracy: 0.6719\n",
      "Epoch [28/100], Step [100/254], Loss: 0.9705, Accuracy: 0.6406\n",
      "Epoch [28/100], Step [200/254], Loss: 0.8621, Accuracy: 0.6406\n",
      "Epoch [28/100], Train Loss: 0.9804, Val Loss: 0.9503, Train Acc: 0.6436, Val Acc: 0.6564\n",
      "==================================================\n",
      "Epoch [29/100], Step [0/254], Loss: 0.9274, Accuracy: 0.6719\n",
      "Epoch [29/100], Step [100/254], Loss: 1.0946, Accuracy: 0.5938\n",
      "Epoch [29/100], Step [200/254], Loss: 0.8415, Accuracy: 0.7031\n",
      "Epoch [29/100], Train Loss: 0.9610, Val Loss: 0.8767, Train Acc: 0.6524, Val Acc: 0.6737\n",
      "==================================================\n",
      "Epoch [30/100], Step [0/254], Loss: 1.0066, Accuracy: 0.5781\n",
      "Epoch [30/100], Step [100/254], Loss: 0.9154, Accuracy: 0.5469\n",
      "Epoch [30/100], Step [200/254], Loss: 0.7293, Accuracy: 0.7812\n",
      "Epoch [30/100], Train Loss: 0.9371, Val Loss: 0.8742, Train Acc: 0.6590, Val Acc: 0.6660\n",
      "==================================================\n",
      "Epoch [31/100], Step [0/254], Loss: 0.8734, Accuracy: 0.6719\n",
      "Epoch [31/100], Step [100/254], Loss: 0.8422, Accuracy: 0.6875\n",
      "Epoch [31/100], Step [200/254], Loss: 0.8888, Accuracy: 0.6562\n",
      "Epoch [31/100], Train Loss: 0.9041, Val Loss: 0.8092, Train Acc: 0.6691, Val Acc: 0.7043\n",
      "==================================================\n",
      "Epoch [32/100], Step [0/254], Loss: 0.8246, Accuracy: 0.6406\n",
      "Epoch [32/100], Step [100/254], Loss: 0.9373, Accuracy: 0.7500\n",
      "Epoch [32/100], Step [200/254], Loss: 1.1450, Accuracy: 0.6406\n",
      "Epoch [32/100], Train Loss: 0.8998, Val Loss: 0.8174, Train Acc: 0.6744, Val Acc: 0.6985\n",
      "==================================================\n",
      "Epoch [33/100], Step [0/254], Loss: 0.7045, Accuracy: 0.7344\n",
      "Epoch [33/100], Step [100/254], Loss: 1.0931, Accuracy: 0.5781\n",
      "Epoch [33/100], Step [200/254], Loss: 0.8505, Accuracy: 0.7344\n",
      "Epoch [33/100], Train Loss: 0.8775, Val Loss: 0.8037, Train Acc: 0.6778, Val Acc: 0.7077\n",
      "==================================================\n",
      "Epoch [34/100], Step [0/254], Loss: 0.8299, Accuracy: 0.6562\n",
      "Epoch [34/100], Step [100/254], Loss: 0.8996, Accuracy: 0.6719\n",
      "Epoch [34/100], Step [200/254], Loss: 0.6517, Accuracy: 0.7969\n",
      "Epoch [34/100], Train Loss: 0.8492, Val Loss: 0.7581, Train Acc: 0.6915, Val Acc: 0.7236\n",
      "==================================================\n",
      "Epoch [35/100], Step [0/254], Loss: 0.6645, Accuracy: 0.7500\n",
      "Epoch [35/100], Step [100/254], Loss: 0.9349, Accuracy: 0.6719\n",
      "Epoch [35/100], Step [200/254], Loss: 0.8704, Accuracy: 0.6406\n",
      "Epoch [35/100], Train Loss: 0.8486, Val Loss: 0.9472, Train Acc: 0.6919, Val Acc: 0.6637\n",
      "==================================================\n",
      "Epoch [36/100], Step [0/254], Loss: 0.6446, Accuracy: 0.7031\n",
      "Epoch [36/100], Step [100/254], Loss: 0.8999, Accuracy: 0.6719\n",
      "Epoch [36/100], Step [200/254], Loss: 0.7777, Accuracy: 0.6875\n",
      "Epoch [36/100], Train Loss: 0.8419, Val Loss: 0.7901, Train Acc: 0.6878, Val Acc: 0.7053\n",
      "==================================================\n",
      "Epoch [37/100], Step [0/254], Loss: 0.7252, Accuracy: 0.7812\n",
      "Epoch [37/100], Step [100/254], Loss: 0.7870, Accuracy: 0.7188\n",
      "Epoch [37/100], Step [200/254], Loss: 0.8102, Accuracy: 0.6250\n",
      "Epoch [37/100], Train Loss: 0.8119, Val Loss: 0.8275, Train Acc: 0.7026, Val Acc: 0.6974\n",
      "==================================================\n",
      "Epoch [38/100], Step [0/254], Loss: 0.8014, Accuracy: 0.6406\n",
      "Epoch [38/100], Step [100/254], Loss: 0.8238, Accuracy: 0.6719\n",
      "Epoch [38/100], Step [200/254], Loss: 0.8511, Accuracy: 0.5938\n",
      "Epoch [38/100], Train Loss: 0.8255, Val Loss: 0.7474, Train Acc: 0.6969, Val Acc: 0.7254\n",
      "==================================================\n",
      "Epoch [39/100], Step [0/254], Loss: 0.8524, Accuracy: 0.7031\n",
      "Epoch [39/100], Step [100/254], Loss: 0.9542, Accuracy: 0.6562\n",
      "Epoch [39/100], Step [200/254], Loss: 0.8498, Accuracy: 0.6719\n",
      "Epoch [39/100], Train Loss: 0.8077, Val Loss: 0.7117, Train Acc: 0.7080, Val Acc: 0.7349\n",
      "==================================================\n",
      "Epoch [40/100], Step [0/254], Loss: 0.8298, Accuracy: 0.7344\n",
      "Epoch [40/100], Step [100/254], Loss: 0.5935, Accuracy: 0.7969\n",
      "Epoch [40/100], Step [200/254], Loss: 0.8127, Accuracy: 0.7188\n",
      "Epoch [40/100], Train Loss: 0.7767, Val Loss: 0.7016, Train Acc: 0.7140, Val Acc: 0.7440\n",
      "==================================================\n",
      "Epoch [41/100], Step [0/254], Loss: 0.6014, Accuracy: 0.7656\n",
      "Epoch [41/100], Step [100/254], Loss: 0.8665, Accuracy: 0.7031\n",
      "Epoch [41/100], Step [200/254], Loss: 0.8649, Accuracy: 0.5938\n",
      "Epoch [41/100], Train Loss: 0.7699, Val Loss: 0.7923, Train Acc: 0.7226, Val Acc: 0.7126\n",
      "==================================================\n",
      "Epoch [42/100], Step [0/254], Loss: 0.9304, Accuracy: 0.6875\n",
      "Epoch [42/100], Step [100/254], Loss: 0.8818, Accuracy: 0.6875\n",
      "Epoch [42/100], Step [200/254], Loss: 0.6345, Accuracy: 0.7500\n",
      "Epoch [42/100], Train Loss: 0.7671, Val Loss: 0.6970, Train Acc: 0.7237, Val Acc: 0.7473\n",
      "==================================================\n",
      "Epoch [43/100], Step [0/254], Loss: 0.6230, Accuracy: 0.7812\n",
      "Epoch [43/100], Step [100/254], Loss: 0.5898, Accuracy: 0.8438\n",
      "Epoch [43/100], Step [200/254], Loss: 0.7254, Accuracy: 0.7812\n",
      "Epoch [43/100], Train Loss: 0.7528, Val Loss: 0.6845, Train Acc: 0.7260, Val Acc: 0.7539\n",
      "==================================================\n",
      "Epoch [44/100], Step [0/254], Loss: 0.7878, Accuracy: 0.7969\n",
      "Epoch [44/100], Step [100/254], Loss: 0.8111, Accuracy: 0.7031\n",
      "Epoch [44/100], Step [200/254], Loss: 0.6203, Accuracy: 0.6875\n",
      "Epoch [44/100], Train Loss: 0.7392, Val Loss: 0.6839, Train Acc: 0.7330, Val Acc: 0.7546\n",
      "==================================================\n",
      "Epoch [45/100], Step [0/254], Loss: 0.6225, Accuracy: 0.7969\n",
      "Epoch [45/100], Step [100/254], Loss: 0.6524, Accuracy: 0.7031\n",
      "Epoch [45/100], Step [200/254], Loss: 0.6736, Accuracy: 0.7188\n",
      "Epoch [45/100], Train Loss: 0.7318, Val Loss: 0.7473, Train Acc: 0.7343, Val Acc: 0.7312\n",
      "==================================================\n",
      "Epoch [46/100], Step [0/254], Loss: 1.1489, Accuracy: 0.6250\n",
      "Epoch [46/100], Step [100/254], Loss: 0.4570, Accuracy: 0.8281\n",
      "Epoch [46/100], Step [200/254], Loss: 0.7800, Accuracy: 0.6719\n",
      "Epoch [46/100], Train Loss: 0.7144, Val Loss: 0.6730, Train Acc: 0.7442, Val Acc: 0.7491\n",
      "==================================================\n",
      "Epoch [47/100], Step [0/254], Loss: 0.6260, Accuracy: 0.8594\n",
      "Epoch [47/100], Step [100/254], Loss: 0.8904, Accuracy: 0.7344\n",
      "Epoch [47/100], Step [200/254], Loss: 0.5980, Accuracy: 0.8125\n",
      "Epoch [47/100], Train Loss: 0.6903, Val Loss: 0.6601, Train Acc: 0.7523, Val Acc: 0.7652\n",
      "==================================================\n",
      "Epoch [48/100], Step [0/254], Loss: 0.7471, Accuracy: 0.7031\n",
      "Epoch [48/100], Step [100/254], Loss: 0.5863, Accuracy: 0.7812\n",
      "Epoch [48/100], Step [200/254], Loss: 0.7539, Accuracy: 0.7656\n",
      "Epoch [48/100], Train Loss: 0.6870, Val Loss: 1.2344, Train Acc: 0.7494, Val Acc: 0.5832\n",
      "==================================================\n",
      "Epoch [49/100], Step [0/254], Loss: 0.6135, Accuracy: 0.8125\n",
      "Epoch [49/100], Step [100/254], Loss: 0.5869, Accuracy: 0.8281\n",
      "Epoch [49/100], Step [200/254], Loss: 0.7278, Accuracy: 0.6875\n",
      "Epoch [49/100], Train Loss: 0.6874, Val Loss: 0.6532, Train Acc: 0.7516, Val Acc: 0.7668\n",
      "==================================================\n",
      "Epoch [50/100], Step [0/254], Loss: 0.6382, Accuracy: 0.7656\n",
      "Epoch [50/100], Step [100/254], Loss: 0.4515, Accuracy: 0.8906\n",
      "Epoch [50/100], Step [200/254], Loss: 0.5886, Accuracy: 0.7812\n",
      "Epoch [50/100], Train Loss: 0.6547, Val Loss: 0.5797, Train Acc: 0.7622, Val Acc: 0.7930\n",
      "==================================================\n",
      "Epoch [51/100], Step [0/254], Loss: 0.6373, Accuracy: 0.8125\n",
      "Epoch [51/100], Step [100/254], Loss: 0.8587, Accuracy: 0.7188\n",
      "Epoch [51/100], Step [200/254], Loss: 0.4586, Accuracy: 0.8438\n",
      "Epoch [51/100], Train Loss: 0.6512, Val Loss: 0.6164, Train Acc: 0.7676, Val Acc: 0.7736\n",
      "==================================================\n",
      "Epoch [52/100], Step [0/254], Loss: 0.5867, Accuracy: 0.7656\n",
      "Epoch [52/100], Step [100/254], Loss: 0.8487, Accuracy: 0.7656\n",
      "Epoch [52/100], Step [200/254], Loss: 0.6234, Accuracy: 0.8438\n",
      "Epoch [52/100], Train Loss: 0.7213, Val Loss: 0.5927, Train Acc: 0.7452, Val Acc: 0.7867\n",
      "==================================================\n",
      "Epoch [53/100], Step [0/254], Loss: 0.8648, Accuracy: 0.6875\n",
      "Epoch [53/100], Step [100/254], Loss: 0.8019, Accuracy: 0.6875\n",
      "Epoch [53/100], Step [200/254], Loss: 0.9335, Accuracy: 0.6250\n",
      "Epoch [53/100], Train Loss: 0.7963, Val Loss: 0.6458, Train Acc: 0.7183, Val Acc: 0.7694\n",
      "==================================================\n",
      "Epoch [54/100], Step [0/254], Loss: 0.7532, Accuracy: 0.7656\n",
      "Epoch [54/100], Step [100/254], Loss: 0.7864, Accuracy: 0.7031\n",
      "Epoch [54/100], Step [200/254], Loss: 0.7794, Accuracy: 0.6875\n",
      "Epoch [54/100], Train Loss: 0.6807, Val Loss: 0.6377, Train Acc: 0.7549, Val Acc: 0.7628\n",
      "==================================================\n",
      "Epoch [55/100], Step [0/254], Loss: 0.4850, Accuracy: 0.8281\n",
      "Epoch [55/100], Step [100/254], Loss: 0.5945, Accuracy: 0.7969\n",
      "Epoch [55/100], Step [200/254], Loss: 0.6520, Accuracy: 0.7656\n",
      "Epoch [55/100], Train Loss: 0.6552, Val Loss: 0.5622, Train Acc: 0.7677, Val Acc: 0.7987\n",
      "==================================================\n",
      "Epoch [56/100], Step [0/254], Loss: 0.6257, Accuracy: 0.7812\n",
      "Epoch [56/100], Step [100/254], Loss: 0.5915, Accuracy: 0.7344\n",
      "Epoch [56/100], Step [200/254], Loss: 0.6582, Accuracy: 0.7344\n",
      "Epoch [56/100], Train Loss: 0.6436, Val Loss: 0.5635, Train Acc: 0.7713, Val Acc: 0.8002\n",
      "==================================================\n",
      "Epoch [57/100], Step [0/254], Loss: 0.6282, Accuracy: 0.7188\n",
      "Epoch [57/100], Step [100/254], Loss: 0.5063, Accuracy: 0.8281\n",
      "Epoch [57/100], Step [200/254], Loss: 0.6861, Accuracy: 0.7031\n",
      "Epoch [57/100], Train Loss: 0.6282, Val Loss: 0.5450, Train Acc: 0.7756, Val Acc: 0.8094\n",
      "==================================================\n",
      "Epoch [58/100], Step [0/254], Loss: 0.5382, Accuracy: 0.8281\n",
      "Epoch [58/100], Step [100/254], Loss: 0.5481, Accuracy: 0.8281\n",
      "Epoch [58/100], Step [200/254], Loss: 0.4681, Accuracy: 0.8438\n",
      "Epoch [58/100], Train Loss: 0.6250, Val Loss: 0.5483, Train Acc: 0.7790, Val Acc: 0.8027\n",
      "==================================================\n",
      "Epoch [59/100], Step [0/254], Loss: 0.7380, Accuracy: 0.7812\n",
      "Epoch [59/100], Step [100/254], Loss: 0.6100, Accuracy: 0.8281\n",
      "Epoch [59/100], Step [200/254], Loss: 0.6794, Accuracy: 0.7500\n",
      "Epoch [59/100], Train Loss: 0.6303, Val Loss: 0.5594, Train Acc: 0.7774, Val Acc: 0.7987\n",
      "==================================================\n",
      "Epoch [60/100], Step [0/254], Loss: 0.4857, Accuracy: 0.8281\n",
      "Epoch [60/100], Step [100/254], Loss: 0.8127, Accuracy: 0.6719\n",
      "Epoch [60/100], Step [200/254], Loss: 0.6083, Accuracy: 0.7812\n",
      "Epoch [60/100], Train Loss: 0.6129, Val Loss: 0.5536, Train Acc: 0.7813, Val Acc: 0.8093\n",
      "==================================================\n",
      "Epoch [61/100], Step [0/254], Loss: 0.7948, Accuracy: 0.7500\n",
      "Epoch [61/100], Step [100/254], Loss: 0.5469, Accuracy: 0.8125\n",
      "Epoch [61/100], Step [200/254], Loss: 0.7207, Accuracy: 0.7188\n",
      "Epoch [61/100], Train Loss: 0.6072, Val Loss: 0.5935, Train Acc: 0.7838, Val Acc: 0.8097\n",
      "==================================================\n",
      "Epoch [62/100], Step [0/254], Loss: 0.6940, Accuracy: 0.7500\n",
      "Epoch [62/100], Step [100/254], Loss: 0.6836, Accuracy: 0.6875\n",
      "Epoch [62/100], Step [200/254], Loss: 0.4755, Accuracy: 0.8125\n",
      "Epoch [62/100], Train Loss: 0.5947, Val Loss: 0.5312, Train Acc: 0.7864, Val Acc: 0.8132\n",
      "==================================================\n",
      "Epoch [63/100], Step [0/254], Loss: 0.6441, Accuracy: 0.7812\n",
      "Epoch [63/100], Step [100/254], Loss: 0.5851, Accuracy: 0.6875\n",
      "Epoch [63/100], Step [200/254], Loss: 0.4706, Accuracy: 0.8438\n",
      "Epoch [63/100], Train Loss: 0.6141, Val Loss: 0.5281, Train Acc: 0.7815, Val Acc: 0.8131\n",
      "==================================================\n",
      "Epoch [64/100], Step [0/254], Loss: 1.0329, Accuracy: 0.6875\n",
      "Epoch [64/100], Step [100/254], Loss: 0.5379, Accuracy: 0.7656\n",
      "Epoch [64/100], Step [200/254], Loss: 0.5730, Accuracy: 0.8438\n",
      "Epoch [64/100], Train Loss: 0.5968, Val Loss: 0.5804, Train Acc: 0.7896, Val Acc: 0.8069\n",
      "==================================================\n",
      "Epoch [65/100], Step [0/254], Loss: 0.5707, Accuracy: 0.8281\n",
      "Epoch [65/100], Step [100/254], Loss: 0.4844, Accuracy: 0.8125\n",
      "Epoch [65/100], Step [200/254], Loss: 0.7128, Accuracy: 0.7344\n",
      "Epoch [65/100], Train Loss: 0.6023, Val Loss: 0.5296, Train Acc: 0.7851, Val Acc: 0.8149\n",
      "==================================================\n",
      "Epoch [66/100], Step [0/254], Loss: 0.5926, Accuracy: 0.7969\n",
      "Epoch [66/100], Step [100/254], Loss: 0.3949, Accuracy: 0.8594\n",
      "Epoch [66/100], Step [200/254], Loss: 0.6596, Accuracy: 0.7969\n",
      "Epoch [66/100], Train Loss: 0.6069, Val Loss: 0.5244, Train Acc: 0.7831, Val Acc: 0.8128\n",
      "==================================================\n",
      "Epoch [67/100], Step [0/254], Loss: 0.7606, Accuracy: 0.7188\n",
      "Epoch [67/100], Step [100/254], Loss: 0.3743, Accuracy: 0.8906\n",
      "Epoch [67/100], Step [200/254], Loss: 0.9109, Accuracy: 0.6875\n",
      "Epoch [67/100], Train Loss: 0.5932, Val Loss: 0.5263, Train Acc: 0.7879, Val Acc: 0.8165\n",
      "==================================================\n",
      "Epoch [68/100], Step [0/254], Loss: 0.6920, Accuracy: 0.7344\n",
      "Epoch [68/100], Step [100/254], Loss: 0.7731, Accuracy: 0.7344\n",
      "Epoch [68/100], Step [200/254], Loss: 0.6844, Accuracy: 0.7500\n",
      "Epoch [68/100], Train Loss: 0.5999, Val Loss: 0.5325, Train Acc: 0.7860, Val Acc: 0.8145\n",
      "==================================================\n",
      "Epoch [69/100], Step [0/254], Loss: 0.5088, Accuracy: 0.8125\n",
      "Epoch [69/100], Step [100/254], Loss: 0.7078, Accuracy: 0.7500\n",
      "Epoch [69/100], Step [200/254], Loss: 0.5870, Accuracy: 0.7656\n",
      "Epoch [69/100], Train Loss: 0.6154, Val Loss: 0.6018, Train Acc: 0.7857, Val Acc: 0.8118\n",
      "==================================================\n",
      "Epoch [70/100], Step [0/254], Loss: 0.6383, Accuracy: 0.7812\n",
      "Epoch [70/100], Step [100/254], Loss: 0.6313, Accuracy: 0.6719\n",
      "Epoch [70/100], Step [200/254], Loss: 0.7984, Accuracy: 0.6875\n",
      "Epoch [70/100], Train Loss: 0.5940, Val Loss: 0.5208, Train Acc: 0.7894, Val Acc: 0.8168\n",
      "==================================================\n",
      "Epoch [71/100], Step [0/254], Loss: 0.5678, Accuracy: 0.7656\n",
      "Epoch [71/100], Step [100/254], Loss: 0.9245, Accuracy: 0.6406\n",
      "Epoch [71/100], Step [200/254], Loss: 0.5567, Accuracy: 0.8281\n",
      "Epoch [71/100], Train Loss: 0.5907, Val Loss: 0.5245, Train Acc: 0.7913, Val Acc: 0.8114\n",
      "==================================================\n",
      "Epoch [72/100], Step [0/254], Loss: 0.6938, Accuracy: 0.7812\n",
      "Epoch [72/100], Step [100/254], Loss: 0.4561, Accuracy: 0.8438\n",
      "Epoch [72/100], Step [200/254], Loss: 0.6597, Accuracy: 0.7344\n",
      "Epoch [72/100], Train Loss: 0.5953, Val Loss: 0.5201, Train Acc: 0.7893, Val Acc: 0.8164\n",
      "==================================================\n",
      "Epoch [73/100], Step [0/254], Loss: 0.4530, Accuracy: 0.8281\n",
      "Epoch [73/100], Step [100/254], Loss: 0.7022, Accuracy: 0.7500\n",
      "Epoch [73/100], Step [200/254], Loss: 0.4780, Accuracy: 0.8281\n",
      "Epoch [73/100], Train Loss: 0.5937, Val Loss: 0.5237, Train Acc: 0.7913, Val Acc: 0.8156\n",
      "==================================================\n",
      "Epoch [74/100], Step [0/254], Loss: 0.5066, Accuracy: 0.7812\n",
      "Epoch [74/100], Step [100/254], Loss: 0.5206, Accuracy: 0.7969\n",
      "Epoch [74/100], Step [200/254], Loss: 0.5068, Accuracy: 0.8438\n",
      "Epoch [74/100], Train Loss: 0.5985, Val Loss: 0.6057, Train Acc: 0.7897, Val Acc: 0.8144\n",
      "==================================================\n",
      "Epoch [75/100], Step [0/254], Loss: 0.7118, Accuracy: 0.7812\n",
      "Epoch [75/100], Step [100/254], Loss: 0.4959, Accuracy: 0.8125\n",
      "Epoch [75/100], Step [200/254], Loss: 0.5459, Accuracy: 0.7969\n",
      "Epoch [75/100], Train Loss: 0.5895, Val Loss: 0.5170, Train Acc: 0.7844, Val Acc: 0.8182\n",
      "==================================================\n",
      "Epoch [76/100], Step [0/254], Loss: 0.5217, Accuracy: 0.7812\n",
      "Epoch [76/100], Step [100/254], Loss: 0.7824, Accuracy: 0.7500\n",
      "Epoch [76/100], Step [200/254], Loss: 0.5357, Accuracy: 0.8281\n",
      "Epoch [76/100], Train Loss: 0.6034, Val Loss: 0.5319, Train Acc: 0.7881, Val Acc: 0.8152\n",
      "==================================================\n",
      "Epoch [77/100], Step [0/254], Loss: 0.5056, Accuracy: 0.8125\n",
      "Epoch [77/100], Step [100/254], Loss: 0.4629, Accuracy: 0.8125\n",
      "Epoch [77/100], Step [200/254], Loss: 0.5228, Accuracy: 0.8438\n",
      "Epoch [77/100], Train Loss: 0.5948, Val Loss: 0.5165, Train Acc: 0.7892, Val Acc: 0.8146\n",
      "==================================================\n",
      "Epoch [78/100], Step [0/254], Loss: 0.5521, Accuracy: 0.7969\n",
      "Epoch [78/100], Step [100/254], Loss: 0.5657, Accuracy: 0.8281\n",
      "Epoch [78/100], Step [200/254], Loss: 0.5909, Accuracy: 0.8125\n",
      "Epoch [78/100], Train Loss: 0.5888, Val Loss: 0.5141, Train Acc: 0.7940, Val Acc: 0.8163\n",
      "==================================================\n",
      "Epoch [79/100], Step [0/254], Loss: 0.4781, Accuracy: 0.8125\n",
      "Epoch [79/100], Step [100/254], Loss: 0.6011, Accuracy: 0.7656\n",
      "Epoch [79/100], Step [200/254], Loss: 0.4663, Accuracy: 0.8125\n",
      "Epoch [79/100], Train Loss: 0.5926, Val Loss: 0.5409, Train Acc: 0.7878, Val Acc: 0.8157\n",
      "==================================================\n",
      "Epoch [80/100], Step [0/254], Loss: 0.6000, Accuracy: 0.8281\n",
      "Epoch [80/100], Step [100/254], Loss: 0.6696, Accuracy: 0.8125\n",
      "Epoch [80/100], Step [200/254], Loss: 0.3967, Accuracy: 0.8438\n",
      "Epoch [80/100], Train Loss: 0.5948, Val Loss: 0.5075, Train Acc: 0.7881, Val Acc: 0.8202\n",
      "==================================================\n",
      "Epoch [81/100], Step [0/254], Loss: 0.6079, Accuracy: 0.7812\n",
      "Epoch [81/100], Step [100/254], Loss: 0.5556, Accuracy: 0.7812\n",
      "Epoch [81/100], Step [200/254], Loss: 0.5059, Accuracy: 0.8438\n",
      "Epoch [81/100], Train Loss: 0.5912, Val Loss: 0.5123, Train Acc: 0.7893, Val Acc: 0.8191\n",
      "==================================================\n",
      "Epoch [82/100], Step [0/254], Loss: 0.7305, Accuracy: 0.7344\n",
      "Epoch [82/100], Step [100/254], Loss: 0.3909, Accuracy: 0.8906\n",
      "Epoch [82/100], Step [200/254], Loss: 0.7471, Accuracy: 0.6719\n",
      "Epoch [82/100], Train Loss: 0.5952, Val Loss: 0.5415, Train Acc: 0.7841, Val Acc: 0.8160\n",
      "==================================================\n",
      "Epoch [83/100], Step [0/254], Loss: 0.7647, Accuracy: 0.7500\n",
      "Epoch [83/100], Step [100/254], Loss: 0.9137, Accuracy: 0.6562\n",
      "Epoch [83/100], Step [200/254], Loss: 0.6020, Accuracy: 0.7812\n",
      "Epoch [83/100], Train Loss: 0.5846, Val Loss: 0.5183, Train Acc: 0.7905, Val Acc: 0.8186\n",
      "==================================================\n",
      "Epoch [84/100], Step [0/254], Loss: 0.6887, Accuracy: 0.8125\n",
      "Epoch [84/100], Step [100/254], Loss: 0.8253, Accuracy: 0.7812\n",
      "Epoch [84/100], Step [200/254], Loss: 0.6374, Accuracy: 0.7344\n",
      "Epoch [84/100], Train Loss: 0.5930, Val Loss: 0.5672, Train Acc: 0.7889, Val Acc: 0.8169\n",
      "==================================================\n",
      "Epoch [85/100], Step [0/254], Loss: 0.5341, Accuracy: 0.7969\n",
      "Epoch [85/100], Step [100/254], Loss: 0.4417, Accuracy: 0.8594\n",
      "Epoch [85/100], Step [200/254], Loss: 0.6796, Accuracy: 0.7500\n",
      "Epoch [85/100], Train Loss: 0.5900, Val Loss: 0.5117, Train Acc: 0.7903, Val Acc: 0.8191\n",
      "==================================================\n",
      "Epoch [86/100], Step [0/254], Loss: 0.6780, Accuracy: 0.7344\n",
      "Epoch [86/100], Step [100/254], Loss: 0.4033, Accuracy: 0.8438\n",
      "Epoch [86/100], Step [200/254], Loss: 0.4959, Accuracy: 0.8594\n",
      "Epoch [86/100], Train Loss: 0.5809, Val Loss: 0.6582, Train Acc: 0.7935, Val Acc: 0.8220\n",
      "==================================================\n",
      "Epoch [87/100], Step [0/254], Loss: 0.7417, Accuracy: 0.7500\n",
      "Epoch [87/100], Step [100/254], Loss: 0.5045, Accuracy: 0.7500\n",
      "Epoch [87/100], Step [200/254], Loss: 0.6440, Accuracy: 0.7812\n",
      "Epoch [87/100], Train Loss: 0.5814, Val Loss: 0.5236, Train Acc: 0.7913, Val Acc: 0.8192\n",
      "==================================================\n",
      "Epoch [88/100], Step [0/254], Loss: 0.4294, Accuracy: 0.8594\n",
      "Epoch [88/100], Step [100/254], Loss: 0.6170, Accuracy: 0.7188\n",
      "Epoch [88/100], Step [200/254], Loss: 0.5957, Accuracy: 0.8438\n",
      "Epoch [88/100], Train Loss: 0.5890, Val Loss: 0.5058, Train Acc: 0.7915, Val Acc: 0.8211\n",
      "==================================================\n",
      "Epoch [89/100], Step [0/254], Loss: 0.5545, Accuracy: 0.7812\n",
      "Epoch [89/100], Step [100/254], Loss: 0.5773, Accuracy: 0.7656\n",
      "Epoch [89/100], Step [200/254], Loss: 0.6881, Accuracy: 0.7500\n",
      "Epoch [89/100], Train Loss: 0.5888, Val Loss: 0.5079, Train Acc: 0.7886, Val Acc: 0.8198\n",
      "==================================================\n",
      "Epoch [90/100], Step [0/254], Loss: 0.5973, Accuracy: 0.7344\n",
      "Epoch [90/100], Step [100/254], Loss: 0.5764, Accuracy: 0.7500\n",
      "Epoch [90/100], Step [200/254], Loss: 0.4095, Accuracy: 0.8438\n",
      "Epoch [90/100], Train Loss: 0.5848, Val Loss: 0.5253, Train Acc: 0.7913, Val Acc: 0.8177\n",
      "==================================================\n",
      "Epoch [91/100], Step [0/254], Loss: 0.6601, Accuracy: 0.7656\n",
      "Epoch [91/100], Step [100/254], Loss: 0.5887, Accuracy: 0.7500\n",
      "Epoch [91/100], Step [200/254], Loss: 0.7512, Accuracy: 0.7344\n",
      "Epoch [91/100], Train Loss: 0.5764, Val Loss: 0.5996, Train Acc: 0.7921, Val Acc: 0.8209\n",
      "==================================================\n",
      "Epoch [92/100], Step [0/254], Loss: 0.6852, Accuracy: 0.6875\n",
      "Epoch [92/100], Step [100/254], Loss: 0.5362, Accuracy: 0.8281\n",
      "Epoch [92/100], Step [200/254], Loss: 0.5507, Accuracy: 0.8125\n",
      "Epoch [92/100], Train Loss: 0.5812, Val Loss: 0.5055, Train Acc: 0.7926, Val Acc: 0.8186\n",
      "==================================================\n",
      "Epoch [93/100], Step [0/254], Loss: 0.8690, Accuracy: 0.7344\n",
      "Epoch [93/100], Step [100/254], Loss: 0.5665, Accuracy: 0.8125\n",
      "Epoch [93/100], Step [200/254], Loss: 0.6446, Accuracy: 0.7812\n",
      "Epoch [93/100], Train Loss: 0.5767, Val Loss: 0.5518, Train Acc: 0.7927, Val Acc: 0.8206\n",
      "==================================================\n",
      "Epoch [94/100], Step [0/254], Loss: 0.5655, Accuracy: 0.8125\n",
      "Epoch [94/100], Step [100/254], Loss: 0.5291, Accuracy: 0.8281\n",
      "Epoch [94/100], Step [200/254], Loss: 0.6042, Accuracy: 0.7812\n",
      "Epoch [94/100], Train Loss: 0.5866, Val Loss: 0.5075, Train Acc: 0.7943, Val Acc: 0.8188\n",
      "==================================================\n",
      "Epoch [95/100], Step [0/254], Loss: 0.7489, Accuracy: 0.7188\n",
      "Epoch [95/100], Step [100/254], Loss: 0.4176, Accuracy: 0.8750\n",
      "Epoch [95/100], Step [200/254], Loss: 0.7231, Accuracy: 0.7344\n",
      "Epoch [95/100], Train Loss: 0.5811, Val Loss: 0.5081, Train Acc: 0.7916, Val Acc: 0.8216\n",
      "==================================================\n",
      "Epoch [96/100], Step [0/254], Loss: 0.6064, Accuracy: 0.7812\n",
      "Epoch [96/100], Step [100/254], Loss: 1.0233, Accuracy: 0.6094\n",
      "Epoch [96/100], Step [200/254], Loss: 0.6448, Accuracy: 0.7812\n",
      "Epoch [96/100], Train Loss: 0.5749, Val Loss: 0.6929, Train Acc: 0.7919, Val Acc: 0.8207\n",
      "==================================================\n",
      "Epoch [97/100], Step [0/254], Loss: 0.6649, Accuracy: 0.7969\n",
      "Epoch [97/100], Step [100/254], Loss: 0.3988, Accuracy: 0.8906\n",
      "Epoch [97/100], Step [200/254], Loss: 0.6282, Accuracy: 0.7812\n",
      "Epoch [97/100], Train Loss: 0.5847, Val Loss: 0.5313, Train Acc: 0.7934, Val Acc: 0.8200\n",
      "==================================================\n",
      "Epoch [98/100], Step [0/254], Loss: 0.6521, Accuracy: 0.8125\n",
      "Epoch [98/100], Step [100/254], Loss: 0.4421, Accuracy: 0.8594\n",
      "Epoch [98/100], Step [200/254], Loss: 0.6615, Accuracy: 0.7031\n",
      "Epoch [98/100], Train Loss: 0.5867, Val Loss: 0.5624, Train Acc: 0.7938, Val Acc: 0.8192\n",
      "==================================================\n",
      "Epoch [99/100], Step [0/254], Loss: 0.5662, Accuracy: 0.7969\n",
      "Epoch [99/100], Step [100/254], Loss: 0.5605, Accuracy: 0.7344\n",
      "Epoch [99/100], Step [200/254], Loss: 0.5845, Accuracy: 0.7969\n",
      "Epoch [99/100], Train Loss: 0.5809, Val Loss: 0.5084, Train Acc: 0.7932, Val Acc: 0.8210\n",
      "==================================================\n",
      "Epoch [100/100], Step [0/254], Loss: 0.5593, Accuracy: 0.7500\n",
      "Epoch [100/100], Step [100/254], Loss: 0.6577, Accuracy: 0.7656\n",
      "Epoch [100/100], Step [200/254], Loss: 0.4851, Accuracy: 0.8125\n",
      "Epoch [100/100], Train Loss: 0.5815, Val Loss: 0.6370, Train Acc: 0.7925, Val Acc: 0.8236\n",
      "==================================================\n",
      "CPU times: user 13h 36min 56s, sys: 27min 19s, total: 14h 4min 16s\n",
      "Wall time: 1h 46min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MobileNetV3(\n",
    "    in_chn=3,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "train(model, device, trainLoader, valLoader, criterion, optimizer, n_epochs, earlyStopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suitable learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/254], Loss: 2.3072, Accuracy: 0.0938\n",
      "Epoch [1/100], Step [100/254], Loss: 1.0484, Accuracy: 0.5625\n",
      "Epoch [1/100], Step [200/254], Loss: 1.0228, Accuracy: 0.5938\n",
      "Epoch [1/100], Train Loss: 1.2454, Val Loss: 2.6897, Train Acc: 0.5452, Val Acc: 0.0738\n",
      "==================================================\n",
      "Epoch [2/100], Step [0/254], Loss: 0.8372, Accuracy: 0.7344\n",
      "Epoch [2/100], Step [100/254], Loss: 0.8029, Accuracy: 0.7031\n",
      "Epoch [2/100], Step [200/254], Loss: 0.8599, Accuracy: 0.7031\n",
      "Epoch [2/100], Train Loss: 0.8802, Val Loss: 1.8130, Train Acc: 0.6821, Val Acc: 0.4188\n",
      "==================================================\n",
      "Epoch [3/100], Step [0/254], Loss: 0.6136, Accuracy: 0.7656\n",
      "Epoch [3/100], Step [100/254], Loss: 1.1179, Accuracy: 0.5625\n",
      "Epoch [3/100], Step [200/254], Loss: 1.0394, Accuracy: 0.5938\n",
      "Epoch [3/100], Train Loss: 0.7825, Val Loss: 0.9701, Train Acc: 0.7217, Val Acc: 0.6691\n",
      "==================================================\n",
      "Epoch [4/100], Step [0/254], Loss: 0.6884, Accuracy: 0.7656\n",
      "Epoch [4/100], Step [100/254], Loss: 0.5601, Accuracy: 0.8438\n",
      "Epoch [4/100], Step [200/254], Loss: 0.7354, Accuracy: 0.7188\n",
      "Epoch [4/100], Train Loss: 0.7177, Val Loss: 0.9285, Train Acc: 0.7442, Val Acc: 0.6704\n",
      "==================================================\n",
      "Epoch [5/100], Step [0/254], Loss: 0.6905, Accuracy: 0.6875\n",
      "Epoch [5/100], Step [100/254], Loss: 0.5127, Accuracy: 0.8438\n",
      "Epoch [5/100], Step [200/254], Loss: 0.7640, Accuracy: 0.6875\n",
      "Epoch [5/100], Train Loss: 0.6601, Val Loss: 0.7512, Train Acc: 0.7720, Val Acc: 0.7344\n",
      "==================================================\n",
      "Epoch [6/100], Step [0/254], Loss: 0.7690, Accuracy: 0.7344\n",
      "Epoch [6/100], Step [100/254], Loss: 0.6458, Accuracy: 0.8125\n",
      "Epoch [6/100], Step [200/254], Loss: 0.5371, Accuracy: 0.7344\n",
      "Epoch [6/100], Train Loss: 0.6055, Val Loss: 0.8701, Train Acc: 0.7894, Val Acc: 0.7030\n",
      "==================================================\n",
      "Epoch [7/100], Step [0/254], Loss: 0.5375, Accuracy: 0.8438\n",
      "Epoch [7/100], Step [100/254], Loss: 0.6435, Accuracy: 0.7969\n",
      "Epoch [7/100], Step [200/254], Loss: 0.5378, Accuracy: 0.8750\n",
      "Epoch [7/100], Train Loss: 0.5400, Val Loss: 0.6500, Train Acc: 0.8118, Val Acc: 0.7887\n",
      "==================================================\n",
      "Epoch [8/100], Step [0/254], Loss: 0.4778, Accuracy: 0.8125\n",
      "Epoch [8/100], Step [100/254], Loss: 0.3636, Accuracy: 0.8906\n",
      "Epoch [8/100], Step [200/254], Loss: 0.5292, Accuracy: 0.7656\n",
      "Epoch [8/100], Train Loss: 0.5026, Val Loss: 0.6610, Train Acc: 0.8239, Val Acc: 0.7752\n",
      "==================================================\n",
      "Epoch [9/100], Step [0/254], Loss: 0.4748, Accuracy: 0.8438\n",
      "Epoch [9/100], Step [100/254], Loss: 0.5434, Accuracy: 0.8594\n",
      "Epoch [9/100], Step [200/254], Loss: 0.3227, Accuracy: 0.8594\n",
      "Epoch [9/100], Train Loss: 0.4870, Val Loss: 1.1424, Train Acc: 0.8292, Val Acc: 0.6677\n",
      "==================================================\n",
      "Epoch [10/100], Step [0/254], Loss: 0.6286, Accuracy: 0.8125\n",
      "Epoch [10/100], Step [100/254], Loss: 0.4730, Accuracy: 0.8594\n",
      "Epoch [10/100], Step [200/254], Loss: 0.4289, Accuracy: 0.8281\n",
      "Epoch [10/100], Train Loss: 0.4783, Val Loss: 0.5818, Train Acc: 0.8370, Val Acc: 0.8032\n",
      "==================================================\n",
      "Epoch [11/100], Step [0/254], Loss: 0.3883, Accuracy: 0.9219\n",
      "Epoch [11/100], Step [100/254], Loss: 0.4641, Accuracy: 0.8594\n",
      "Epoch [11/100], Step [200/254], Loss: 0.4735, Accuracy: 0.8594\n",
      "Epoch [11/100], Train Loss: 0.4435, Val Loss: 0.8402, Train Acc: 0.8473, Val Acc: 0.7328\n",
      "==================================================\n",
      "Epoch [12/100], Step [0/254], Loss: 0.3551, Accuracy: 0.8906\n",
      "Epoch [12/100], Step [100/254], Loss: 0.4965, Accuracy: 0.8281\n",
      "Epoch [12/100], Step [200/254], Loss: 0.5826, Accuracy: 0.7969\n",
      "Epoch [12/100], Train Loss: 0.4224, Val Loss: 0.8357, Train Acc: 0.8519, Val Acc: 0.7341\n",
      "==================================================\n",
      "Epoch [13/100], Step [0/254], Loss: 0.4588, Accuracy: 0.8438\n",
      "Epoch [13/100], Step [100/254], Loss: 0.3655, Accuracy: 0.8906\n",
      "Epoch [13/100], Step [200/254], Loss: 0.3618, Accuracy: 0.8594\n",
      "Epoch [13/100], Train Loss: 0.4173, Val Loss: 1.1962, Train Acc: 0.8557, Val Acc: 0.6791\n",
      "==================================================\n",
      "Epoch [14/100], Step [0/254], Loss: 0.3439, Accuracy: 0.9219\n",
      "Epoch [14/100], Step [100/254], Loss: 0.5031, Accuracy: 0.8594\n",
      "Epoch [14/100], Step [200/254], Loss: 0.2615, Accuracy: 0.9219\n",
      "Epoch [14/100], Train Loss: 0.3983, Val Loss: 0.9087, Train Acc: 0.8623, Val Acc: 0.7277\n",
      "==================================================\n",
      "Epoch [15/100], Step [0/254], Loss: 0.1705, Accuracy: 0.9531\n",
      "Epoch [15/100], Step [100/254], Loss: 0.3730, Accuracy: 0.8125\n",
      "Epoch [15/100], Step [200/254], Loss: 0.3357, Accuracy: 0.9062\n",
      "Epoch [15/100], Train Loss: 0.3214, Val Loss: 0.2785, Train Acc: 0.8909, Val Acc: 0.9027\n",
      "==================================================\n",
      "Epoch [16/100], Step [0/254], Loss: 0.2071, Accuracy: 0.9062\n",
      "Epoch [16/100], Step [100/254], Loss: 0.3274, Accuracy: 0.8125\n",
      "Epoch [16/100], Step [200/254], Loss: 0.3276, Accuracy: 0.9062\n",
      "Epoch [16/100], Train Loss: 0.3180, Val Loss: 0.2514, Train Acc: 0.8891, Val Acc: 0.9126\n",
      "==================================================\n",
      "Epoch [17/100], Step [0/254], Loss: 0.3958, Accuracy: 0.8594\n",
      "Epoch [17/100], Step [100/254], Loss: 0.2836, Accuracy: 0.8750\n",
      "Epoch [17/100], Step [200/254], Loss: 0.2850, Accuracy: 0.9219\n",
      "Epoch [17/100], Train Loss: 0.2904, Val Loss: 0.3043, Train Acc: 0.8997, Val Acc: 0.8946\n",
      "==================================================\n",
      "Epoch [18/100], Step [0/254], Loss: 0.3141, Accuracy: 0.8906\n",
      "Epoch [18/100], Step [100/254], Loss: 0.3740, Accuracy: 0.8594\n",
      "Epoch [18/100], Step [200/254], Loss: 0.2675, Accuracy: 0.9062\n",
      "Epoch [18/100], Train Loss: 0.2949, Val Loss: 0.2396, Train Acc: 0.8980, Val Acc: 0.9158\n",
      "==================================================\n",
      "Epoch [19/100], Step [0/254], Loss: 0.2294, Accuracy: 0.9375\n",
      "Epoch [19/100], Step [100/254], Loss: 0.2178, Accuracy: 0.9062\n",
      "Epoch [19/100], Step [200/254], Loss: 0.3623, Accuracy: 0.8906\n",
      "Epoch [19/100], Train Loss: 0.2931, Val Loss: 0.2366, Train Acc: 0.8973, Val Acc: 0.9173\n",
      "==================================================\n",
      "Epoch [20/100], Step [0/254], Loss: 0.2337, Accuracy: 0.8906\n",
      "Epoch [20/100], Step [100/254], Loss: 0.2776, Accuracy: 0.8906\n",
      "Epoch [20/100], Step [200/254], Loss: 0.2996, Accuracy: 0.9062\n",
      "Epoch [20/100], Train Loss: 0.2748, Val Loss: 0.2584, Train Acc: 0.9003, Val Acc: 0.9072\n",
      "==================================================\n",
      "Epoch [21/100], Step [0/254], Loss: 0.2387, Accuracy: 0.9062\n",
      "Epoch [21/100], Step [100/254], Loss: 0.3131, Accuracy: 0.8906\n",
      "Epoch [21/100], Step [200/254], Loss: 0.1921, Accuracy: 0.9375\n",
      "Epoch [21/100], Train Loss: 0.2794, Val Loss: 0.2701, Train Acc: 0.9003, Val Acc: 0.9019\n",
      "==================================================\n",
      "Epoch [22/100], Step [0/254], Loss: 0.2271, Accuracy: 0.9375\n",
      "Epoch [22/100], Step [100/254], Loss: 0.2992, Accuracy: 0.9219\n",
      "Epoch [22/100], Step [200/254], Loss: 0.2738, Accuracy: 0.8438\n",
      "Epoch [22/100], Train Loss: 0.2803, Val Loss: 0.2978, Train Acc: 0.9029, Val Acc: 0.8959\n",
      "==================================================\n",
      "Epoch [23/100], Step [0/254], Loss: 0.3045, Accuracy: 0.9219\n",
      "Epoch [23/100], Step [100/254], Loss: 0.1317, Accuracy: 0.9844\n",
      "Epoch [23/100], Step [200/254], Loss: 0.4783, Accuracy: 0.8438\n",
      "Epoch [23/100], Train Loss: 0.2767, Val Loss: 0.2840, Train Acc: 0.9034, Val Acc: 0.8987\n",
      "==================================================\n",
      "Epoch [24/100], Step [0/254], Loss: 0.3763, Accuracy: 0.8594\n",
      "Epoch [24/100], Step [100/254], Loss: 0.2645, Accuracy: 0.9062\n",
      "Epoch [24/100], Step [200/254], Loss: 0.3573, Accuracy: 0.8906\n",
      "Epoch [24/100], Train Loss: 0.2544, Val Loss: 0.2016, Train Acc: 0.9126, Val Acc: 0.9310\n",
      "==================================================\n",
      "Epoch [25/100], Step [0/254], Loss: 0.2131, Accuracy: 0.9219\n",
      "Epoch [25/100], Step [100/254], Loss: 0.3422, Accuracy: 0.8750\n",
      "Epoch [25/100], Step [200/254], Loss: 0.2214, Accuracy: 0.9219\n",
      "Epoch [25/100], Train Loss: 0.2535, Val Loss: 0.2027, Train Acc: 0.9117, Val Acc: 0.9288\n",
      "==================================================\n",
      "Epoch [26/100], Step [0/254], Loss: 0.2572, Accuracy: 0.9375\n",
      "Epoch [26/100], Step [100/254], Loss: 0.2010, Accuracy: 0.9375\n",
      "Epoch [26/100], Step [200/254], Loss: 0.1930, Accuracy: 0.9062\n",
      "Epoch [26/100], Train Loss: 0.2552, Val Loss: 0.1982, Train Acc: 0.9115, Val Acc: 0.9314\n",
      "==================================================\n",
      "Epoch [27/100], Step [0/254], Loss: 0.2434, Accuracy: 0.9062\n",
      "Epoch [27/100], Step [100/254], Loss: 0.3207, Accuracy: 0.8906\n",
      "Epoch [27/100], Step [200/254], Loss: 0.2551, Accuracy: 0.9219\n",
      "Epoch [27/100], Train Loss: 0.2550, Val Loss: 0.2002, Train Acc: 0.9099, Val Acc: 0.9307\n",
      "==================================================\n",
      "Epoch [28/100], Step [0/254], Loss: 0.1346, Accuracy: 0.9688\n",
      "Epoch [28/100], Step [100/254], Loss: 0.3005, Accuracy: 0.9062\n",
      "Epoch [28/100], Step [200/254], Loss: 0.2363, Accuracy: 0.9531\n",
      "Epoch [28/100], Train Loss: 0.2543, Val Loss: 0.2017, Train Acc: 0.9115, Val Acc: 0.9283\n",
      "==================================================\n",
      "Epoch [29/100], Step [0/254], Loss: 0.3009, Accuracy: 0.8906\n",
      "Epoch [29/100], Step [100/254], Loss: 0.1321, Accuracy: 0.9531\n",
      "Epoch [29/100], Step [200/254], Loss: 0.2629, Accuracy: 0.8750\n",
      "Epoch [29/100], Train Loss: 0.2451, Val Loss: 0.1994, Train Acc: 0.9161, Val Acc: 0.9313\n",
      "==================================================\n",
      "Epoch [30/100], Step [0/254], Loss: 0.2534, Accuracy: 0.8906\n",
      "Epoch [30/100], Step [100/254], Loss: 0.1515, Accuracy: 0.9531\n",
      "Epoch [30/100], Step [200/254], Loss: 0.1481, Accuracy: 0.9531\n",
      "Epoch [30/100], Train Loss: 0.2387, Val Loss: 0.2011, Train Acc: 0.9144, Val Acc: 0.9292\n",
      "==================================================\n",
      "Epoch [31/100], Step [0/254], Loss: 0.3147, Accuracy: 0.9062\n",
      "Epoch [31/100], Step [100/254], Loss: 0.2660, Accuracy: 0.9062\n",
      "Epoch [31/100], Step [200/254], Loss: 0.2833, Accuracy: 0.8594\n",
      "Epoch [31/100], Train Loss: 0.2390, Val Loss: 0.1931, Train Acc: 0.9144, Val Acc: 0.9310\n",
      "==================================================\n",
      "Epoch [32/100], Step [0/254], Loss: 0.1753, Accuracy: 0.9219\n",
      "Epoch [32/100], Step [100/254], Loss: 0.1655, Accuracy: 0.9531\n",
      "Epoch [32/100], Step [200/254], Loss: 0.3050, Accuracy: 0.8750\n",
      "Epoch [32/100], Train Loss: 0.2350, Val Loss: 0.1876, Train Acc: 0.9155, Val Acc: 0.9342\n",
      "==================================================\n",
      "Epoch [33/100], Step [0/254], Loss: 0.2917, Accuracy: 0.8906\n",
      "Epoch [33/100], Step [100/254], Loss: 0.2869, Accuracy: 0.8906\n",
      "Epoch [33/100], Step [200/254], Loss: 0.4849, Accuracy: 0.8438\n",
      "Epoch [33/100], Train Loss: 0.2413, Val Loss: 0.1958, Train Acc: 0.9160, Val Acc: 0.9320\n",
      "==================================================\n",
      "Epoch [34/100], Step [0/254], Loss: 0.3046, Accuracy: 0.9062\n",
      "Epoch [34/100], Step [100/254], Loss: 0.2740, Accuracy: 0.8906\n",
      "Epoch [34/100], Step [200/254], Loss: 0.1667, Accuracy: 0.9375\n",
      "Epoch [34/100], Train Loss: 0.2459, Val Loss: 0.1920, Train Acc: 0.9166, Val Acc: 0.9320\n",
      "==================================================\n",
      "Epoch [35/100], Step [0/254], Loss: 0.3366, Accuracy: 0.8906\n",
      "Epoch [35/100], Step [100/254], Loss: 0.1567, Accuracy: 0.9375\n",
      "Epoch [35/100], Step [200/254], Loss: 0.1280, Accuracy: 0.9688\n",
      "Epoch [35/100], Train Loss: 0.2405, Val Loss: 0.1922, Train Acc: 0.9154, Val Acc: 0.9320\n",
      "==================================================\n",
      "Epoch [36/100], Step [0/254], Loss: 0.2132, Accuracy: 0.9531\n",
      "Epoch [36/100], Step [100/254], Loss: 0.2200, Accuracy: 0.9375\n",
      "Epoch [36/100], Step [200/254], Loss: 0.1648, Accuracy: 0.9531\n",
      "Epoch [36/100], Train Loss: 0.2374, Val Loss: 0.1903, Train Acc: 0.9148, Val Acc: 0.9333\n",
      "==================================================\n",
      "Epoch [37/100], Step [0/254], Loss: 0.3446, Accuracy: 0.8750\n",
      "Epoch [37/100], Step [100/254], Loss: 0.2920, Accuracy: 0.9062\n",
      "Epoch [37/100], Step [200/254], Loss: 0.2941, Accuracy: 0.9219\n",
      "Epoch [37/100], Train Loss: 0.2327, Val Loss: 0.1898, Train Acc: 0.9205, Val Acc: 0.9317\n",
      "==================================================\n",
      "Epoch [38/100], Step [0/254], Loss: 0.2396, Accuracy: 0.9219\n",
      "Epoch [38/100], Step [100/254], Loss: 0.1761, Accuracy: 0.9531\n",
      "Epoch [38/100], Step [200/254], Loss: 0.2282, Accuracy: 0.8906\n",
      "Epoch [38/100], Train Loss: 0.2425, Val Loss: 0.1881, Train Acc: 0.9164, Val Acc: 0.9337\n",
      "==================================================\n",
      "Epoch [39/100], Step [0/254], Loss: 0.1383, Accuracy: 0.9531\n",
      "Epoch [39/100], Step [100/254], Loss: 0.1937, Accuracy: 0.9531\n",
      "Epoch [39/100], Step [200/254], Loss: 0.1854, Accuracy: 0.9219\n",
      "Epoch [39/100], Train Loss: 0.2338, Val Loss: 0.1933, Train Acc: 0.9193, Val Acc: 0.9334\n",
      "==================================================\n",
      "Epoch [40/100], Step [0/254], Loss: 0.1407, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [100/254], Loss: 0.1830, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [200/254], Loss: 0.0544, Accuracy: 1.0000\n",
      "Epoch [40/100], Train Loss: 0.2339, Val Loss: 0.1866, Train Acc: 0.9158, Val Acc: 0.9343\n",
      "==================================================\n",
      "Epoch [41/100], Step [0/254], Loss: 0.3219, Accuracy: 0.8438\n",
      "Epoch [41/100], Step [100/254], Loss: 0.1101, Accuracy: 0.9688\n",
      "Epoch [41/100], Step [200/254], Loss: 0.3443, Accuracy: 0.7969\n",
      "Epoch [41/100], Train Loss: 0.2366, Val Loss: 0.1900, Train Acc: 0.9157, Val Acc: 0.9322\n",
      "==================================================\n",
      "Epoch [42/100], Step [0/254], Loss: 0.3968, Accuracy: 0.8438\n",
      "Epoch [42/100], Step [100/254], Loss: 0.1383, Accuracy: 0.9531\n",
      "Epoch [42/100], Step [200/254], Loss: 0.2318, Accuracy: 0.9062\n",
      "Epoch [42/100], Train Loss: 0.2327, Val Loss: 0.1859, Train Acc: 0.9178, Val Acc: 0.9341\n",
      "==================================================\n",
      "Epoch [43/100], Step [0/254], Loss: 0.2036, Accuracy: 0.9219\n",
      "Epoch [43/100], Step [100/254], Loss: 0.1260, Accuracy: 0.9531\n",
      "Epoch [43/100], Step [200/254], Loss: 0.1569, Accuracy: 0.9219\n",
      "Epoch [43/100], Train Loss: 0.2293, Val Loss: 0.1893, Train Acc: 0.9198, Val Acc: 0.9320\n",
      "==================================================\n",
      "Epoch [44/100], Step [0/254], Loss: 0.2128, Accuracy: 0.9375\n",
      "Epoch [44/100], Step [100/254], Loss: 0.1967, Accuracy: 0.9375\n",
      "Epoch [44/100], Step [200/254], Loss: 0.2945, Accuracy: 0.8906\n",
      "Epoch [44/100], Train Loss: 0.2402, Val Loss: 0.1888, Train Acc: 0.9153, Val Acc: 0.9341\n",
      "==================================================\n",
      "Epoch [45/100], Step [0/254], Loss: 0.2727, Accuracy: 0.9375\n",
      "Epoch [45/100], Step [100/254], Loss: 0.2621, Accuracy: 0.9062\n",
      "Epoch [45/100], Step [200/254], Loss: 0.2536, Accuracy: 0.8750\n",
      "Epoch [45/100], Train Loss: 0.2388, Val Loss: 0.1865, Train Acc: 0.9174, Val Acc: 0.9339\n",
      "==================================================\n",
      "Epoch [46/100], Step [0/254], Loss: 0.1203, Accuracy: 0.9531\n",
      "Epoch [46/100], Step [100/254], Loss: 0.3206, Accuracy: 0.8906\n",
      "Epoch [46/100], Step [200/254], Loss: 0.1534, Accuracy: 0.9375\n",
      "Epoch [46/100], Train Loss: 0.2335, Val Loss: 0.1906, Train Acc: 0.9187, Val Acc: 0.9340\n",
      "==================================================\n",
      "Epoch [47/100], Step [0/254], Loss: 0.1638, Accuracy: 0.9219\n",
      "Epoch [47/100], Step [100/254], Loss: 0.2005, Accuracy: 0.9375\n",
      "Epoch [47/100], Step [200/254], Loss: 0.2517, Accuracy: 0.9375\n",
      "Epoch [47/100], Train Loss: 0.2378, Val Loss: 0.1906, Train Acc: 0.9151, Val Acc: 0.9328\n",
      "==================================================\n",
      "Epoch [48/100], Step [0/254], Loss: 0.2845, Accuracy: 0.9219\n",
      "Epoch [48/100], Step [100/254], Loss: 0.2500, Accuracy: 0.8906\n",
      "Epoch [48/100], Step [200/254], Loss: 0.2160, Accuracy: 0.9375\n",
      "Epoch [48/100], Train Loss: 0.2292, Val Loss: 0.1882, Train Acc: 0.9193, Val Acc: 0.9337\n",
      "==================================================\n",
      "Epoch [49/100], Step [0/254], Loss: 0.1194, Accuracy: 0.9688\n",
      "Epoch [49/100], Step [100/254], Loss: 0.2957, Accuracy: 0.8750\n",
      "Epoch [49/100], Step [200/254], Loss: 0.1118, Accuracy: 0.9844\n",
      "Epoch [49/100], Train Loss: 0.2313, Val Loss: 0.1892, Train Acc: 0.9192, Val Acc: 0.9338\n",
      "==================================================\n",
      "Epoch [50/100], Step [0/254], Loss: 0.2657, Accuracy: 0.9062\n",
      "Epoch [50/100], Step [100/254], Loss: 0.3312, Accuracy: 0.8594\n",
      "Epoch [50/100], Step [200/254], Loss: 0.2511, Accuracy: 0.9375\n",
      "Epoch [50/100], Train Loss: 0.2339, Val Loss: 0.1896, Train Acc: 0.9179, Val Acc: 0.9352\n",
      "==================================================\n",
      "Epoch [51/100], Step [0/254], Loss: 0.1479, Accuracy: 0.9844\n",
      "Epoch [51/100], Step [100/254], Loss: 0.1713, Accuracy: 0.9375\n",
      "Epoch [51/100], Step [200/254], Loss: 0.2883, Accuracy: 0.9062\n",
      "Epoch [51/100], Train Loss: 0.2348, Val Loss: 0.1870, Train Acc: 0.9197, Val Acc: 0.9346\n",
      "==================================================\n",
      "Epoch [52/100], Step [0/254], Loss: 0.1791, Accuracy: 0.9219\n",
      "Epoch [52/100], Step [100/254], Loss: 0.2353, Accuracy: 0.9375\n",
      "Epoch [52/100], Step [200/254], Loss: 0.3412, Accuracy: 0.8750\n",
      "Epoch [52/100], Train Loss: 0.2392, Val Loss: 0.1895, Train Acc: 0.9157, Val Acc: 0.9331\n",
      "==================================================\n",
      "Epoch [53/100], Step [0/254], Loss: 0.4188, Accuracy: 0.8438\n",
      "Epoch [53/100], Step [100/254], Loss: 0.2291, Accuracy: 0.9219\n",
      "Epoch [53/100], Step [200/254], Loss: 0.3609, Accuracy: 0.8281\n",
      "Epoch [53/100], Train Loss: 0.2262, Val Loss: 0.1862, Train Acc: 0.9189, Val Acc: 0.9363\n",
      "==================================================\n",
      "CPU times: user 7h 10min 17s, sys: 14min 17s, total: 7h 24min 35s\n",
      "Wall time: 56min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MobileNetV3(\n",
    "    in_chn=3,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train(model, device, trainLoader, valLoader, criterion, optimizer, n_epochs, earlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.5 s, sys: 911 ms, total: 28.4 s\n",
      "Wall time: 3.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred, actual = infer(model, device, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9209\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = (torch.argmax(pred, dim=1) == actual).float().mean()\n",
    "print(f\"Test Accuracy: {acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using GELU instead of hard swish in bottleneck block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import GELU\n",
    "\n",
    "\n",
    "class MobileNetV3Gelu(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chn,\n",
    "        se_reduction=4,\n",
    "        mode=\"small\",\n",
    "        num_classes=10,\n",
    "        bn_eps=0.001,\n",
    "        bn_momentum=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if mode == \"small\":\n",
    "            # MobileNetV3-Small\n",
    "            layers_config = [\n",
    "                [3, 16, 16, True, ReLU, 2],\n",
    "                [3, 72, 24, False, ReLU, 2],\n",
    "                [3, 88, 24, False, ReLU, 1],\n",
    "                [5, 96, 40, True, GELU, 2],\n",
    "                [5, 240, 40, True, GELU, 1],\n",
    "                [5, 240, 40, True, GELU, 1],\n",
    "                [5, 120, 48, True, GELU, 1],\n",
    "                [5, 144, 48, True, GELU, 1],\n",
    "                [5, 288, 96, True, GELU, 2],\n",
    "                [5, 576, 96, True, GELU, 1],\n",
    "                [5, 576, 96, True, GELU, 1],\n",
    "            ]\n",
    "            last_channel = 1280\n",
    "            # final layer\n",
    "            self.final_layers = [\n",
    "                ConvBlock(\n",
    "                    layers_config[-1][2], 576, activation=Hardswish, kernel_size=1\n",
    "                ),\n",
    "                SqueezeAndExcite(576, se_reduction),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(576, last_channel, 1),\n",
    "                Hardswish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(last_channel, num_classes),\n",
    "            ]\n",
    "\n",
    "        # Initial layers\n",
    "        self.features: list[nn.Module] = [\n",
    "            ConvBlock(in_chn, 16, activation=Hardswish, kernel_size=3, stride=2)\n",
    "        ]\n",
    "        #         print(dir(self.features[-1]))\n",
    "\n",
    "        # Build main blocks\n",
    "\n",
    "        input_channel = 16\n",
    "        for kernel, exp, out, se, act, stride in layers_config:\n",
    "            self.features.append(\n",
    "                BottleNeck(\n",
    "                    in_chn=input_channel,\n",
    "                    out_chn=out,\n",
    "                    expansion_channel=exp,\n",
    "                    activation=act,\n",
    "                    kernel=kernel,\n",
    "                    se_flag=se,\n",
    "                    stride=stride,\n",
    "                )\n",
    "            )\n",
    "            input_channel = out\n",
    "\n",
    "        self.start = nn.Sequential(*self.features)\n",
    "        self.final = nn.Sequential(*self.final_layers)\n",
    "\n",
    "        # modify batchnorm layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eps = bn_eps\n",
    "                m.momentum = bn_momentum\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/254], Loss: 2.3033, Accuracy: 0.0781\n",
      "Epoch [1/100], Step [100/254], Loss: 1.1713, Accuracy: 0.5469\n",
      "Epoch [1/100], Step [200/254], Loss: 0.8708, Accuracy: 0.6875\n",
      "Epoch [1/100], Train Loss: 1.3328, Val Loss: 2.7721, Train Acc: 0.5068, Val Acc: 0.0738\n",
      "==================================================\n",
      "Epoch [2/100], Step [0/254], Loss: 0.9396, Accuracy: 0.6406\n",
      "Epoch [2/100], Step [100/254], Loss: 0.9380, Accuracy: 0.6094\n",
      "Epoch [2/100], Step [200/254], Loss: 0.6081, Accuracy: 0.7969\n",
      "Epoch [2/100], Train Loss: 0.9541, Val Loss: 2.4884, Train Acc: 0.6583, Val Acc: 0.3290\n",
      "==================================================\n",
      "Epoch [3/100], Step [0/254], Loss: 0.9162, Accuracy: 0.7031\n",
      "Epoch [3/100], Step [100/254], Loss: 0.7114, Accuracy: 0.7969\n",
      "Epoch [3/100], Step [200/254], Loss: 0.6410, Accuracy: 0.7031\n",
      "Epoch [3/100], Train Loss: 0.8251, Val Loss: 0.8028, Train Acc: 0.7052, Val Acc: 0.6998\n",
      "==================================================\n",
      "Epoch [4/100], Step [0/254], Loss: 0.5372, Accuracy: 0.7500\n",
      "Epoch [4/100], Step [100/254], Loss: 0.7678, Accuracy: 0.7188\n",
      "Epoch [4/100], Step [200/254], Loss: 0.7533, Accuracy: 0.6875\n",
      "Epoch [4/100], Train Loss: 0.7559, Val Loss: 0.7327, Train Acc: 0.7268, Val Acc: 0.7435\n",
      "==================================================\n",
      "Epoch [5/100], Step [0/254], Loss: 0.8675, Accuracy: 0.7500\n",
      "Epoch [5/100], Step [100/254], Loss: 0.7461, Accuracy: 0.7656\n",
      "Epoch [5/100], Step [200/254], Loss: 0.6199, Accuracy: 0.7344\n",
      "Epoch [5/100], Train Loss: 0.7034, Val Loss: 0.7963, Train Acc: 0.7432, Val Acc: 0.7172\n",
      "==================================================\n",
      "Epoch [6/100], Step [0/254], Loss: 0.6669, Accuracy: 0.8125\n",
      "Epoch [6/100], Step [100/254], Loss: 0.6084, Accuracy: 0.7500\n",
      "Epoch [6/100], Step [200/254], Loss: 0.5991, Accuracy: 0.7656\n",
      "Epoch [6/100], Train Loss: 0.6647, Val Loss: 0.6373, Train Acc: 0.7619, Val Acc: 0.7736\n",
      "==================================================\n",
      "Epoch [7/100], Step [0/254], Loss: 0.4884, Accuracy: 0.8281\n",
      "Epoch [7/100], Step [100/254], Loss: 0.5503, Accuracy: 0.7969\n",
      "Epoch [7/100], Step [200/254], Loss: 0.6819, Accuracy: 0.8125\n",
      "Epoch [7/100], Train Loss: 0.6277, Val Loss: 0.6062, Train Acc: 0.7779, Val Acc: 0.7853\n",
      "==================================================\n",
      "Epoch [8/100], Step [0/254], Loss: 0.8799, Accuracy: 0.6250\n",
      "Epoch [8/100], Step [100/254], Loss: 0.7236, Accuracy: 0.7188\n",
      "Epoch [8/100], Step [200/254], Loss: 0.7517, Accuracy: 0.7656\n",
      "Epoch [8/100], Train Loss: 0.5984, Val Loss: 0.5254, Train Acc: 0.7883, Val Acc: 0.8131\n",
      "==================================================\n",
      "Epoch [9/100], Step [0/254], Loss: 0.4241, Accuracy: 0.8438\n",
      "Epoch [9/100], Step [100/254], Loss: 0.7515, Accuracy: 0.7344\n",
      "Epoch [9/100], Step [200/254], Loss: 0.5331, Accuracy: 0.8438\n",
      "Epoch [9/100], Train Loss: 0.5600, Val Loss: 0.5039, Train Acc: 0.8043, Val Acc: 0.8192\n",
      "==================================================\n",
      "Epoch [10/100], Step [0/254], Loss: 0.6197, Accuracy: 0.7500\n",
      "Epoch [10/100], Step [100/254], Loss: 0.6569, Accuracy: 0.7969\n",
      "Epoch [10/100], Step [200/254], Loss: 0.4425, Accuracy: 0.8594\n",
      "Epoch [10/100], Train Loss: 0.5235, Val Loss: 0.5324, Train Acc: 0.8166, Val Acc: 0.8109\n",
      "==================================================\n",
      "Epoch [11/100], Step [0/254], Loss: 0.5134, Accuracy: 0.8281\n",
      "Epoch [11/100], Step [100/254], Loss: 0.2840, Accuracy: 0.8906\n",
      "Epoch [11/100], Step [200/254], Loss: 0.5335, Accuracy: 0.7969\n",
      "Epoch [11/100], Train Loss: 0.5073, Val Loss: 0.5313, Train Acc: 0.8211, Val Acc: 0.8144\n",
      "==================================================\n",
      "Epoch [12/100], Step [0/254], Loss: 0.6650, Accuracy: 0.8281\n",
      "Epoch [12/100], Step [100/254], Loss: 0.4255, Accuracy: 0.7969\n",
      "Epoch [12/100], Step [200/254], Loss: 0.3019, Accuracy: 0.8906\n",
      "Epoch [12/100], Train Loss: 0.4755, Val Loss: 0.4709, Train Acc: 0.8337, Val Acc: 0.8290\n",
      "==================================================\n",
      "Epoch [13/100], Step [0/254], Loss: 0.3078, Accuracy: 0.8906\n",
      "Epoch [13/100], Step [100/254], Loss: 0.4643, Accuracy: 0.8594\n",
      "Epoch [13/100], Step [200/254], Loss: 0.3071, Accuracy: 0.8906\n",
      "Epoch [13/100], Train Loss: 0.4549, Val Loss: 0.7729, Train Acc: 0.8420, Val Acc: 0.7636\n",
      "==================================================\n",
      "Epoch [14/100], Step [0/254], Loss: 0.5483, Accuracy: 0.8281\n",
      "Epoch [14/100], Step [100/254], Loss: 0.5515, Accuracy: 0.7812\n",
      "Epoch [14/100], Step [200/254], Loss: 0.4220, Accuracy: 0.8750\n",
      "Epoch [14/100], Train Loss: 0.4333, Val Loss: 0.5930, Train Acc: 0.8500, Val Acc: 0.8056\n",
      "==================================================\n",
      "Epoch [15/100], Step [0/254], Loss: 0.4207, Accuracy: 0.8438\n",
      "Epoch [15/100], Step [100/254], Loss: 0.5190, Accuracy: 0.8281\n",
      "Epoch [15/100], Step [200/254], Loss: 0.3159, Accuracy: 0.8750\n",
      "Epoch [15/100], Train Loss: 0.4224, Val Loss: 0.4326, Train Acc: 0.8529, Val Acc: 0.8484\n",
      "==================================================\n",
      "Epoch [16/100], Step [0/254], Loss: 0.4592, Accuracy: 0.8281\n",
      "Epoch [16/100], Step [100/254], Loss: 0.3556, Accuracy: 0.8906\n",
      "Epoch [16/100], Step [200/254], Loss: 0.3848, Accuracy: 0.8594\n",
      "Epoch [16/100], Train Loss: 0.4068, Val Loss: 0.4303, Train Acc: 0.8583, Val Acc: 0.8440\n",
      "==================================================\n",
      "Epoch [17/100], Step [0/254], Loss: 0.6311, Accuracy: 0.7500\n",
      "Epoch [17/100], Step [100/254], Loss: 0.4280, Accuracy: 0.8438\n",
      "Epoch [17/100], Step [200/254], Loss: 0.4045, Accuracy: 0.8750\n",
      "Epoch [17/100], Train Loss: 0.4125, Val Loss: 0.3344, Train Acc: 0.8598, Val Acc: 0.8832\n",
      "==================================================\n",
      "Epoch [18/100], Step [0/254], Loss: 0.3063, Accuracy: 0.8750\n",
      "Epoch [18/100], Step [100/254], Loss: 0.2570, Accuracy: 0.9375\n",
      "Epoch [18/100], Step [200/254], Loss: 0.2922, Accuracy: 0.8750\n",
      "Epoch [18/100], Train Loss: 0.3793, Val Loss: 0.4030, Train Acc: 0.8698, Val Acc: 0.8595\n",
      "==================================================\n",
      "Epoch [19/100], Step [0/254], Loss: 0.6014, Accuracy: 0.7812\n",
      "Epoch [19/100], Step [100/254], Loss: 0.5996, Accuracy: 0.7969\n",
      "Epoch [19/100], Step [200/254], Loss: 0.4629, Accuracy: 0.8125\n",
      "Epoch [19/100], Train Loss: 0.3792, Val Loss: 0.4030, Train Acc: 0.8703, Val Acc: 0.8607\n",
      "==================================================\n",
      "Epoch [20/100], Step [0/254], Loss: 0.2011, Accuracy: 0.9062\n",
      "Epoch [20/100], Step [100/254], Loss: 0.6373, Accuracy: 0.7656\n",
      "Epoch [20/100], Step [200/254], Loss: 0.3001, Accuracy: 0.9375\n",
      "Epoch [20/100], Train Loss: 0.3738, Val Loss: 0.3373, Train Acc: 0.8713, Val Acc: 0.8790\n",
      "==================================================\n",
      "Epoch [21/100], Step [0/254], Loss: 0.2598, Accuracy: 0.8750\n",
      "Epoch [21/100], Step [100/254], Loss: 0.2827, Accuracy: 0.8594\n",
      "Epoch [21/100], Step [200/254], Loss: 0.2544, Accuracy: 0.9219\n",
      "Epoch [21/100], Train Loss: 0.3571, Val Loss: 0.6994, Train Acc: 0.8776, Val Acc: 0.7604\n",
      "==================================================\n",
      "Epoch [22/100], Step [0/254], Loss: 0.4530, Accuracy: 0.8438\n",
      "Epoch [22/100], Step [100/254], Loss: 0.2333, Accuracy: 0.9219\n",
      "Epoch [22/100], Step [200/254], Loss: 0.5178, Accuracy: 0.8750\n",
      "Epoch [22/100], Train Loss: 0.3007, Val Loss: 0.2365, Train Acc: 0.8947, Val Acc: 0.9197\n",
      "==================================================\n",
      "Epoch [23/100], Step [0/254], Loss: 0.3380, Accuracy: 0.8906\n",
      "Epoch [23/100], Step [100/254], Loss: 0.3046, Accuracy: 0.9219\n",
      "Epoch [23/100], Step [200/254], Loss: 0.3232, Accuracy: 0.8750\n",
      "Epoch [23/100], Train Loss: 0.2897, Val Loss: 0.2551, Train Acc: 0.8986, Val Acc: 0.9081\n",
      "==================================================\n",
      "Epoch [24/100], Step [0/254], Loss: 0.3180, Accuracy: 0.9062\n",
      "Epoch [24/100], Step [100/254], Loss: 0.3652, Accuracy: 0.8594\n",
      "Epoch [24/100], Step [200/254], Loss: 0.4165, Accuracy: 0.8125\n",
      "Epoch [24/100], Train Loss: 0.2800, Val Loss: 0.2338, Train Acc: 0.8995, Val Acc: 0.9147\n",
      "==================================================\n",
      "Epoch [25/100], Step [0/254], Loss: 0.2559, Accuracy: 0.8750\n",
      "Epoch [25/100], Step [100/254], Loss: 0.3048, Accuracy: 0.9531\n",
      "Epoch [25/100], Step [200/254], Loss: 0.2553, Accuracy: 0.9219\n",
      "Epoch [25/100], Train Loss: 0.2805, Val Loss: 0.2202, Train Acc: 0.9030, Val Acc: 0.9227\n",
      "==================================================\n",
      "Epoch [26/100], Step [0/254], Loss: 0.2729, Accuracy: 0.9219\n",
      "Epoch [26/100], Step [100/254], Loss: 0.2497, Accuracy: 0.9219\n",
      "Epoch [26/100], Step [200/254], Loss: 0.2752, Accuracy: 0.8906\n",
      "Epoch [26/100], Train Loss: 0.2715, Val Loss: 0.2287, Train Acc: 0.9058, Val Acc: 0.9190\n",
      "==================================================\n",
      "Epoch [27/100], Step [0/254], Loss: 0.4233, Accuracy: 0.8906\n",
      "Epoch [27/100], Step [100/254], Loss: 0.2108, Accuracy: 0.9062\n",
      "Epoch [27/100], Step [200/254], Loss: 0.2452, Accuracy: 0.9062\n",
      "Epoch [27/100], Train Loss: 0.2681, Val Loss: 0.2243, Train Acc: 0.9037, Val Acc: 0.9196\n",
      "==================================================\n",
      "Epoch [28/100], Step [0/254], Loss: 0.3066, Accuracy: 0.8594\n",
      "Epoch [28/100], Step [100/254], Loss: 0.1755, Accuracy: 0.9688\n",
      "Epoch [28/100], Step [200/254], Loss: 0.2064, Accuracy: 0.9531\n",
      "Epoch [28/100], Train Loss: 0.2647, Val Loss: 0.2146, Train Acc: 0.9068, Val Acc: 0.9246\n",
      "==================================================\n",
      "Epoch [29/100], Step [0/254], Loss: 0.2219, Accuracy: 0.9062\n",
      "Epoch [29/100], Step [100/254], Loss: 0.3631, Accuracy: 0.8906\n",
      "Epoch [29/100], Step [200/254], Loss: 0.1891, Accuracy: 0.9375\n",
      "Epoch [29/100], Train Loss: 0.2654, Val Loss: 0.2216, Train Acc: 0.9061, Val Acc: 0.9211\n",
      "==================================================\n",
      "Epoch [30/100], Step [0/254], Loss: 0.1695, Accuracy: 0.9375\n",
      "Epoch [30/100], Step [100/254], Loss: 0.4278, Accuracy: 0.8750\n",
      "Epoch [30/100], Step [200/254], Loss: 0.3273, Accuracy: 0.8438\n",
      "Epoch [30/100], Train Loss: 0.2647, Val Loss: 0.2079, Train Acc: 0.9078, Val Acc: 0.9269\n",
      "==================================================\n",
      "Epoch [31/100], Step [0/254], Loss: 0.1827, Accuracy: 0.9688\n",
      "Epoch [31/100], Step [100/254], Loss: 0.2009, Accuracy: 0.9219\n",
      "Epoch [31/100], Step [200/254], Loss: 0.2131, Accuracy: 0.9062\n",
      "Epoch [31/100], Train Loss: 0.2605, Val Loss: 0.2287, Train Acc: 0.9066, Val Acc: 0.9169\n",
      "==================================================\n",
      "Epoch [32/100], Step [0/254], Loss: 0.2692, Accuracy: 0.9062\n",
      "Epoch [32/100], Step [100/254], Loss: 0.2252, Accuracy: 0.9219\n",
      "Epoch [32/100], Step [200/254], Loss: 0.4003, Accuracy: 0.8750\n",
      "Epoch [32/100], Train Loss: 0.2552, Val Loss: 0.2151, Train Acc: 0.9095, Val Acc: 0.9209\n",
      "==================================================\n",
      "Epoch [33/100], Step [0/254], Loss: 0.2553, Accuracy: 0.9219\n",
      "Epoch [33/100], Step [100/254], Loss: 0.1067, Accuracy: 0.9688\n",
      "Epoch [33/100], Step [200/254], Loss: 0.1828, Accuracy: 0.9219\n",
      "Epoch [33/100], Train Loss: 0.2506, Val Loss: 0.2053, Train Acc: 0.9104, Val Acc: 0.9264\n",
      "==================================================\n",
      "Epoch [34/100], Step [0/254], Loss: 0.4908, Accuracy: 0.8125\n",
      "Epoch [34/100], Step [100/254], Loss: 0.2126, Accuracy: 0.9219\n",
      "Epoch [34/100], Step [200/254], Loss: 0.3771, Accuracy: 0.8594\n",
      "Epoch [34/100], Train Loss: 0.2557, Val Loss: 0.2218, Train Acc: 0.9086, Val Acc: 0.9196\n",
      "==================================================\n",
      "Epoch [35/100], Step [0/254], Loss: 0.2709, Accuracy: 0.8906\n",
      "Epoch [35/100], Step [100/254], Loss: 0.4607, Accuracy: 0.8125\n",
      "Epoch [35/100], Step [200/254], Loss: 0.3077, Accuracy: 0.9062\n",
      "Epoch [35/100], Train Loss: 0.2573, Val Loss: 0.2055, Train Acc: 0.9096, Val Acc: 0.9247\n",
      "==================================================\n",
      "Epoch [36/100], Step [0/254], Loss: 0.2906, Accuracy: 0.9219\n",
      "Epoch [36/100], Step [100/254], Loss: 0.2543, Accuracy: 0.9375\n",
      "Epoch [36/100], Step [200/254], Loss: 0.1934, Accuracy: 0.9062\n",
      "Epoch [36/100], Train Loss: 0.2481, Val Loss: 0.2034, Train Acc: 0.9099, Val Acc: 0.9291\n",
      "==================================================\n",
      "Epoch [37/100], Step [0/254], Loss: 0.3302, Accuracy: 0.8906\n",
      "Epoch [37/100], Step [100/254], Loss: 0.1959, Accuracy: 0.9531\n",
      "Epoch [37/100], Step [200/254], Loss: 0.3077, Accuracy: 0.9219\n",
      "Epoch [37/100], Train Loss: 0.2428, Val Loss: 0.1900, Train Acc: 0.9130, Val Acc: 0.9302\n",
      "==================================================\n",
      "Epoch [38/100], Step [0/254], Loss: 0.2417, Accuracy: 0.9219\n",
      "Epoch [38/100], Step [100/254], Loss: 0.2890, Accuracy: 0.9062\n",
      "Epoch [38/100], Step [200/254], Loss: 0.2109, Accuracy: 0.9219\n",
      "Epoch [38/100], Train Loss: 0.2379, Val Loss: 0.2046, Train Acc: 0.9149, Val Acc: 0.9262\n",
      "==================================================\n",
      "Epoch [39/100], Step [0/254], Loss: 0.1892, Accuracy: 0.9219\n",
      "Epoch [39/100], Step [100/254], Loss: 0.1254, Accuracy: 0.9688\n",
      "Epoch [39/100], Step [200/254], Loss: 0.4471, Accuracy: 0.8125\n",
      "Epoch [39/100], Train Loss: 0.2435, Val Loss: 0.1878, Train Acc: 0.9129, Val Acc: 0.9344\n",
      "==================================================\n",
      "Epoch [40/100], Step [0/254], Loss: 0.0946, Accuracy: 0.9688\n",
      "Epoch [40/100], Step [100/254], Loss: 0.2697, Accuracy: 0.9062\n",
      "Epoch [40/100], Step [200/254], Loss: 0.2423, Accuracy: 0.8906\n",
      "Epoch [40/100], Train Loss: 0.2357, Val Loss: 0.2177, Train Acc: 0.9170, Val Acc: 0.9214\n",
      "==================================================\n",
      "Epoch [41/100], Step [0/254], Loss: 0.2214, Accuracy: 0.9062\n",
      "Epoch [41/100], Step [100/254], Loss: 0.1170, Accuracy: 0.9688\n",
      "Epoch [41/100], Step [200/254], Loss: 0.1810, Accuracy: 0.9062\n",
      "Epoch [41/100], Train Loss: 0.2340, Val Loss: 0.1954, Train Acc: 0.9177, Val Acc: 0.9287\n",
      "==================================================\n",
      "Epoch [42/100], Step [0/254], Loss: 0.2688, Accuracy: 0.9062\n",
      "Epoch [42/100], Step [100/254], Loss: 0.1203, Accuracy: 0.9688\n",
      "Epoch [42/100], Step [200/254], Loss: 0.3188, Accuracy: 0.8594\n",
      "Epoch [42/100], Train Loss: 0.2367, Val Loss: 0.1854, Train Acc: 0.9149, Val Acc: 0.9336\n",
      "==================================================\n",
      "Epoch [43/100], Step [0/254], Loss: 0.1935, Accuracy: 0.9531\n",
      "Epoch [43/100], Step [100/254], Loss: 0.2509, Accuracy: 0.9219\n",
      "Epoch [43/100], Step [200/254], Loss: 0.3411, Accuracy: 0.8281\n",
      "Epoch [43/100], Train Loss: 0.2308, Val Loss: 0.1894, Train Acc: 0.9176, Val Acc: 0.9343\n",
      "==================================================\n",
      "Epoch [44/100], Step [0/254], Loss: 0.2632, Accuracy: 0.8594\n",
      "Epoch [44/100], Step [100/254], Loss: 0.1020, Accuracy: 0.9688\n",
      "Epoch [44/100], Step [200/254], Loss: 0.1894, Accuracy: 0.9531\n",
      "Epoch [44/100], Train Loss: 0.2255, Val Loss: 0.1914, Train Acc: 0.9200, Val Acc: 0.9306\n",
      "==================================================\n",
      "Epoch [45/100], Step [0/254], Loss: 0.4191, Accuracy: 0.8594\n",
      "Epoch [45/100], Step [100/254], Loss: 0.1293, Accuracy: 0.9531\n",
      "Epoch [45/100], Step [200/254], Loss: 0.1869, Accuracy: 0.9531\n",
      "Epoch [45/100], Train Loss: 0.2251, Val Loss: 0.1835, Train Acc: 0.9195, Val Acc: 0.9361\n",
      "==================================================\n",
      "Epoch [46/100], Step [0/254], Loss: 0.2533, Accuracy: 0.9219\n",
      "Epoch [46/100], Step [100/254], Loss: 0.3062, Accuracy: 0.8750\n",
      "Epoch [46/100], Step [200/254], Loss: 0.2377, Accuracy: 0.9219\n",
      "Epoch [46/100], Train Loss: 0.2313, Val Loss: 0.1745, Train Acc: 0.9177, Val Acc: 0.9373\n",
      "==================================================\n",
      "Epoch [47/100], Step [0/254], Loss: 0.3209, Accuracy: 0.8906\n",
      "Epoch [47/100], Step [100/254], Loss: 0.1208, Accuracy: 0.9531\n",
      "Epoch [47/100], Step [200/254], Loss: 0.2901, Accuracy: 0.8906\n",
      "Epoch [47/100], Train Loss: 0.2333, Val Loss: 0.1701, Train Acc: 0.9165, Val Acc: 0.9386\n",
      "==================================================\n",
      "Epoch [48/100], Step [0/254], Loss: 0.2653, Accuracy: 0.9062\n",
      "Epoch [48/100], Step [100/254], Loss: 0.3189, Accuracy: 0.8750\n",
      "Epoch [48/100], Step [200/254], Loss: 0.2681, Accuracy: 0.8750\n",
      "Epoch [48/100], Train Loss: 0.2209, Val Loss: 0.1738, Train Acc: 0.9226, Val Acc: 0.9369\n",
      "==================================================\n",
      "Epoch [49/100], Step [0/254], Loss: 0.1258, Accuracy: 0.9375\n",
      "Epoch [49/100], Step [100/254], Loss: 0.2357, Accuracy: 0.9062\n",
      "Epoch [49/100], Step [200/254], Loss: 0.1408, Accuracy: 0.9375\n",
      "Epoch [49/100], Train Loss: 0.2069, Val Loss: 0.2169, Train Acc: 0.9262, Val Acc: 0.9210\n",
      "==================================================\n",
      "Epoch [50/100], Step [0/254], Loss: 0.1905, Accuracy: 0.9375\n",
      "Epoch [50/100], Step [100/254], Loss: 0.3231, Accuracy: 0.8906\n",
      "Epoch [50/100], Step [200/254], Loss: 0.3509, Accuracy: 0.9062\n",
      "Epoch [50/100], Train Loss: 0.2219, Val Loss: 0.2111, Train Acc: 0.9211, Val Acc: 0.9211\n",
      "==================================================\n",
      "Epoch [51/100], Step [0/254], Loss: 0.3118, Accuracy: 0.8906\n",
      "Epoch [51/100], Step [100/254], Loss: 0.1196, Accuracy: 0.9531\n",
      "Epoch [51/100], Step [200/254], Loss: 0.0750, Accuracy: 0.9844\n",
      "Epoch [51/100], Train Loss: 0.2134, Val Loss: 0.1827, Train Acc: 0.9243, Val Acc: 0.9351\n",
      "==================================================\n",
      "Epoch [52/100], Step [0/254], Loss: 0.2739, Accuracy: 0.9219\n",
      "Epoch [52/100], Step [100/254], Loss: 0.1722, Accuracy: 0.9375\n",
      "Epoch [52/100], Step [200/254], Loss: 0.1711, Accuracy: 0.9219\n",
      "Epoch [52/100], Train Loss: 0.2079, Val Loss: 0.1612, Train Acc: 0.9248, Val Acc: 0.9431\n",
      "==================================================\n",
      "Epoch [53/100], Step [0/254], Loss: 0.1260, Accuracy: 0.9531\n",
      "Epoch [53/100], Step [100/254], Loss: 0.0662, Accuracy: 1.0000\n",
      "Epoch [53/100], Step [200/254], Loss: 0.1824, Accuracy: 0.8906\n",
      "Epoch [53/100], Train Loss: 0.2063, Val Loss: 0.1621, Train Acc: 0.9261, Val Acc: 0.9420\n",
      "==================================================\n",
      "Epoch [54/100], Step [0/254], Loss: 0.3448, Accuracy: 0.8750\n",
      "Epoch [54/100], Step [100/254], Loss: 0.2693, Accuracy: 0.8438\n",
      "Epoch [54/100], Step [200/254], Loss: 0.2763, Accuracy: 0.8906\n",
      "Epoch [54/100], Train Loss: 0.2181, Val Loss: 0.1578, Train Acc: 0.9232, Val Acc: 0.9428\n",
      "==================================================\n",
      "Epoch [55/100], Step [0/254], Loss: 0.1398, Accuracy: 0.9688\n",
      "Epoch [55/100], Step [100/254], Loss: 0.1190, Accuracy: 0.9531\n",
      "Epoch [55/100], Step [200/254], Loss: 0.2264, Accuracy: 0.8906\n",
      "Epoch [55/100], Train Loss: 0.1937, Val Loss: 0.1561, Train Acc: 0.9312, Val Acc: 0.9423\n",
      "==================================================\n",
      "Epoch [56/100], Step [0/254], Loss: 0.1051, Accuracy: 0.9688\n",
      "Epoch [56/100], Step [100/254], Loss: 0.1285, Accuracy: 0.9531\n",
      "Epoch [56/100], Step [200/254], Loss: 0.2525, Accuracy: 0.9062\n",
      "Epoch [56/100], Train Loss: 0.1962, Val Loss: 0.1584, Train Acc: 0.9285, Val Acc: 0.9433\n",
      "==================================================\n",
      "Epoch [57/100], Step [0/254], Loss: 0.3038, Accuracy: 0.9219\n",
      "Epoch [57/100], Step [100/254], Loss: 0.1359, Accuracy: 0.9688\n",
      "Epoch [57/100], Step [200/254], Loss: 0.1299, Accuracy: 0.9688\n",
      "Epoch [57/100], Train Loss: 0.1937, Val Loss: 0.1591, Train Acc: 0.9301, Val Acc: 0.9426\n",
      "==================================================\n",
      "Epoch [58/100], Step [0/254], Loss: 0.2543, Accuracy: 0.9219\n",
      "Epoch [58/100], Step [100/254], Loss: 0.3725, Accuracy: 0.8281\n",
      "Epoch [58/100], Step [200/254], Loss: 0.1521, Accuracy: 0.9375\n",
      "Epoch [58/100], Train Loss: 0.1961, Val Loss: 0.1552, Train Acc: 0.9304, Val Acc: 0.9456\n",
      "==================================================\n",
      "Epoch [59/100], Step [0/254], Loss: 0.1823, Accuracy: 0.9062\n",
      "Epoch [59/100], Step [100/254], Loss: 0.1756, Accuracy: 0.9219\n",
      "Epoch [59/100], Step [200/254], Loss: 0.2067, Accuracy: 0.8906\n",
      "Epoch [59/100], Train Loss: 0.1968, Val Loss: 0.1564, Train Acc: 0.9302, Val Acc: 0.9430\n",
      "==================================================\n",
      "Epoch [60/100], Step [0/254], Loss: 0.3004, Accuracy: 0.8750\n",
      "Epoch [60/100], Step [100/254], Loss: 0.1431, Accuracy: 0.9375\n",
      "Epoch [60/100], Step [200/254], Loss: 0.2704, Accuracy: 0.8906\n",
      "Epoch [60/100], Train Loss: 0.1982, Val Loss: 0.1550, Train Acc: 0.9270, Val Acc: 0.9443\n",
      "==================================================\n",
      "Epoch [61/100], Step [0/254], Loss: 0.1676, Accuracy: 0.9375\n",
      "Epoch [61/100], Step [100/254], Loss: 0.1070, Accuracy: 0.9688\n",
      "Epoch [61/100], Step [200/254], Loss: 0.1269, Accuracy: 0.9531\n",
      "Epoch [61/100], Train Loss: 0.1994, Val Loss: 0.1546, Train Acc: 0.9310, Val Acc: 0.9434\n",
      "==================================================\n",
      "Epoch [62/100], Step [0/254], Loss: 0.1188, Accuracy: 0.9531\n",
      "Epoch [62/100], Step [100/254], Loss: 0.1417, Accuracy: 0.9375\n",
      "Epoch [62/100], Step [200/254], Loss: 0.2264, Accuracy: 0.8594\n",
      "Epoch [62/100], Train Loss: 0.2023, Val Loss: 0.1552, Train Acc: 0.9273, Val Acc: 0.9450\n",
      "==================================================\n",
      "Epoch [63/100], Step [0/254], Loss: 0.1657, Accuracy: 0.9531\n",
      "Epoch [63/100], Step [100/254], Loss: 0.1566, Accuracy: 0.9531\n",
      "Epoch [63/100], Step [200/254], Loss: 0.2817, Accuracy: 0.8906\n",
      "Epoch [63/100], Train Loss: 0.1931, Val Loss: 0.1572, Train Acc: 0.9298, Val Acc: 0.9438\n",
      "==================================================\n",
      "Epoch [64/100], Step [0/254], Loss: 0.3063, Accuracy: 0.8906\n",
      "Epoch [64/100], Step [100/254], Loss: 0.2562, Accuracy: 0.9219\n",
      "Epoch [64/100], Step [200/254], Loss: 0.1557, Accuracy: 0.9375\n",
      "Epoch [64/100], Train Loss: 0.1885, Val Loss: 0.1507, Train Acc: 0.9315, Val Acc: 0.9473\n",
      "==================================================\n",
      "Epoch [65/100], Step [0/254], Loss: 0.1186, Accuracy: 0.9688\n",
      "Epoch [65/100], Step [100/254], Loss: 0.1718, Accuracy: 0.9531\n",
      "Epoch [65/100], Step [200/254], Loss: 0.1914, Accuracy: 0.9219\n",
      "Epoch [65/100], Train Loss: 0.1931, Val Loss: 0.1522, Train Acc: 0.9309, Val Acc: 0.9453\n",
      "==================================================\n",
      "Epoch [66/100], Step [0/254], Loss: 0.1959, Accuracy: 0.9219\n",
      "Epoch [66/100], Step [100/254], Loss: 0.3357, Accuracy: 0.8906\n",
      "Epoch [66/100], Step [200/254], Loss: 0.1334, Accuracy: 0.9688\n",
      "Epoch [66/100], Train Loss: 0.1958, Val Loss: 0.1523, Train Acc: 0.9287, Val Acc: 0.9480\n",
      "==================================================\n",
      "Epoch [67/100], Step [0/254], Loss: 0.1722, Accuracy: 0.9531\n",
      "Epoch [67/100], Step [100/254], Loss: 0.0884, Accuracy: 0.9844\n",
      "Epoch [67/100], Step [200/254], Loss: 0.2406, Accuracy: 0.9375\n",
      "Epoch [67/100], Train Loss: 0.1877, Val Loss: 0.1521, Train Acc: 0.9344, Val Acc: 0.9454\n",
      "==================================================\n",
      "Epoch [68/100], Step [0/254], Loss: 0.2829, Accuracy: 0.8906\n",
      "Epoch [68/100], Step [100/254], Loss: 0.2131, Accuracy: 0.9375\n",
      "Epoch [68/100], Step [200/254], Loss: 0.1394, Accuracy: 0.9688\n",
      "Epoch [68/100], Train Loss: 0.1929, Val Loss: 0.1480, Train Acc: 0.9296, Val Acc: 0.9483\n",
      "==================================================\n",
      "Epoch [69/100], Step [0/254], Loss: 0.0957, Accuracy: 1.0000\n",
      "Epoch [69/100], Step [100/254], Loss: 0.0787, Accuracy: 0.9688\n",
      "Epoch [69/100], Step [200/254], Loss: 0.1450, Accuracy: 0.9844\n",
      "Epoch [69/100], Train Loss: 0.1917, Val Loss: 0.1502, Train Acc: 0.9329, Val Acc: 0.9468\n",
      "==================================================\n",
      "Epoch [70/100], Step [0/254], Loss: 0.0594, Accuracy: 1.0000\n",
      "Epoch [70/100], Step [100/254], Loss: 0.1136, Accuracy: 0.9531\n",
      "Epoch [70/100], Step [200/254], Loss: 0.3724, Accuracy: 0.8281\n",
      "Epoch [70/100], Train Loss: 0.1937, Val Loss: 0.1512, Train Acc: 0.9292, Val Acc: 0.9463\n",
      "==================================================\n",
      "Epoch [71/100], Step [0/254], Loss: 0.1272, Accuracy: 0.9375\n",
      "Epoch [71/100], Step [100/254], Loss: 0.2373, Accuracy: 0.9219\n",
      "Epoch [71/100], Step [200/254], Loss: 0.2731, Accuracy: 0.8750\n",
      "Epoch [71/100], Train Loss: 0.1979, Val Loss: 0.1518, Train Acc: 0.9281, Val Acc: 0.9443\n",
      "==================================================\n",
      "Epoch [72/100], Step [0/254], Loss: 0.2239, Accuracy: 0.9062\n",
      "Epoch [72/100], Step [100/254], Loss: 0.1913, Accuracy: 0.9531\n",
      "Epoch [72/100], Step [200/254], Loss: 0.1761, Accuracy: 0.9375\n",
      "Epoch [72/100], Train Loss: 0.1988, Val Loss: 0.1500, Train Acc: 0.9286, Val Acc: 0.9445\n",
      "==================================================\n",
      "Epoch [73/100], Step [0/254], Loss: 0.1633, Accuracy: 0.9531\n",
      "Epoch [73/100], Step [100/254], Loss: 0.1372, Accuracy: 0.9531\n",
      "Epoch [73/100], Step [200/254], Loss: 0.0975, Accuracy: 0.9688\n",
      "Epoch [73/100], Train Loss: 0.1913, Val Loss: 0.1454, Train Acc: 0.9331, Val Acc: 0.9496\n",
      "==================================================\n",
      "Epoch [74/100], Step [0/254], Loss: 0.1098, Accuracy: 0.9688\n",
      "Epoch [74/100], Step [100/254], Loss: 0.1478, Accuracy: 0.9375\n",
      "Epoch [74/100], Step [200/254], Loss: 0.0894, Accuracy: 0.9844\n",
      "Epoch [74/100], Train Loss: 0.1866, Val Loss: 0.1468, Train Acc: 0.9318, Val Acc: 0.9475\n",
      "==================================================\n",
      "Epoch [75/100], Step [0/254], Loss: 0.3143, Accuracy: 0.8906\n",
      "Epoch [75/100], Step [100/254], Loss: 0.1442, Accuracy: 0.9375\n",
      "Epoch [75/100], Step [200/254], Loss: 0.3169, Accuracy: 0.9062\n",
      "Epoch [75/100], Train Loss: 0.1858, Val Loss: 0.1524, Train Acc: 0.9353, Val Acc: 0.9449\n",
      "==================================================\n",
      "Epoch [76/100], Step [0/254], Loss: 0.2248, Accuracy: 0.9062\n",
      "Epoch [76/100], Step [100/254], Loss: 0.1732, Accuracy: 0.9375\n",
      "Epoch [76/100], Step [200/254], Loss: 0.1051, Accuracy: 0.9688\n",
      "Epoch [76/100], Train Loss: 0.1848, Val Loss: 0.1495, Train Acc: 0.9349, Val Acc: 0.9465\n",
      "==================================================\n",
      "Epoch [77/100], Step [0/254], Loss: 0.1407, Accuracy: 0.9531\n",
      "Epoch [77/100], Step [100/254], Loss: 0.1654, Accuracy: 0.9375\n",
      "Epoch [77/100], Step [200/254], Loss: 0.0982, Accuracy: 0.9688\n",
      "Epoch [77/100], Train Loss: 0.1862, Val Loss: 0.1510, Train Acc: 0.9332, Val Acc: 0.9456\n",
      "==================================================\n",
      "Epoch [78/100], Step [0/254], Loss: 0.2878, Accuracy: 0.9062\n",
      "Epoch [78/100], Step [100/254], Loss: 0.2569, Accuracy: 0.9375\n",
      "Epoch [78/100], Step [200/254], Loss: 0.2172, Accuracy: 0.9219\n",
      "Epoch [78/100], Train Loss: 0.1914, Val Loss: 0.1478, Train Acc: 0.9292, Val Acc: 0.9462\n",
      "==================================================\n",
      "Epoch [79/100], Step [0/254], Loss: 0.1458, Accuracy: 0.9531\n",
      "Epoch [79/100], Step [100/254], Loss: 0.1175, Accuracy: 0.9844\n",
      "Epoch [79/100], Step [200/254], Loss: 0.2369, Accuracy: 0.9219\n",
      "Epoch [79/100], Train Loss: 0.1929, Val Loss: 0.1504, Train Acc: 0.9321, Val Acc: 0.9452\n",
      "==================================================\n",
      "Epoch [80/100], Step [0/254], Loss: 0.1087, Accuracy: 0.9531\n",
      "Epoch [80/100], Step [100/254], Loss: 0.1913, Accuracy: 0.9375\n",
      "Epoch [80/100], Step [200/254], Loss: 0.1548, Accuracy: 0.9688\n",
      "Epoch [80/100], Train Loss: 0.1892, Val Loss: 0.1489, Train Acc: 0.9349, Val Acc: 0.9469\n",
      "==================================================\n",
      "Epoch [81/100], Step [0/254], Loss: 0.1812, Accuracy: 0.9375\n",
      "Epoch [81/100], Step [100/254], Loss: 0.0713, Accuracy: 0.9688\n",
      "Epoch [81/100], Step [200/254], Loss: 0.2388, Accuracy: 0.8906\n",
      "Epoch [81/100], Train Loss: 0.1838, Val Loss: 0.1492, Train Acc: 0.9341, Val Acc: 0.9466\n",
      "==================================================\n",
      "Epoch [82/100], Step [0/254], Loss: 0.3264, Accuracy: 0.8906\n",
      "Epoch [82/100], Step [100/254], Loss: 0.3421, Accuracy: 0.8750\n",
      "Epoch [82/100], Step [200/254], Loss: 0.3112, Accuracy: 0.9219\n",
      "Epoch [82/100], Train Loss: 0.1879, Val Loss: 0.1457, Train Acc: 0.9330, Val Acc: 0.9463\n",
      "==================================================\n",
      "Epoch [83/100], Step [0/254], Loss: 0.2260, Accuracy: 0.9375\n",
      "Epoch [83/100], Step [100/254], Loss: 0.1074, Accuracy: 0.9375\n",
      "Epoch [83/100], Step [200/254], Loss: 0.1556, Accuracy: 0.9375\n",
      "Epoch [83/100], Train Loss: 0.1838, Val Loss: 0.1436, Train Acc: 0.9323, Val Acc: 0.9491\n",
      "==================================================\n",
      "Epoch [84/100], Step [0/254], Loss: 0.1665, Accuracy: 0.9531\n",
      "Epoch [84/100], Step [100/254], Loss: 0.1236, Accuracy: 0.9531\n",
      "Epoch [84/100], Step [200/254], Loss: 0.0544, Accuracy: 0.9844\n",
      "Epoch [84/100], Train Loss: 0.1850, Val Loss: 0.1443, Train Acc: 0.9313, Val Acc: 0.9493\n",
      "==================================================\n",
      "Epoch [85/100], Step [0/254], Loss: 0.2908, Accuracy: 0.9219\n",
      "Epoch [85/100], Step [100/254], Loss: 0.1304, Accuracy: 0.9531\n",
      "Epoch [85/100], Step [200/254], Loss: 0.2726, Accuracy: 0.9062\n",
      "Epoch [85/100], Train Loss: 0.1908, Val Loss: 0.1494, Train Acc: 0.9329, Val Acc: 0.9469\n",
      "==================================================\n",
      "Epoch [86/100], Step [0/254], Loss: 0.2834, Accuracy: 0.9062\n",
      "Epoch [86/100], Step [100/254], Loss: 0.1104, Accuracy: 0.9531\n",
      "Epoch [86/100], Step [200/254], Loss: 0.1126, Accuracy: 0.9688\n",
      "Epoch [86/100], Train Loss: 0.1781, Val Loss: 0.1442, Train Acc: 0.9361, Val Acc: 0.9483\n",
      "==================================================\n",
      "Epoch [87/100], Step [0/254], Loss: 0.1993, Accuracy: 0.9219\n",
      "Epoch [87/100], Step [100/254], Loss: 0.2717, Accuracy: 0.9375\n",
      "Epoch [87/100], Step [200/254], Loss: 0.1293, Accuracy: 0.9375\n",
      "Epoch [87/100], Train Loss: 0.1842, Val Loss: 0.1459, Train Acc: 0.9337, Val Acc: 0.9477\n",
      "==================================================\n",
      "Epoch [88/100], Step [0/254], Loss: 0.2857, Accuracy: 0.9219\n",
      "Epoch [88/100], Step [100/254], Loss: 0.1517, Accuracy: 0.9219\n",
      "Epoch [88/100], Step [200/254], Loss: 0.2425, Accuracy: 0.9219\n",
      "Epoch [88/100], Train Loss: 0.1813, Val Loss: 0.1452, Train Acc: 0.9328, Val Acc: 0.9482\n",
      "==================================================\n",
      "Epoch [89/100], Step [0/254], Loss: 0.2586, Accuracy: 0.9375\n",
      "Epoch [89/100], Step [100/254], Loss: 0.1430, Accuracy: 0.9531\n",
      "Epoch [89/100], Step [200/254], Loss: 0.2073, Accuracy: 0.9375\n",
      "Epoch [89/100], Train Loss: 0.1844, Val Loss: 0.1473, Train Acc: 0.9326, Val Acc: 0.9479\n",
      "==================================================\n",
      "Epoch [90/100], Step [0/254], Loss: 0.1980, Accuracy: 0.9375\n",
      "Epoch [90/100], Step [100/254], Loss: 0.1691, Accuracy: 0.9688\n",
      "Epoch [90/100], Step [200/254], Loss: 0.2266, Accuracy: 0.9375\n",
      "Epoch [90/100], Train Loss: 0.1881, Val Loss: 0.1454, Train Acc: 0.9347, Val Acc: 0.9478\n",
      "==================================================\n",
      "Epoch [91/100], Step [0/254], Loss: 0.1271, Accuracy: 0.9375\n",
      "Epoch [91/100], Step [100/254], Loss: 0.1624, Accuracy: 0.9062\n",
      "Epoch [91/100], Step [200/254], Loss: 0.2287, Accuracy: 0.9062\n",
      "Epoch [91/100], Train Loss: 0.1870, Val Loss: 0.1487, Train Acc: 0.9326, Val Acc: 0.9491\n",
      "==================================================\n",
      "Epoch [92/100], Step [0/254], Loss: 0.2906, Accuracy: 0.9062\n",
      "Epoch [92/100], Step [100/254], Loss: 0.1113, Accuracy: 0.9844\n",
      "Epoch [92/100], Step [200/254], Loss: 0.1946, Accuracy: 0.9531\n",
      "Epoch [92/100], Train Loss: 0.1773, Val Loss: 0.1496, Train Acc: 0.9359, Val Acc: 0.9475\n",
      "==================================================\n",
      "Epoch [93/100], Step [0/254], Loss: 0.1180, Accuracy: 0.9531\n",
      "Epoch [93/100], Step [100/254], Loss: 0.0742, Accuracy: 0.9688\n",
      "Epoch [93/100], Step [200/254], Loss: 0.1824, Accuracy: 0.9688\n",
      "Epoch [93/100], Train Loss: 0.1969, Val Loss: 0.1472, Train Acc: 0.9324, Val Acc: 0.9490\n",
      "==================================================\n",
      "Epoch [94/100], Step [0/254], Loss: 0.2927, Accuracy: 0.9062\n",
      "Epoch [94/100], Step [100/254], Loss: 0.2320, Accuracy: 0.8906\n",
      "Epoch [94/100], Step [200/254], Loss: 0.1807, Accuracy: 0.9531\n",
      "Epoch [94/100], Train Loss: 0.1892, Val Loss: 0.1493, Train Acc: 0.9307, Val Acc: 0.9471\n",
      "==================================================\n",
      "CPU times: user 13h 15min 5s, sys: 26min 33s, total: 13h 41min 39s\n",
      "Wall time: 1h 43min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MobileNetV3Gelu(\n",
    "    in_chn=3,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train(model, device, trainLoader, valLoader, criterion, optimizer, n_epochs, earlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.6 s, sys: 903 ms, total: 27.5 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predGelu, actualGelu = infer(model, device, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "geluAcc = (torch.argmax(predGelu, dim=1) == actualGelu).float().mean()\n",
    "print(f\"Test Accuracy: {geluAcc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using ELU instead of hardswish in bottleneck block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ELU\n",
    "\n",
    "\n",
    "class MobileNetV3Elu(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chn,\n",
    "        se_reduction=4,\n",
    "        mode=\"small\",\n",
    "        num_classes=10,\n",
    "        bn_eps=0.001,\n",
    "        bn_momentum=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if mode == \"small\":\n",
    "            # MobileNetV3-Small\n",
    "            layers_config = [\n",
    "                [3, 16, 16, True, ReLU, 2],\n",
    "                [3, 72, 24, False, ReLU, 2],\n",
    "                [3, 88, 24, False, ReLU, 1],\n",
    "                [5, 96, 40, True, ELU, 2],\n",
    "                [5, 240, 40, True, ELU, 1],\n",
    "                [5, 240, 40, True, ELU, 1],\n",
    "                [5, 120, 48, True, ELU, 1],\n",
    "                [5, 144, 48, True, ELU, 1],\n",
    "                [5, 288, 96, True, ELU, 2],\n",
    "                [5, 576, 96, True, ELU, 1],\n",
    "                [5, 576, 96, True, ELU, 1],\n",
    "            ]\n",
    "            last_channel = 1280\n",
    "            # final layer\n",
    "            self.final_layers = [\n",
    "                ConvBlock(\n",
    "                    layers_config[-1][2], 576, activation=Hardswish, kernel_size=1\n",
    "                ),\n",
    "                SqueezeAndExcite(576, se_reduction),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(576, last_channel, 1),\n",
    "                Hardswish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(last_channel, num_classes),\n",
    "            ]\n",
    "\n",
    "        # Initial layers\n",
    "        self.features: list[nn.Module] = [\n",
    "            ConvBlock(in_chn, 16, activation=Hardswish, kernel_size=3, stride=2)\n",
    "        ]\n",
    "        #         print(dir(self.features[-1]))\n",
    "\n",
    "        # Build main blocks\n",
    "\n",
    "        input_channel = 16\n",
    "        for kernel, exp, out, se, act, stride in layers_config:\n",
    "            self.features.append(\n",
    "                BottleNeck(\n",
    "                    in_chn=input_channel,\n",
    "                    out_chn=out,\n",
    "                    expansion_channel=exp,\n",
    "                    activation=act,\n",
    "                    kernel=kernel,\n",
    "                    se_flag=se,\n",
    "                    stride=stride,\n",
    "                )\n",
    "            )\n",
    "            input_channel = out\n",
    "\n",
    "        self.start = nn.Sequential(*self.features)\n",
    "        self.final = nn.Sequential(*self.final_layers)\n",
    "\n",
    "        # modify batchnorm layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eps = bn_eps\n",
    "                m.momentum = bn_momentum\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/254], Loss: 2.3077, Accuracy: 0.0156\n",
      "Epoch [1/100], Step [100/254], Loss: 0.9235, Accuracy: 0.6719\n",
      "Epoch [1/100], Step [200/254], Loss: 1.1456, Accuracy: 0.6406\n",
      "Epoch [1/100], Train Loss: 1.0937, Val Loss: 2.8207, Train Acc: 0.6079, Val Acc: 0.1106\n",
      "==================================================\n",
      "Epoch [2/100], Step [0/254], Loss: 0.7742, Accuracy: 0.6875\n",
      "Epoch [2/100], Step [100/254], Loss: 0.8375, Accuracy: 0.6719\n",
      "Epoch [2/100], Step [200/254], Loss: 0.5904, Accuracy: 0.7969\n",
      "Epoch [2/100], Train Loss: 0.7931, Val Loss: 2.8497, Train Acc: 0.7180, Val Acc: 0.3428\n",
      "==================================================\n",
      "Epoch [3/100], Step [0/254], Loss: 1.0052, Accuracy: 0.6406\n",
      "Epoch [3/100], Step [100/254], Loss: 0.7003, Accuracy: 0.7344\n",
      "Epoch [3/100], Step [200/254], Loss: 0.7165, Accuracy: 0.7188\n",
      "Epoch [3/100], Train Loss: 0.7011, Val Loss: 0.8753, Train Acc: 0.7525, Val Acc: 0.7069\n",
      "==================================================\n",
      "Epoch [4/100], Step [0/254], Loss: 0.6188, Accuracy: 0.7344\n",
      "Epoch [4/100], Step [100/254], Loss: 0.6048, Accuracy: 0.7656\n",
      "Epoch [4/100], Step [200/254], Loss: 0.7716, Accuracy: 0.7656\n",
      "Epoch [4/100], Train Loss: 0.6390, Val Loss: 0.7820, Train Acc: 0.7768, Val Acc: 0.7410\n",
      "==================================================\n",
      "Epoch [5/100], Step [0/254], Loss: 0.5431, Accuracy: 0.7969\n",
      "Epoch [5/100], Step [100/254], Loss: 0.5815, Accuracy: 0.7500\n",
      "Epoch [5/100], Step [200/254], Loss: 0.6489, Accuracy: 0.7188\n",
      "Epoch [5/100], Train Loss: 0.5866, Val Loss: 0.7844, Train Acc: 0.7929, Val Acc: 0.7298\n",
      "==================================================\n",
      "Epoch [6/100], Step [0/254], Loss: 0.6436, Accuracy: 0.7812\n",
      "Epoch [6/100], Step [100/254], Loss: 0.6187, Accuracy: 0.7812\n",
      "Epoch [6/100], Step [200/254], Loss: 0.5574, Accuracy: 0.8125\n",
      "Epoch [6/100], Train Loss: 0.5609, Val Loss: 0.4948, Train Acc: 0.8055, Val Acc: 0.8299\n",
      "==================================================\n",
      "Epoch [7/100], Step [0/254], Loss: 0.4408, Accuracy: 0.8438\n",
      "Epoch [7/100], Step [100/254], Loss: 0.4387, Accuracy: 0.7969\n",
      "Epoch [7/100], Step [200/254], Loss: 0.6785, Accuracy: 0.7812\n",
      "Epoch [7/100], Train Loss: 0.5418, Val Loss: 0.4954, Train Acc: 0.8147, Val Acc: 0.8298\n",
      "==================================================\n",
      "Epoch [8/100], Step [0/254], Loss: 0.5265, Accuracy: 0.8125\n",
      "Epoch [8/100], Step [100/254], Loss: 0.5616, Accuracy: 0.7812\n",
      "Epoch [8/100], Step [200/254], Loss: 0.3719, Accuracy: 0.8438\n",
      "Epoch [8/100], Train Loss: 0.5033, Val Loss: 0.7494, Train Acc: 0.8254, Val Acc: 0.7436\n",
      "==================================================\n",
      "Epoch [9/100], Step [0/254], Loss: 0.5646, Accuracy: 0.7656\n",
      "Epoch [9/100], Step [100/254], Loss: 0.5077, Accuracy: 0.8438\n",
      "Epoch [9/100], Step [200/254], Loss: 0.5610, Accuracy: 0.7500\n",
      "Epoch [9/100], Train Loss: 0.5019, Val Loss: 0.4539, Train Acc: 0.8265, Val Acc: 0.8419\n",
      "==================================================\n",
      "Epoch [10/100], Step [0/254], Loss: 0.3653, Accuracy: 0.8594\n",
      "Epoch [10/100], Step [100/254], Loss: 0.5973, Accuracy: 0.8125\n",
      "Epoch [10/100], Step [200/254], Loss: 0.5143, Accuracy: 0.7969\n",
      "Epoch [10/100], Train Loss: 0.4648, Val Loss: 0.5403, Train Acc: 0.8393, Val Acc: 0.8124\n",
      "==================================================\n",
      "Epoch [11/100], Step [0/254], Loss: 0.5694, Accuracy: 0.7969\n",
      "Epoch [11/100], Step [100/254], Loss: 0.4590, Accuracy: 0.8906\n",
      "Epoch [11/100], Step [200/254], Loss: 0.4733, Accuracy: 0.8438\n",
      "Epoch [11/100], Train Loss: 0.4585, Val Loss: 0.5072, Train Acc: 0.8386, Val Acc: 0.8210\n",
      "==================================================\n",
      "Epoch [12/100], Step [0/254], Loss: 0.3785, Accuracy: 0.9062\n",
      "Epoch [12/100], Step [100/254], Loss: 0.3815, Accuracy: 0.8906\n",
      "Epoch [12/100], Step [200/254], Loss: 0.3388, Accuracy: 0.8750\n",
      "Epoch [12/100], Train Loss: 0.4469, Val Loss: 0.5548, Train Acc: 0.8436, Val Acc: 0.8088\n",
      "==================================================\n",
      "Epoch [13/100], Step [0/254], Loss: 0.2705, Accuracy: 0.8906\n",
      "Epoch [13/100], Step [100/254], Loss: 0.3685, Accuracy: 0.8906\n",
      "Epoch [13/100], Step [200/254], Loss: 0.4219, Accuracy: 0.8594\n",
      "Epoch [13/100], Train Loss: 0.4357, Val Loss: 0.5451, Train Acc: 0.8489, Val Acc: 0.8121\n",
      "==================================================\n",
      "Epoch [14/100], Step [0/254], Loss: 0.5606, Accuracy: 0.7656\n",
      "Epoch [14/100], Step [100/254], Loss: 0.2815, Accuracy: 0.8906\n",
      "Epoch [14/100], Step [200/254], Loss: 0.4288, Accuracy: 0.8281\n",
      "Epoch [14/100], Train Loss: 0.3655, Val Loss: 0.2975, Train Acc: 0.8701, Val Acc: 0.8952\n",
      "==================================================\n",
      "Epoch [15/100], Step [0/254], Loss: 0.3841, Accuracy: 0.8594\n",
      "Epoch [15/100], Step [100/254], Loss: 0.4239, Accuracy: 0.8438\n",
      "Epoch [15/100], Step [200/254], Loss: 0.3322, Accuracy: 0.9062\n",
      "Epoch [15/100], Train Loss: 0.3517, Val Loss: 0.2946, Train Acc: 0.8752, Val Acc: 0.8928\n",
      "==================================================\n",
      "Epoch [16/100], Step [0/254], Loss: 0.2955, Accuracy: 0.8750\n",
      "Epoch [16/100], Step [100/254], Loss: 0.3138, Accuracy: 0.8750\n",
      "Epoch [16/100], Step [200/254], Loss: 0.4986, Accuracy: 0.8125\n",
      "Epoch [16/100], Train Loss: 0.3467, Val Loss: 0.2938, Train Acc: 0.8771, Val Acc: 0.8961\n",
      "==================================================\n",
      "Epoch [17/100], Step [0/254], Loss: 0.3523, Accuracy: 0.8906\n",
      "Epoch [17/100], Step [100/254], Loss: 0.2082, Accuracy: 0.9375\n",
      "Epoch [17/100], Step [200/254], Loss: 0.4834, Accuracy: 0.8906\n",
      "Epoch [17/100], Train Loss: 0.3444, Val Loss: 0.2904, Train Acc: 0.8797, Val Acc: 0.8949\n",
      "==================================================\n",
      "Epoch [18/100], Step [0/254], Loss: 0.3255, Accuracy: 0.8594\n",
      "Epoch [18/100], Step [100/254], Loss: 0.2520, Accuracy: 0.9062\n",
      "Epoch [18/100], Step [200/254], Loss: 0.2471, Accuracy: 0.9062\n",
      "Epoch [18/100], Train Loss: 0.3374, Val Loss: 0.2986, Train Acc: 0.8779, Val Acc: 0.8931\n",
      "==================================================\n",
      "Epoch [19/100], Step [0/254], Loss: 0.3168, Accuracy: 0.8594\n",
      "Epoch [19/100], Step [100/254], Loss: 0.3491, Accuracy: 0.9062\n",
      "Epoch [19/100], Step [200/254], Loss: 0.3081, Accuracy: 0.8750\n",
      "Epoch [19/100], Train Loss: 0.3350, Val Loss: 0.3115, Train Acc: 0.8787, Val Acc: 0.8844\n",
      "==================================================\n",
      "Epoch [20/100], Step [0/254], Loss: 0.1714, Accuracy: 0.9219\n",
      "Epoch [20/100], Step [100/254], Loss: 0.1867, Accuracy: 0.9531\n",
      "Epoch [20/100], Step [200/254], Loss: 0.2152, Accuracy: 0.9375\n",
      "Epoch [20/100], Train Loss: 0.3361, Val Loss: 0.2698, Train Acc: 0.8815, Val Acc: 0.9035\n",
      "==================================================\n",
      "Epoch [21/100], Step [0/254], Loss: 0.3832, Accuracy: 0.8594\n",
      "Epoch [21/100], Step [100/254], Loss: 0.6144, Accuracy: 0.7656\n",
      "Epoch [21/100], Step [200/254], Loss: 0.2791, Accuracy: 0.9062\n",
      "Epoch [21/100], Train Loss: 0.3261, Val Loss: 0.2717, Train Acc: 0.8836, Val Acc: 0.9029\n",
      "==================================================\n",
      "Epoch [22/100], Step [0/254], Loss: 0.2696, Accuracy: 0.9375\n",
      "Epoch [22/100], Step [100/254], Loss: 0.1685, Accuracy: 0.9219\n",
      "Epoch [22/100], Step [200/254], Loss: 0.2665, Accuracy: 0.9062\n",
      "Epoch [22/100], Train Loss: 0.3212, Val Loss: 0.2751, Train Acc: 0.8831, Val Acc: 0.9007\n",
      "==================================================\n",
      "Epoch [23/100], Step [0/254], Loss: 0.2729, Accuracy: 0.8906\n",
      "Epoch [23/100], Step [100/254], Loss: 0.2515, Accuracy: 0.9219\n",
      "Epoch [23/100], Step [200/254], Loss: 0.3350, Accuracy: 0.8594\n",
      "Epoch [23/100], Train Loss: 0.3207, Val Loss: 0.2621, Train Acc: 0.8870, Val Acc: 0.9055\n",
      "==================================================\n",
      "Epoch [24/100], Step [0/254], Loss: 0.4491, Accuracy: 0.8438\n",
      "Epoch [24/100], Step [100/254], Loss: 0.2404, Accuracy: 0.9062\n",
      "Epoch [24/100], Step [200/254], Loss: 0.2501, Accuracy: 0.9062\n",
      "Epoch [24/100], Train Loss: 0.2978, Val Loss: 0.3153, Train Acc: 0.8929, Val Acc: 0.8869\n",
      "==================================================\n",
      "Epoch [25/100], Step [0/254], Loss: 0.2725, Accuracy: 0.9062\n",
      "Epoch [25/100], Step [100/254], Loss: 0.1684, Accuracy: 0.9219\n",
      "Epoch [25/100], Step [200/254], Loss: 0.3494, Accuracy: 0.8906\n",
      "Epoch [25/100], Train Loss: 0.3070, Val Loss: 0.2454, Train Acc: 0.8903, Val Acc: 0.9114\n",
      "==================================================\n",
      "Epoch [26/100], Step [0/254], Loss: 0.3556, Accuracy: 0.8594\n",
      "Epoch [26/100], Step [100/254], Loss: 0.3792, Accuracy: 0.9062\n",
      "Epoch [26/100], Step [200/254], Loss: 0.3071, Accuracy: 0.8594\n",
      "Epoch [26/100], Train Loss: 0.3054, Val Loss: 0.3113, Train Acc: 0.8914, Val Acc: 0.8872\n",
      "==================================================\n",
      "Epoch [27/100], Step [0/254], Loss: 0.2384, Accuracy: 0.9219\n",
      "Epoch [27/100], Step [100/254], Loss: 0.2175, Accuracy: 0.9375\n",
      "Epoch [27/100], Step [200/254], Loss: 0.3612, Accuracy: 0.9062\n",
      "Epoch [27/100], Train Loss: 0.3045, Val Loss: 0.2537, Train Acc: 0.8898, Val Acc: 0.9062\n",
      "==================================================\n",
      "Epoch [28/100], Step [0/254], Loss: 0.2734, Accuracy: 0.8750\n",
      "Epoch [28/100], Step [100/254], Loss: 0.4491, Accuracy: 0.8125\n",
      "Epoch [28/100], Step [200/254], Loss: 0.2755, Accuracy: 0.8906\n",
      "Epoch [28/100], Train Loss: 0.3002, Val Loss: 0.2588, Train Acc: 0.8920, Val Acc: 0.9051\n",
      "==================================================\n",
      "Epoch [29/100], Step [0/254], Loss: 0.4328, Accuracy: 0.7969\n",
      "Epoch [29/100], Step [100/254], Loss: 0.3233, Accuracy: 0.8906\n",
      "Epoch [29/100], Step [200/254], Loss: 0.3594, Accuracy: 0.8438\n",
      "Epoch [29/100], Train Loss: 0.3013, Val Loss: 0.2712, Train Acc: 0.8903, Val Acc: 0.9011\n",
      "==================================================\n",
      "Epoch [30/100], Step [0/254], Loss: 0.3927, Accuracy: 0.8281\n",
      "Epoch [30/100], Step [100/254], Loss: 0.2697, Accuracy: 0.9062\n",
      "Epoch [30/100], Step [200/254], Loss: 0.2192, Accuracy: 0.9219\n",
      "Epoch [30/100], Train Loss: 0.2805, Val Loss: 0.2347, Train Acc: 0.8986, Val Acc: 0.9171\n",
      "==================================================\n",
      "Epoch [31/100], Step [0/254], Loss: 0.2439, Accuracy: 0.9219\n",
      "Epoch [31/100], Step [100/254], Loss: 0.2451, Accuracy: 0.8906\n",
      "Epoch [31/100], Step [200/254], Loss: 0.2524, Accuracy: 0.9062\n",
      "Epoch [31/100], Train Loss: 0.2792, Val Loss: 0.2303, Train Acc: 0.8991, Val Acc: 0.9186\n",
      "==================================================\n",
      "Epoch [32/100], Step [0/254], Loss: 0.4171, Accuracy: 0.8281\n",
      "Epoch [32/100], Step [100/254], Loss: 0.3421, Accuracy: 0.8906\n",
      "Epoch [32/100], Step [200/254], Loss: 0.2090, Accuracy: 0.9219\n",
      "Epoch [32/100], Train Loss: 0.2794, Val Loss: 0.2279, Train Acc: 0.8978, Val Acc: 0.9175\n",
      "==================================================\n",
      "Epoch [33/100], Step [0/254], Loss: 0.2344, Accuracy: 0.9375\n",
      "Epoch [33/100], Step [100/254], Loss: 0.2569, Accuracy: 0.8906\n",
      "Epoch [33/100], Step [200/254], Loss: 0.3242, Accuracy: 0.8594\n",
      "Epoch [33/100], Train Loss: 0.2793, Val Loss: 0.2279, Train Acc: 0.8994, Val Acc: 0.9187\n",
      "==================================================\n",
      "Epoch [34/100], Step [0/254], Loss: 0.2183, Accuracy: 0.9531\n",
      "Epoch [34/100], Step [100/254], Loss: 0.2739, Accuracy: 0.8906\n",
      "Epoch [34/100], Step [200/254], Loss: 0.2263, Accuracy: 0.9531\n",
      "Epoch [34/100], Train Loss: 0.2862, Val Loss: 0.2197, Train Acc: 0.8999, Val Acc: 0.9220\n",
      "==================================================\n",
      "Epoch [35/100], Step [0/254], Loss: 0.1923, Accuracy: 0.9375\n",
      "Epoch [35/100], Step [100/254], Loss: 0.1229, Accuracy: 0.9531\n",
      "Epoch [35/100], Step [200/254], Loss: 0.1390, Accuracy: 0.9688\n",
      "Epoch [35/100], Train Loss: 0.2676, Val Loss: 0.2327, Train Acc: 0.9024, Val Acc: 0.9164\n",
      "==================================================\n",
      "Epoch [36/100], Step [0/254], Loss: 0.1633, Accuracy: 0.9219\n",
      "Epoch [36/100], Step [100/254], Loss: 0.2117, Accuracy: 0.9219\n",
      "Epoch [36/100], Step [200/254], Loss: 0.2271, Accuracy: 0.9219\n",
      "Epoch [36/100], Train Loss: 0.2740, Val Loss: 0.2252, Train Acc: 0.9005, Val Acc: 0.9193\n",
      "==================================================\n",
      "Epoch [37/100], Step [0/254], Loss: 0.2601, Accuracy: 0.8906\n",
      "Epoch [37/100], Step [100/254], Loss: 0.1496, Accuracy: 0.9688\n",
      "Epoch [37/100], Step [200/254], Loss: 0.2448, Accuracy: 0.9375\n",
      "Epoch [37/100], Train Loss: 0.2719, Val Loss: 0.2238, Train Acc: 0.9024, Val Acc: 0.9183\n",
      "==================================================\n",
      "Epoch [38/100], Step [0/254], Loss: 0.2712, Accuracy: 0.8906\n",
      "Epoch [38/100], Step [100/254], Loss: 0.1253, Accuracy: 0.9844\n",
      "Epoch [38/100], Step [200/254], Loss: 0.2339, Accuracy: 0.9219\n",
      "Epoch [38/100], Train Loss: 0.2701, Val Loss: 0.2243, Train Acc: 0.9027, Val Acc: 0.9198\n",
      "==================================================\n",
      "Epoch [39/100], Step [0/254], Loss: 0.2477, Accuracy: 0.8906\n",
      "Epoch [39/100], Step [100/254], Loss: 0.2475, Accuracy: 0.9062\n",
      "Epoch [39/100], Step [200/254], Loss: 0.2392, Accuracy: 0.8906\n",
      "Epoch [39/100], Train Loss: 0.2741, Val Loss: 0.2216, Train Acc: 0.9010, Val Acc: 0.9193\n",
      "==================================================\n",
      "Epoch [40/100], Step [0/254], Loss: 0.1696, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [100/254], Loss: 0.2130, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [200/254], Loss: 0.3727, Accuracy: 0.9062\n",
      "Epoch [40/100], Train Loss: 0.2685, Val Loss: 0.2191, Train Acc: 0.9031, Val Acc: 0.9216\n",
      "==================================================\n",
      "Epoch [41/100], Step [0/254], Loss: 0.2527, Accuracy: 0.9375\n",
      "Epoch [41/100], Step [100/254], Loss: 0.1622, Accuracy: 0.9219\n",
      "Epoch [41/100], Step [200/254], Loss: 0.2865, Accuracy: 0.9375\n",
      "Epoch [41/100], Train Loss: 0.2668, Val Loss: 0.2186, Train Acc: 0.9058, Val Acc: 0.9208\n",
      "==================================================\n",
      "Epoch [42/100], Step [0/254], Loss: 0.2181, Accuracy: 0.9062\n",
      "Epoch [42/100], Step [100/254], Loss: 0.2185, Accuracy: 0.9531\n",
      "Epoch [42/100], Step [200/254], Loss: 0.1192, Accuracy: 0.9531\n",
      "Epoch [42/100], Train Loss: 0.2636, Val Loss: 0.2229, Train Acc: 0.9050, Val Acc: 0.9196\n",
      "==================================================\n",
      "Epoch [43/100], Step [0/254], Loss: 0.2579, Accuracy: 0.9062\n",
      "Epoch [43/100], Step [100/254], Loss: 0.3246, Accuracy: 0.8438\n",
      "Epoch [43/100], Step [200/254], Loss: 0.2099, Accuracy: 0.9219\n",
      "Epoch [43/100], Train Loss: 0.2688, Val Loss: 0.2201, Train Acc: 0.9042, Val Acc: 0.9208\n",
      "==================================================\n",
      "Epoch [44/100], Step [0/254], Loss: 0.2017, Accuracy: 0.9062\n",
      "Epoch [44/100], Step [100/254], Loss: 0.2751, Accuracy: 0.8906\n",
      "Epoch [44/100], Step [200/254], Loss: 0.3976, Accuracy: 0.8906\n",
      "Epoch [44/100], Train Loss: 0.2663, Val Loss: 0.2222, Train Acc: 0.9018, Val Acc: 0.9183\n",
      "==================================================\n",
      "Epoch [45/100], Step [0/254], Loss: 0.1327, Accuracy: 0.9531\n",
      "Epoch [45/100], Step [100/254], Loss: 0.1490, Accuracy: 0.9375\n",
      "Epoch [45/100], Step [200/254], Loss: 0.3127, Accuracy: 0.9062\n",
      "Epoch [45/100], Train Loss: 0.2742, Val Loss: 0.2217, Train Acc: 0.8979, Val Acc: 0.9203\n",
      "==================================================\n",
      "Epoch [46/100], Step [0/254], Loss: 0.2605, Accuracy: 0.9531\n",
      "Epoch [46/100], Step [100/254], Loss: 0.3511, Accuracy: 0.9062\n",
      "Epoch [46/100], Step [200/254], Loss: 0.2005, Accuracy: 0.9219\n",
      "Epoch [46/100], Train Loss: 0.2676, Val Loss: 0.2174, Train Acc: 0.9034, Val Acc: 0.9224\n",
      "==================================================\n",
      "Epoch [47/100], Step [0/254], Loss: 0.3928, Accuracy: 0.8594\n",
      "Epoch [47/100], Step [100/254], Loss: 0.2204, Accuracy: 0.9062\n",
      "Epoch [47/100], Step [200/254], Loss: 0.2511, Accuracy: 0.9219\n",
      "Epoch [47/100], Train Loss: 0.2692, Val Loss: 0.2195, Train Acc: 0.9019, Val Acc: 0.9209\n",
      "==================================================\n",
      "Epoch [48/100], Step [0/254], Loss: 0.3023, Accuracy: 0.9219\n",
      "Epoch [48/100], Step [100/254], Loss: 0.2875, Accuracy: 0.8906\n",
      "Epoch [48/100], Step [200/254], Loss: 0.2672, Accuracy: 0.8906\n",
      "Epoch [48/100], Train Loss: 0.2777, Val Loss: 0.2207, Train Acc: 0.8989, Val Acc: 0.9198\n",
      "==================================================\n",
      "Epoch [49/100], Step [0/254], Loss: 0.1817, Accuracy: 0.9375\n",
      "Epoch [49/100], Step [100/254], Loss: 0.2158, Accuracy: 0.9375\n",
      "Epoch [49/100], Step [200/254], Loss: 0.3636, Accuracy: 0.8906\n",
      "Epoch [49/100], Train Loss: 0.2700, Val Loss: 0.2208, Train Acc: 0.9042, Val Acc: 0.9217\n",
      "==================================================\n",
      "Epoch [50/100], Step [0/254], Loss: 0.2815, Accuracy: 0.9062\n",
      "Epoch [50/100], Step [100/254], Loss: 0.3312, Accuracy: 0.9062\n",
      "Epoch [50/100], Step [200/254], Loss: 0.2152, Accuracy: 0.9062\n",
      "Epoch [50/100], Train Loss: 0.2698, Val Loss: 0.2199, Train Acc: 0.9041, Val Acc: 0.9214\n",
      "==================================================\n",
      "Epoch [51/100], Step [0/254], Loss: 0.2667, Accuracy: 0.8906\n",
      "Epoch [51/100], Step [100/254], Loss: 0.2356, Accuracy: 0.9062\n",
      "Epoch [51/100], Step [200/254], Loss: 0.1786, Accuracy: 0.9219\n",
      "Epoch [51/100], Train Loss: 0.2684, Val Loss: 0.2219, Train Acc: 0.9028, Val Acc: 0.9206\n",
      "==================================================\n",
      "Epoch [52/100], Step [0/254], Loss: 0.2153, Accuracy: 0.8906\n",
      "Epoch [52/100], Step [100/254], Loss: 0.2281, Accuracy: 0.9375\n",
      "Epoch [52/100], Step [200/254], Loss: 0.2320, Accuracy: 0.8906\n",
      "Epoch [52/100], Train Loss: 0.2640, Val Loss: 0.2195, Train Acc: 0.9015, Val Acc: 0.9219\n",
      "==================================================\n",
      "Epoch [53/100], Step [0/254], Loss: 0.2974, Accuracy: 0.9062\n",
      "Epoch [53/100], Step [100/254], Loss: 0.2259, Accuracy: 0.8906\n",
      "Epoch [53/100], Step [200/254], Loss: 0.3680, Accuracy: 0.8750\n",
      "Epoch [53/100], Train Loss: 0.2741, Val Loss: 0.2175, Train Acc: 0.9040, Val Acc: 0.9227\n",
      "==================================================\n",
      "Epoch [54/100], Step [0/254], Loss: 0.3142, Accuracy: 0.9062\n",
      "Epoch [54/100], Step [100/254], Loss: 0.3712, Accuracy: 0.8125\n",
      "Epoch [54/100], Step [200/254], Loss: 0.2521, Accuracy: 0.9219\n",
      "Epoch [54/100], Train Loss: 0.2771, Val Loss: 0.2169, Train Acc: 0.9044, Val Acc: 0.9235\n",
      "==================================================\n",
      "Epoch [55/100], Step [0/254], Loss: 0.4098, Accuracy: 0.8594\n",
      "Epoch [55/100], Step [100/254], Loss: 0.1964, Accuracy: 0.9219\n",
      "Epoch [55/100], Step [200/254], Loss: 0.3583, Accuracy: 0.8594\n",
      "Epoch [55/100], Train Loss: 0.2604, Val Loss: 0.2158, Train Acc: 0.9069, Val Acc: 0.9209\n",
      "==================================================\n",
      "Epoch [56/100], Step [0/254], Loss: 0.3215, Accuracy: 0.8906\n",
      "Epoch [56/100], Step [100/254], Loss: 0.2306, Accuracy: 0.9375\n",
      "Epoch [56/100], Step [200/254], Loss: 0.3293, Accuracy: 0.8594\n",
      "Epoch [56/100], Train Loss: 0.2583, Val Loss: 0.2204, Train Acc: 0.9081, Val Acc: 0.9224\n",
      "==================================================\n",
      "Epoch [57/100], Step [0/254], Loss: 0.1859, Accuracy: 0.9375\n",
      "Epoch [57/100], Step [100/254], Loss: 0.2575, Accuracy: 0.9219\n",
      "Epoch [57/100], Step [200/254], Loss: 0.4393, Accuracy: 0.8438\n",
      "Epoch [57/100], Train Loss: 0.2671, Val Loss: 0.2207, Train Acc: 0.9037, Val Acc: 0.9215\n",
      "==================================================\n",
      "Epoch [58/100], Step [0/254], Loss: 0.2652, Accuracy: 0.8906\n",
      "Epoch [58/100], Step [100/254], Loss: 0.2652, Accuracy: 0.9062\n",
      "Epoch [58/100], Step [200/254], Loss: 0.1298, Accuracy: 0.9531\n",
      "Epoch [58/100], Train Loss: 0.2635, Val Loss: 0.2163, Train Acc: 0.9066, Val Acc: 0.9242\n",
      "==================================================\n",
      "Epoch [59/100], Step [0/254], Loss: 0.2411, Accuracy: 0.9062\n",
      "Epoch [59/100], Step [100/254], Loss: 0.3935, Accuracy: 0.8438\n",
      "Epoch [59/100], Step [200/254], Loss: 0.2141, Accuracy: 0.9219\n",
      "Epoch [59/100], Train Loss: 0.2699, Val Loss: 0.2170, Train Acc: 0.9032, Val Acc: 0.9227\n",
      "==================================================\n",
      "Epoch [60/100], Step [0/254], Loss: 0.2264, Accuracy: 0.9062\n",
      "Epoch [60/100], Step [100/254], Loss: 0.4150, Accuracy: 0.8281\n",
      "Epoch [60/100], Step [200/254], Loss: 0.3238, Accuracy: 0.8438\n",
      "Epoch [60/100], Train Loss: 0.2708, Val Loss: 0.2203, Train Acc: 0.9027, Val Acc: 0.9194\n",
      "==================================================\n",
      "Epoch [61/100], Step [0/254], Loss: 0.2730, Accuracy: 0.9219\n",
      "Epoch [61/100], Step [100/254], Loss: 0.4312, Accuracy: 0.8438\n",
      "Epoch [61/100], Step [200/254], Loss: 0.2839, Accuracy: 0.9062\n",
      "Epoch [61/100], Train Loss: 0.2691, Val Loss: 0.2167, Train Acc: 0.9053, Val Acc: 0.9235\n",
      "==================================================\n",
      "Epoch [62/100], Step [0/254], Loss: 0.3229, Accuracy: 0.8906\n",
      "Epoch [62/100], Step [100/254], Loss: 0.2443, Accuracy: 0.9062\n",
      "Epoch [62/100], Step [200/254], Loss: 0.4241, Accuracy: 0.8750\n",
      "Epoch [62/100], Train Loss: 0.2634, Val Loss: 0.2191, Train Acc: 0.9046, Val Acc: 0.9215\n",
      "==================================================\n",
      "Epoch [63/100], Step [0/254], Loss: 0.0876, Accuracy: 0.9844\n",
      "Epoch [63/100], Step [100/254], Loss: 0.2241, Accuracy: 0.9062\n",
      "Epoch [63/100], Step [200/254], Loss: 0.2371, Accuracy: 0.9062\n",
      "Epoch [63/100], Train Loss: 0.2770, Val Loss: 0.2194, Train Acc: 0.9029, Val Acc: 0.9211\n",
      "==================================================\n",
      "Epoch [64/100], Step [0/254], Loss: 0.3428, Accuracy: 0.8906\n",
      "Epoch [64/100], Step [100/254], Loss: 0.1838, Accuracy: 0.9375\n",
      "Epoch [64/100], Step [200/254], Loss: 0.3529, Accuracy: 0.9219\n",
      "Epoch [64/100], Train Loss: 0.2598, Val Loss: 0.2216, Train Acc: 0.9067, Val Acc: 0.9211\n",
      "==================================================\n",
      "Epoch [65/100], Step [0/254], Loss: 0.1964, Accuracy: 0.9375\n",
      "Epoch [65/100], Step [100/254], Loss: 0.2295, Accuracy: 0.9062\n",
      "Epoch [65/100], Step [200/254], Loss: 0.3189, Accuracy: 0.8906\n",
      "Epoch [65/100], Train Loss: 0.2579, Val Loss: 0.2174, Train Acc: 0.9066, Val Acc: 0.9198\n",
      "==================================================\n",
      "Epoch [66/100], Step [0/254], Loss: 0.1742, Accuracy: 0.9375\n",
      "Epoch [66/100], Step [100/254], Loss: 0.2078, Accuracy: 0.9219\n",
      "Epoch [66/100], Step [200/254], Loss: 0.3159, Accuracy: 0.8906\n",
      "Epoch [66/100], Train Loss: 0.2736, Val Loss: 0.2215, Train Acc: 0.9003, Val Acc: 0.9201\n",
      "==================================================\n",
      "CPU times: user 9h 36min 23s, sys: 21min 43s, total: 9h 58min 7s\n",
      "Wall time: 1h 15min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MobileNetV3Elu(\n",
    "    in_chn=3,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train(model, device, trainLoader, valLoader, criterion, optimizer, n_epochs, earlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 1.43 s, total: 31.6 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predElu, actualElu = infer(model, device, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "eluAcc = (torch.argmax(predElu, dim=1) == actualElu).float().mean()\n",
    "print(f\"Test Accuracy: {geluAcc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using LeakyRelu instead of hardswish in Bottleneck block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LeakyReLU\n",
    "\n",
    "\n",
    "class MobileNetV3Leaky(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chn,\n",
    "        se_reduction=4,\n",
    "        mode=\"small\",\n",
    "        num_classes=10,\n",
    "        bn_eps=0.001,\n",
    "        bn_momentum=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if mode == \"small\":\n",
    "            # MobileNetV3-Small\n",
    "            layers_config = [\n",
    "                [3, 16, 16, True, ReLU, 2],\n",
    "                [3, 72, 24, False, ReLU, 2],\n",
    "                [3, 88, 24, False, ReLU, 1],\n",
    "                [5, 96, 40, True, LeakyReLU, 2],\n",
    "                [5, 240, 40, True, LeakyReLU, 1],\n",
    "                [5, 240, 40, True, LeakyReLU, 1],\n",
    "                [5, 120, 48, True, LeakyReLU, 1],\n",
    "                [5, 144, 48, True, LeakyReLU, 1],\n",
    "                [5, 288, 96, True, LeakyReLU, 2],\n",
    "                [5, 576, 96, True, LeakyReLU, 1],\n",
    "                [5, 576, 96, True, LeakyReLU, 1],\n",
    "            ]\n",
    "            last_channel = 1280\n",
    "            # final layer\n",
    "            self.final_layers = [\n",
    "                ConvBlock(\n",
    "                    layers_config[-1][2], 576, activation=Hardswish, kernel_size=1\n",
    "                ),\n",
    "                SqueezeAndExcite(576, se_reduction),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(576, last_channel, 1),\n",
    "                Hardswish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(last_channel, num_classes),\n",
    "            ]\n",
    "\n",
    "        # Initial layers\n",
    "        self.features: list[nn.Module] = [\n",
    "            ConvBlock(in_chn, 16, activation=Hardswish, kernel_size=3, stride=2)\n",
    "        ]\n",
    "        #         print(dir(self.features[-1]))\n",
    "\n",
    "        # Build main blocks\n",
    "\n",
    "        input_channel = 16\n",
    "        for kernel, exp, out, se, act, stride in layers_config:\n",
    "            self.features.append(\n",
    "                BottleNeck(\n",
    "                    in_chn=input_channel,\n",
    "                    out_chn=out,\n",
    "                    expansion_channel=exp,\n",
    "                    activation=act,\n",
    "                    kernel=kernel,\n",
    "                    se_flag=se,\n",
    "                    stride=stride,\n",
    "                )\n",
    "            )\n",
    "            input_channel = out\n",
    "\n",
    "        self.start = nn.Sequential(*self.features)\n",
    "        self.final = nn.Sequential(*self.final_layers)\n",
    "\n",
    "        # modify batchnorm layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eps = bn_eps\n",
    "                m.momentum = bn_momentum\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/254], Loss: 2.3042, Accuracy: 0.0469\n",
      "Epoch [1/100], Step [100/254], Loss: 1.4230, Accuracy: 0.4531\n",
      "Epoch [1/100], Step [200/254], Loss: 1.0796, Accuracy: 0.5312\n",
      "Epoch [1/100], Train Loss: 1.2976, Val Loss: 3.3156, Train Acc: 0.5125, Val Acc: 0.0738\n",
      "==================================================\n",
      "Epoch [2/100], Step [0/254], Loss: 1.0535, Accuracy: 0.5469\n",
      "Epoch [2/100], Step [100/254], Loss: 0.9163, Accuracy: 0.6094\n",
      "Epoch [2/100], Step [200/254], Loss: 0.6824, Accuracy: 0.7656\n",
      "Epoch [2/100], Train Loss: 0.9217, Val Loss: 2.8344, Train Acc: 0.6688, Val Acc: 0.2652\n",
      "==================================================\n",
      "Epoch [3/100], Step [0/254], Loss: 0.8961, Accuracy: 0.6875\n",
      "Epoch [3/100], Step [100/254], Loss: 0.7060, Accuracy: 0.7500\n",
      "Epoch [3/100], Step [200/254], Loss: 0.7184, Accuracy: 0.6719\n",
      "Epoch [3/100], Train Loss: 0.8171, Val Loss: 0.9022, Train Acc: 0.7063, Val Acc: 0.6848\n",
      "==================================================\n",
      "Epoch [4/100], Step [0/254], Loss: 0.6913, Accuracy: 0.7812\n",
      "Epoch [4/100], Step [100/254], Loss: 1.1335, Accuracy: 0.6406\n",
      "Epoch [4/100], Step [200/254], Loss: 0.7924, Accuracy: 0.7344\n",
      "Epoch [4/100], Train Loss: 0.7540, Val Loss: 0.7250, Train Acc: 0.7336, Val Acc: 0.7472\n",
      "==================================================\n",
      "Epoch [5/100], Step [0/254], Loss: 0.6015, Accuracy: 0.8281\n",
      "Epoch [5/100], Step [100/254], Loss: 0.7950, Accuracy: 0.7031\n",
      "Epoch [5/100], Step [200/254], Loss: 0.6332, Accuracy: 0.7969\n",
      "Epoch [5/100], Train Loss: 0.7034, Val Loss: 1.1144, Train Acc: 0.7490, Val Acc: 0.6396\n",
      "==================================================\n",
      "Epoch [6/100], Step [0/254], Loss: 0.8245, Accuracy: 0.6719\n",
      "Epoch [6/100], Step [100/254], Loss: 0.8196, Accuracy: 0.6875\n",
      "Epoch [6/100], Step [200/254], Loss: 0.5780, Accuracy: 0.8125\n",
      "Epoch [6/100], Train Loss: 0.6683, Val Loss: 0.7595, Train Acc: 0.7654, Val Acc: 0.7359\n",
      "==================================================\n",
      "Epoch [7/100], Step [0/254], Loss: 0.6949, Accuracy: 0.7500\n",
      "Epoch [7/100], Step [100/254], Loss: 0.6096, Accuracy: 0.7812\n",
      "Epoch [7/100], Step [200/254], Loss: 0.5566, Accuracy: 0.8125\n",
      "Epoch [7/100], Train Loss: 0.6259, Val Loss: 0.6550, Train Acc: 0.7792, Val Acc: 0.7706\n",
      "==================================================\n",
      "Epoch [8/100], Step [0/254], Loss: 0.5064, Accuracy: 0.8125\n",
      "Epoch [8/100], Step [100/254], Loss: 0.8951, Accuracy: 0.6875\n",
      "Epoch [8/100], Step [200/254], Loss: 0.7336, Accuracy: 0.6875\n",
      "Epoch [8/100], Train Loss: 0.5957, Val Loss: 0.5947, Train Acc: 0.7911, Val Acc: 0.7961\n",
      "==================================================\n",
      "Epoch [9/100], Step [0/254], Loss: 0.7489, Accuracy: 0.7500\n",
      "Epoch [9/100], Step [100/254], Loss: 0.4050, Accuracy: 0.8125\n",
      "Epoch [9/100], Step [200/254], Loss: 0.4793, Accuracy: 0.8281\n",
      "Epoch [9/100], Train Loss: 0.5559, Val Loss: 0.7056, Train Acc: 0.8052, Val Acc: 0.7688\n",
      "==================================================\n",
      "Epoch [10/100], Step [0/254], Loss: 0.3745, Accuracy: 0.8750\n",
      "Epoch [10/100], Step [100/254], Loss: 0.6023, Accuracy: 0.8125\n",
      "Epoch [10/100], Step [200/254], Loss: 0.5646, Accuracy: 0.7500\n",
      "Epoch [10/100], Train Loss: 0.5224, Val Loss: 0.7149, Train Acc: 0.8139, Val Acc: 0.7577\n",
      "==================================================\n",
      "Epoch [11/100], Step [0/254], Loss: 0.4100, Accuracy: 0.8750\n",
      "Epoch [11/100], Step [100/254], Loss: 0.3335, Accuracy: 0.8594\n",
      "Epoch [11/100], Step [200/254], Loss: 0.5420, Accuracy: 0.7812\n",
      "Epoch [11/100], Train Loss: 0.4984, Val Loss: 0.5284, Train Acc: 0.8245, Val Acc: 0.8150\n",
      "==================================================\n",
      "Epoch [12/100], Step [0/254], Loss: 0.5212, Accuracy: 0.7969\n",
      "Epoch [12/100], Step [100/254], Loss: 0.4441, Accuracy: 0.8594\n",
      "Epoch [12/100], Step [200/254], Loss: 0.3808, Accuracy: 0.8906\n",
      "Epoch [12/100], Train Loss: 0.4698, Val Loss: 0.6575, Train Acc: 0.8356, Val Acc: 0.7884\n",
      "==================================================\n",
      "Epoch [13/100], Step [0/254], Loss: 0.4902, Accuracy: 0.8438\n",
      "Epoch [13/100], Step [100/254], Loss: 0.4417, Accuracy: 0.8281\n",
      "Epoch [13/100], Step [200/254], Loss: 0.3902, Accuracy: 0.8750\n",
      "Epoch [13/100], Train Loss: 0.4458, Val Loss: 0.6746, Train Acc: 0.8452, Val Acc: 0.7772\n",
      "==================================================\n",
      "Epoch [14/100], Step [0/254], Loss: 0.5446, Accuracy: 0.8125\n",
      "Epoch [14/100], Step [100/254], Loss: 0.6022, Accuracy: 0.7969\n",
      "Epoch [14/100], Step [200/254], Loss: 0.3443, Accuracy: 0.8750\n",
      "Epoch [14/100], Train Loss: 0.4304, Val Loss: 0.8157, Train Acc: 0.8485, Val Acc: 0.7577\n",
      "==================================================\n",
      "Epoch [15/100], Step [0/254], Loss: 0.3309, Accuracy: 0.8750\n",
      "Epoch [15/100], Step [100/254], Loss: 0.3434, Accuracy: 0.8906\n",
      "Epoch [15/100], Step [200/254], Loss: 0.6441, Accuracy: 0.7969\n",
      "Epoch [15/100], Train Loss: 0.4317, Val Loss: 0.5219, Train Acc: 0.8494, Val Acc: 0.8168\n",
      "==================================================\n",
      "Epoch [16/100], Step [0/254], Loss: 0.3293, Accuracy: 0.8906\n",
      "Epoch [16/100], Step [100/254], Loss: 0.2536, Accuracy: 0.8906\n",
      "Epoch [16/100], Step [200/254], Loss: 0.3718, Accuracy: 0.8594\n",
      "Epoch [16/100], Train Loss: 0.4042, Val Loss: 0.9993, Train Acc: 0.8609, Val Acc: 0.7270\n",
      "==================================================\n",
      "Epoch [17/100], Step [0/254], Loss: 0.3840, Accuracy: 0.8594\n",
      "Epoch [17/100], Step [100/254], Loss: 0.4519, Accuracy: 0.8594\n",
      "Epoch [17/100], Step [200/254], Loss: 0.2631, Accuracy: 0.8594\n",
      "Epoch [17/100], Train Loss: 0.3899, Val Loss: 0.3899, Train Acc: 0.8601, Val Acc: 0.8616\n",
      "==================================================\n",
      "Epoch [18/100], Step [0/254], Loss: 0.5190, Accuracy: 0.8125\n",
      "Epoch [18/100], Step [100/254], Loss: 0.4241, Accuracy: 0.8594\n",
      "Epoch [18/100], Step [200/254], Loss: 0.1519, Accuracy: 0.9531\n",
      "Epoch [18/100], Train Loss: 0.3975, Val Loss: 0.3553, Train Acc: 0.8623, Val Acc: 0.8748\n",
      "==================================================\n",
      "Epoch [19/100], Step [0/254], Loss: 0.2844, Accuracy: 0.8906\n",
      "Epoch [19/100], Step [100/254], Loss: 0.3822, Accuracy: 0.8594\n",
      "Epoch [19/100], Step [200/254], Loss: 0.2984, Accuracy: 0.9219\n",
      "Epoch [19/100], Train Loss: 0.3819, Val Loss: 0.6305, Train Acc: 0.8649, Val Acc: 0.7881\n",
      "==================================================\n",
      "Epoch [20/100], Step [0/254], Loss: 0.3110, Accuracy: 0.9062\n",
      "Epoch [20/100], Step [100/254], Loss: 0.3397, Accuracy: 0.9062\n",
      "Epoch [20/100], Step [200/254], Loss: 0.3680, Accuracy: 0.8750\n",
      "Epoch [20/100], Train Loss: 0.3638, Val Loss: 0.4782, Train Acc: 0.8736, Val Acc: 0.8456\n",
      "==================================================\n",
      "Epoch [21/100], Step [0/254], Loss: 0.5348, Accuracy: 0.8125\n",
      "Epoch [21/100], Step [100/254], Loss: 0.2502, Accuracy: 0.9219\n",
      "Epoch [21/100], Step [200/254], Loss: 0.2680, Accuracy: 0.9062\n",
      "Epoch [21/100], Train Loss: 0.3549, Val Loss: 0.4930, Train Acc: 0.8771, Val Acc: 0.8292\n",
      "==================================================\n",
      "Epoch [22/100], Step [0/254], Loss: 0.4912, Accuracy: 0.8438\n",
      "Epoch [22/100], Step [100/254], Loss: 0.5737, Accuracy: 0.7812\n",
      "Epoch [22/100], Step [200/254], Loss: 0.3058, Accuracy: 0.8594\n",
      "Epoch [22/100], Train Loss: 0.3513, Val Loss: 0.3218, Train Acc: 0.8754, Val Acc: 0.8857\n",
      "==================================================\n",
      "Epoch [23/100], Step [0/254], Loss: 0.3330, Accuracy: 0.8750\n",
      "Epoch [23/100], Step [100/254], Loss: 0.2556, Accuracy: 0.9219\n",
      "Epoch [23/100], Step [200/254], Loss: 0.2670, Accuracy: 0.9062\n",
      "Epoch [23/100], Train Loss: 0.3444, Val Loss: 0.3929, Train Acc: 0.8792, Val Acc: 0.8713\n",
      "==================================================\n",
      "Epoch [24/100], Step [0/254], Loss: 0.2401, Accuracy: 0.9062\n",
      "Epoch [24/100], Step [100/254], Loss: 0.3431, Accuracy: 0.9062\n",
      "Epoch [24/100], Step [200/254], Loss: 0.4578, Accuracy: 0.8594\n",
      "Epoch [24/100], Train Loss: 0.3249, Val Loss: 0.4564, Train Acc: 0.8866, Val Acc: 0.8386\n",
      "==================================================\n",
      "Epoch [25/100], Step [0/254], Loss: 0.3444, Accuracy: 0.9219\n",
      "Epoch [25/100], Step [100/254], Loss: 0.2683, Accuracy: 0.9062\n",
      "Epoch [25/100], Step [200/254], Loss: 0.2649, Accuracy: 0.9219\n",
      "Epoch [25/100], Train Loss: 0.3125, Val Loss: 0.4311, Train Acc: 0.8920, Val Acc: 0.8479\n",
      "==================================================\n",
      "Epoch [26/100], Step [0/254], Loss: 0.2447, Accuracy: 0.9375\n",
      "Epoch [26/100], Step [100/254], Loss: 0.2543, Accuracy: 0.9062\n",
      "Epoch [26/100], Step [200/254], Loss: 0.2922, Accuracy: 0.9062\n",
      "Epoch [26/100], Train Loss: 0.3182, Val Loss: 0.3715, Train Acc: 0.8910, Val Acc: 0.8709\n",
      "==================================================\n",
      "Epoch [27/100], Step [0/254], Loss: 0.2172, Accuracy: 0.9219\n",
      "Epoch [27/100], Step [100/254], Loss: 0.2783, Accuracy: 0.9062\n",
      "Epoch [27/100], Step [200/254], Loss: 0.2627, Accuracy: 0.9062\n",
      "Epoch [27/100], Train Loss: 0.2643, Val Loss: 0.2194, Train Acc: 0.9057, Val Acc: 0.9223\n",
      "==================================================\n",
      "Epoch [28/100], Step [0/254], Loss: 0.1871, Accuracy: 0.9375\n",
      "Epoch [28/100], Step [100/254], Loss: 0.2141, Accuracy: 0.9062\n",
      "Epoch [28/100], Step [200/254], Loss: 0.3518, Accuracy: 0.8906\n",
      "Epoch [28/100], Train Loss: 0.2466, Val Loss: 0.2081, Train Acc: 0.9144, Val Acc: 0.9259\n",
      "==================================================\n",
      "Epoch [29/100], Step [0/254], Loss: 0.2799, Accuracy: 0.9219\n",
      "Epoch [29/100], Step [100/254], Loss: 0.2944, Accuracy: 0.8750\n",
      "Epoch [29/100], Step [200/254], Loss: 0.2987, Accuracy: 0.8750\n",
      "Epoch [29/100], Train Loss: 0.2516, Val Loss: 0.2037, Train Acc: 0.9110, Val Acc: 0.9293\n",
      "==================================================\n",
      "Epoch [30/100], Step [0/254], Loss: 0.3201, Accuracy: 0.9062\n",
      "Epoch [30/100], Step [100/254], Loss: 0.4412, Accuracy: 0.8438\n",
      "Epoch [30/100], Step [200/254], Loss: 0.2791, Accuracy: 0.8281\n",
      "Epoch [30/100], Train Loss: 0.2488, Val Loss: 0.1925, Train Acc: 0.9142, Val Acc: 0.9330\n",
      "==================================================\n",
      "Epoch [31/100], Step [0/254], Loss: 0.2570, Accuracy: 0.9375\n",
      "Epoch [31/100], Step [100/254], Loss: 0.1781, Accuracy: 0.9375\n",
      "Epoch [31/100], Step [200/254], Loss: 0.2156, Accuracy: 0.9219\n",
      "Epoch [31/100], Train Loss: 0.2474, Val Loss: 0.2367, Train Acc: 0.9150, Val Acc: 0.9179\n",
      "==================================================\n",
      "Epoch [32/100], Step [0/254], Loss: 0.2759, Accuracy: 0.9062\n",
      "Epoch [32/100], Step [100/254], Loss: 0.2080, Accuracy: 0.9219\n",
      "Epoch [32/100], Step [200/254], Loss: 0.1867, Accuracy: 0.9219\n",
      "Epoch [32/100], Train Loss: 0.2285, Val Loss: 0.1957, Train Acc: 0.9200, Val Acc: 0.9299\n",
      "==================================================\n",
      "Epoch [33/100], Step [0/254], Loss: 0.0876, Accuracy: 0.9844\n",
      "Epoch [33/100], Step [100/254], Loss: 0.2561, Accuracy: 0.9375\n",
      "Epoch [33/100], Step [200/254], Loss: 0.2483, Accuracy: 0.9219\n",
      "Epoch [33/100], Train Loss: 0.2379, Val Loss: 0.2099, Train Acc: 0.9136, Val Acc: 0.9241\n",
      "==================================================\n",
      "Epoch [34/100], Step [0/254], Loss: 0.2107, Accuracy: 0.9219\n",
      "Epoch [34/100], Step [100/254], Loss: 0.1303, Accuracy: 0.9375\n",
      "Epoch [34/100], Step [200/254], Loss: 0.1944, Accuracy: 0.9062\n",
      "Epoch [34/100], Train Loss: 0.2345, Val Loss: 0.2029, Train Acc: 0.9174, Val Acc: 0.9282\n",
      "==================================================\n",
      "Epoch [35/100], Step [0/254], Loss: 0.2849, Accuracy: 0.8906\n",
      "Epoch [35/100], Step [100/254], Loss: 0.2193, Accuracy: 0.9375\n",
      "Epoch [35/100], Step [200/254], Loss: 0.1416, Accuracy: 0.9531\n",
      "Epoch [35/100], Train Loss: 0.2299, Val Loss: 0.1847, Train Acc: 0.9172, Val Acc: 0.9336\n",
      "==================================================\n",
      "Epoch [36/100], Step [0/254], Loss: 0.2953, Accuracy: 0.8594\n",
      "Epoch [36/100], Step [100/254], Loss: 0.0829, Accuracy: 0.9688\n",
      "Epoch [36/100], Step [200/254], Loss: 0.3703, Accuracy: 0.8281\n",
      "Epoch [36/100], Train Loss: 0.2221, Val Loss: 0.1775, Train Acc: 0.9213, Val Acc: 0.9383\n",
      "==================================================\n",
      "Epoch [37/100], Step [0/254], Loss: 0.3850, Accuracy: 0.8594\n",
      "Epoch [37/100], Step [100/254], Loss: 0.1760, Accuracy: 0.9531\n",
      "Epoch [37/100], Step [200/254], Loss: 0.1012, Accuracy: 0.9688\n",
      "Epoch [37/100], Train Loss: 0.2160, Val Loss: 0.1729, Train Acc: 0.9240, Val Acc: 0.9374\n",
      "==================================================\n",
      "Epoch [38/100], Step [0/254], Loss: 0.1901, Accuracy: 0.9062\n",
      "Epoch [38/100], Step [100/254], Loss: 0.2528, Accuracy: 0.9062\n",
      "Epoch [38/100], Step [200/254], Loss: 0.1323, Accuracy: 0.9844\n",
      "Epoch [38/100], Train Loss: 0.2171, Val Loss: 0.1779, Train Acc: 0.9221, Val Acc: 0.9371\n",
      "==================================================\n",
      "Epoch [39/100], Step [0/254], Loss: 0.1275, Accuracy: 0.9688\n",
      "Epoch [39/100], Step [100/254], Loss: 0.2865, Accuracy: 0.9062\n",
      "Epoch [39/100], Step [200/254], Loss: 0.4320, Accuracy: 0.8281\n",
      "Epoch [39/100], Train Loss: 0.2129, Val Loss: 0.1680, Train Acc: 0.9245, Val Acc: 0.9406\n",
      "==================================================\n",
      "Epoch [40/100], Step [0/254], Loss: 0.1657, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [100/254], Loss: 0.1588, Accuracy: 0.9375\n",
      "Epoch [40/100], Step [200/254], Loss: 0.2877, Accuracy: 0.9062\n",
      "Epoch [40/100], Train Loss: 0.2136, Val Loss: 0.1774, Train Acc: 0.9210, Val Acc: 0.9370\n",
      "==================================================\n",
      "Epoch [41/100], Step [0/254], Loss: 0.3027, Accuracy: 0.9062\n",
      "Epoch [41/100], Step [100/254], Loss: 0.1369, Accuracy: 0.9531\n",
      "Epoch [41/100], Step [200/254], Loss: 0.0846, Accuracy: 0.9688\n",
      "Epoch [41/100], Train Loss: 0.2132, Val Loss: 0.1721, Train Acc: 0.9212, Val Acc: 0.9403\n",
      "==================================================\n",
      "Epoch [42/100], Step [0/254], Loss: 0.1243, Accuracy: 0.9531\n",
      "Epoch [42/100], Step [100/254], Loss: 0.1928, Accuracy: 0.9375\n",
      "Epoch [42/100], Step [200/254], Loss: 0.2288, Accuracy: 0.9062\n",
      "Epoch [42/100], Train Loss: 0.2143, Val Loss: 0.1704, Train Acc: 0.9255, Val Acc: 0.9409\n",
      "==================================================\n",
      "Epoch [43/100], Step [0/254], Loss: 0.3861, Accuracy: 0.8281\n",
      "Epoch [43/100], Step [100/254], Loss: 0.1880, Accuracy: 0.9219\n",
      "Epoch [43/100], Step [200/254], Loss: 0.1691, Accuracy: 0.9375\n",
      "Epoch [43/100], Train Loss: 0.2211, Val Loss: 0.1724, Train Acc: 0.9219, Val Acc: 0.9385\n",
      "==================================================\n",
      "Epoch [44/100], Step [0/254], Loss: 0.2027, Accuracy: 0.9219\n",
      "Epoch [44/100], Step [100/254], Loss: 0.1680, Accuracy: 0.9219\n",
      "Epoch [44/100], Step [200/254], Loss: 0.1521, Accuracy: 0.9375\n",
      "Epoch [44/100], Train Loss: 0.2142, Val Loss: 0.1696, Train Acc: 0.9240, Val Acc: 0.9386\n",
      "==================================================\n",
      "Epoch [45/100], Step [0/254], Loss: 0.1200, Accuracy: 0.9531\n",
      "Epoch [45/100], Step [100/254], Loss: 0.1533, Accuracy: 0.9531\n",
      "Epoch [45/100], Step [200/254], Loss: 0.1464, Accuracy: 0.9375\n",
      "Epoch [45/100], Train Loss: 0.2061, Val Loss: 0.1711, Train Acc: 0.9275, Val Acc: 0.9389\n",
      "==================================================\n",
      "Epoch [46/100], Step [0/254], Loss: 0.1573, Accuracy: 0.9531\n",
      "Epoch [46/100], Step [100/254], Loss: 0.1887, Accuracy: 0.9062\n",
      "Epoch [46/100], Step [200/254], Loss: 0.4404, Accuracy: 0.8281\n",
      "Epoch [46/100], Train Loss: 0.2093, Val Loss: 0.1686, Train Acc: 0.9277, Val Acc: 0.9399\n",
      "==================================================\n",
      "Epoch [47/100], Step [0/254], Loss: 0.2670, Accuracy: 0.9062\n",
      "Epoch [47/100], Step [100/254], Loss: 0.2090, Accuracy: 0.9219\n",
      "Epoch [47/100], Step [200/254], Loss: 0.2055, Accuracy: 0.9531\n",
      "Epoch [47/100], Train Loss: 0.2101, Val Loss: 0.1698, Train Acc: 0.9245, Val Acc: 0.9406\n",
      "==================================================\n",
      "Epoch [48/100], Step [0/254], Loss: 0.1901, Accuracy: 0.9531\n",
      "Epoch [48/100], Step [100/254], Loss: 0.0767, Accuracy: 0.9844\n",
      "Epoch [48/100], Step [200/254], Loss: 0.1535, Accuracy: 0.9531\n",
      "Epoch [48/100], Train Loss: 0.2103, Val Loss: 0.1664, Train Acc: 0.9266, Val Acc: 0.9414\n",
      "==================================================\n",
      "Epoch [49/100], Step [0/254], Loss: 0.1977, Accuracy: 0.9062\n",
      "Epoch [49/100], Step [100/254], Loss: 0.2043, Accuracy: 0.9375\n",
      "Epoch [49/100], Step [200/254], Loss: 0.1713, Accuracy: 0.9219\n",
      "Epoch [49/100], Train Loss: 0.2219, Val Loss: 0.1697, Train Acc: 0.9223, Val Acc: 0.9396\n",
      "==================================================\n",
      "Epoch [50/100], Step [0/254], Loss: 0.1987, Accuracy: 0.9062\n",
      "Epoch [50/100], Step [100/254], Loss: 0.1176, Accuracy: 0.9375\n",
      "Epoch [50/100], Step [200/254], Loss: 0.1547, Accuracy: 0.9375\n",
      "Epoch [50/100], Train Loss: 0.2070, Val Loss: 0.1670, Train Acc: 0.9265, Val Acc: 0.9401\n",
      "==================================================\n",
      "Epoch [51/100], Step [0/254], Loss: 0.1838, Accuracy: 0.9375\n",
      "Epoch [51/100], Step [100/254], Loss: 0.1501, Accuracy: 0.9219\n",
      "Epoch [51/100], Step [200/254], Loss: 0.1240, Accuracy: 0.9531\n",
      "Epoch [51/100], Train Loss: 0.2033, Val Loss: 0.1648, Train Acc: 0.9262, Val Acc: 0.9417\n",
      "==================================================\n",
      "Epoch [52/100], Step [0/254], Loss: 0.1115, Accuracy: 0.9688\n",
      "Epoch [52/100], Step [100/254], Loss: 0.1111, Accuracy: 0.9531\n",
      "Epoch [52/100], Step [200/254], Loss: 0.1482, Accuracy: 0.9375\n",
      "Epoch [52/100], Train Loss: 0.2185, Val Loss: 0.1711, Train Acc: 0.9239, Val Acc: 0.9386\n",
      "==================================================\n",
      "Epoch [53/100], Step [0/254], Loss: 0.2748, Accuracy: 0.8906\n",
      "Epoch [53/100], Step [100/254], Loss: 0.1719, Accuracy: 0.9375\n",
      "Epoch [53/100], Step [200/254], Loss: 0.1754, Accuracy: 0.9219\n",
      "Epoch [53/100], Train Loss: 0.2115, Val Loss: 0.1681, Train Acc: 0.9243, Val Acc: 0.9415\n",
      "==================================================\n",
      "Epoch [54/100], Step [0/254], Loss: 0.1203, Accuracy: 0.9688\n",
      "Epoch [54/100], Step [100/254], Loss: 0.0437, Accuracy: 1.0000\n",
      "Epoch [54/100], Step [200/254], Loss: 0.2320, Accuracy: 0.9531\n",
      "Epoch [54/100], Train Loss: 0.2050, Val Loss: 0.1676, Train Acc: 0.9278, Val Acc: 0.9412\n",
      "==================================================\n",
      "Epoch [55/100], Step [0/254], Loss: 0.1929, Accuracy: 0.9219\n",
      "Epoch [55/100], Step [100/254], Loss: 0.2316, Accuracy: 0.9688\n",
      "Epoch [55/100], Step [200/254], Loss: 0.1637, Accuracy: 0.9219\n",
      "Epoch [55/100], Train Loss: 0.2042, Val Loss: 0.1671, Train Acc: 0.9277, Val Acc: 0.9402\n",
      "==================================================\n",
      "Epoch [56/100], Step [0/254], Loss: 0.1454, Accuracy: 0.9375\n",
      "Epoch [56/100], Step [100/254], Loss: 0.3326, Accuracy: 0.8438\n",
      "Epoch [56/100], Step [200/254], Loss: 0.1847, Accuracy: 0.9219\n",
      "Epoch [56/100], Train Loss: 0.2071, Val Loss: 0.1666, Train Acc: 0.9245, Val Acc: 0.9421\n",
      "==================================================\n",
      "Epoch [57/100], Step [0/254], Loss: 0.2125, Accuracy: 0.9688\n",
      "Epoch [57/100], Step [100/254], Loss: 0.1702, Accuracy: 0.9375\n",
      "Epoch [57/100], Step [200/254], Loss: 0.1591, Accuracy: 0.9375\n",
      "Epoch [57/100], Train Loss: 0.2164, Val Loss: 0.1662, Train Acc: 0.9238, Val Acc: 0.9432\n",
      "==================================================\n",
      "Epoch [58/100], Step [0/254], Loss: 0.1936, Accuracy: 0.9219\n",
      "Epoch [58/100], Step [100/254], Loss: 0.2624, Accuracy: 0.9062\n",
      "Epoch [58/100], Step [200/254], Loss: 0.2144, Accuracy: 0.9375\n",
      "Epoch [58/100], Train Loss: 0.2132, Val Loss: 0.1702, Train Acc: 0.9237, Val Acc: 0.9405\n",
      "==================================================\n",
      "Epoch [59/100], Step [0/254], Loss: 0.2967, Accuracy: 0.8594\n",
      "Epoch [59/100], Step [100/254], Loss: 0.1244, Accuracy: 0.9531\n",
      "Epoch [59/100], Step [200/254], Loss: 0.2470, Accuracy: 0.9219\n",
      "Epoch [59/100], Train Loss: 0.2048, Val Loss: 0.1730, Train Acc: 0.9260, Val Acc: 0.9391\n",
      "==================================================\n",
      "Epoch [60/100], Step [0/254], Loss: 0.1931, Accuracy: 0.9375\n",
      "Epoch [60/100], Step [100/254], Loss: 0.1962, Accuracy: 0.9219\n",
      "Epoch [60/100], Step [200/254], Loss: 0.1895, Accuracy: 0.9219\n",
      "Epoch [60/100], Train Loss: 0.2118, Val Loss: 0.1700, Train Acc: 0.9232, Val Acc: 0.9402\n",
      "==================================================\n",
      "Epoch [61/100], Step [0/254], Loss: 0.1914, Accuracy: 0.8906\n",
      "Epoch [61/100], Step [100/254], Loss: 0.3249, Accuracy: 0.8438\n",
      "Epoch [61/100], Step [200/254], Loss: 0.2811, Accuracy: 0.8906\n",
      "Epoch [61/100], Train Loss: 0.2113, Val Loss: 0.1688, Train Acc: 0.9260, Val Acc: 0.9409\n",
      "==================================================\n",
      "Epoch [62/100], Step [0/254], Loss: 0.1531, Accuracy: 0.9375\n",
      "Epoch [62/100], Step [100/254], Loss: 0.1541, Accuracy: 0.9688\n",
      "Epoch [62/100], Step [200/254], Loss: 0.1238, Accuracy: 0.9531\n",
      "Epoch [62/100], Train Loss: 0.2035, Val Loss: 0.1680, Train Acc: 0.9280, Val Acc: 0.9395\n",
      "==================================================\n",
      "CPU times: user 8h 41min 10s, sys: 17min 22s, total: 8h 58min 32s\n",
      "Wall time: 1h 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MobileNetV3Leaky(\n",
    "    in_chn=3,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train(model, device, trainLoader, valLoader, criterion, optimizer, n_epochs, earlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 s, sys: 894 ms, total: 28 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predLeaky, actualLeaky = infer(model, device, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "predAcc = (torch.argmax(predLeaky, dim=1) == actualLeaky).float().mean()\n",
    "print(f\"Test Accuracy: {predAcc.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
