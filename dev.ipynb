{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/micromamba/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "dataPath = Path(\"tiny-imagenet\")\n",
    "if dataPath.exists() is False:\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    ds: DatasetDict = load_dataset(\"zh-plus/tiny-imagenet\")  # type: ignore\n",
    "    ds.save_to_disk(dataPath)  # type: ignore\n",
    "\n",
    "else:\n",
    "    from datasets import load_from_disk\n",
    "\n",
    "    ds: DatasetDict = load_from_disk(dataPath)  # type: ignore\n",
    "\n",
    "assert isinstance(ds, DatasetDict)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][1500][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"valid\"][900][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size = (64, 64)\n",
      "Mode = RGB\n",
      "Format = JPEG\n"
     ]
    }
   ],
   "source": [
    "img = ds[\"train\"][0][\"image\"]\n",
    "\n",
    "print(f\"Size = {img.size}\")\n",
    "print(f\"Mode = {img.mode}\")\n",
    "print(f\"Format = {img.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Prepare data for training and evaluating.\n",
    "\n",
    "Also augment the train data by introduce random effects like cropting, rotating, flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import functional as ImgF\n",
    "\n",
    "\n",
    "# ds[\"train\"][0][\"image\"] is a PIL.JpegImagePlugin.JpegImageFile\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of images and its labels. Return image and label. If transform is provided, apply it to the image.\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    IMG_SIZE = 64, 64\n",
    "\n",
    "    def transformBuild(self, normaliser):\n",
    "        transformations = []\n",
    "        transformations.append(v2.Resize(size=ImageDataset.IMG_SIZE))\n",
    "        if self.randCrop:\n",
    "            transformations.append(\n",
    "                v2.RandomResizedCrop(size=ImageDataset.IMG_SIZE, scale=(0.8, 1.0))\n",
    "            )\n",
    "        if self.randRot:\n",
    "            transformations.append(v2.RandomRotation(30))  # type: ignore\n",
    "        if self.randFlipH:\n",
    "            transformations.append(v2.RandomHorizontalFlip())\n",
    "        if self.randFlipV:\n",
    "            transformations.append(v2.RandomVerticalFlip())\n",
    "\n",
    "        transformations.append(v2.ToTensor())\n",
    "        transformations.append(normaliser)\n",
    "\n",
    "        return v2.Compose(transformations)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        randCrop=False,\n",
    "        randRot=False,\n",
    "        randFlipH=False,\n",
    "        randFlipV=False,\n",
    "        normaliser=None,\n",
    "    ):\n",
    "        self.randCrop = randCrop\n",
    "        self.randRot = randRot\n",
    "        self.randFlipH = randFlipH\n",
    "        self.randFlipV = randFlipV\n",
    "\n",
    "        self.length = len(data)\n",
    "        self.imgSize = self.IMG_SIZE\n",
    "\n",
    "        self.images = [d[\"image\"] for d in data]\n",
    "        self.labels = [d[\"label\"] for d in data]\n",
    "\n",
    "        # calculate normaliser if not provided\n",
    "        if normaliser is None:\n",
    "            mean = torch.zeros(3)\n",
    "            std = torch.zeros(3)\n",
    "\n",
    "            for img in self.images:\n",
    "                img = ImgF.to_tensor(img)\n",
    "                mean += img.mean(dim=(0, 1, 2))\n",
    "                std += img.std(dim=(0, 1, 2))\n",
    "\n",
    "            mean /= self.length\n",
    "            std /= self.length\n",
    "\n",
    "            normaliser = v2.Normalize(mean.tolist(), std.tolist())\n",
    "        self.normaliser = normaliser    \n",
    "\n",
    "        # build the transformer\n",
    "        self.imgTransformer = self.transformBuild(normaliser)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgTransformer(self.images[idx]), self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/micromamba/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# img255Scaler = v2.Lambda(lambda x: x / 255.0)\n",
    "# trainSet = ImageDataset(ds[\"train\"], True, True, True, True, img255Scaler)\n",
    "# test if augmentations are overdoing it\n",
    "trainSet = ImageDataset(ds[\"train\"])\n",
    "testSet = ImageDataset(ds[\"valid\"], normaliser=trainSet.normaliser)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "testLoader = DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = trainSet[0][0].size()\n",
    "sampleSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate if the image is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8052459..2.3207536].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_np = trainSet[0][0].permute(1, 2, 0).cpu().numpy()\n",
    "plt.imshow(img_np)\n",
    "plt.axis(\"off\")  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test output shape torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class SimpleCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCnn, self).__init__()        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.LazyLinear(512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = SimpleCnn()\n",
    "sampleBatchSize = sampleSize.insert(0, BATCH_SIZE)\n",
    "sampleIn = torch.randn(BATCH_SIZE, *sampleBatchSize)\n",
    "print(f\"test output shape {model(sampleIn).shape}\")\n",
    "\n",
    "del model\n",
    "del sampleBatchSize\n",
    "del sampleIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Step [0/1563], Loss: 6.9067, Accuracy: 0.0000\n",
      "Epoch [1/100], Step [100/1563], Loss: 5.2735, Accuracy: 0.0156\n",
      "Epoch [1/100], Step [200/1563], Loss: 5.0663, Accuracy: 0.0156\n",
      "Epoch [1/100], Step [300/1563], Loss: 4.9468, Accuracy: 0.0000\n",
      "Epoch [1/100], Step [400/1563], Loss: 4.8137, Accuracy: 0.0000\n",
      "Epoch [1/100], Step [500/1563], Loss: 4.7019, Accuracy: 0.0312\n",
      "Epoch [1/100], Step [600/1563], Loss: 4.4214, Accuracy: 0.0781\n",
      "Epoch [1/100], Step [700/1563], Loss: 4.7680, Accuracy: 0.0312\n",
      "Epoch [1/100], Step [800/1563], Loss: 4.7324, Accuracy: 0.0156\n",
      "Epoch [1/100], Step [900/1563], Loss: 4.1820, Accuracy: 0.1250\n",
      "Epoch [1/100], Step [1000/1563], Loss: 4.5219, Accuracy: 0.0625\n",
      "Epoch [1/100], Step [1100/1563], Loss: 4.4839, Accuracy: 0.0781\n",
      "Epoch [1/100], Step [1200/1563], Loss: 4.3178, Accuracy: 0.0625\n",
      "Epoch [1/100], Step [1300/1563], Loss: 4.4400, Accuracy: 0.0781\n",
      "Epoch [1/100], Step [1400/1563], Loss: 4.1520, Accuracy: 0.1094\n",
      "Epoch [1/100], Step [1500/1563], Loss: 4.3027, Accuracy: 0.0156\n",
      "Epoch [1/100] - Average Loss: 4.7037\n",
      "Epoch [2/100], Step [0/1563], Loss: 4.2667, Accuracy: 0.0781\n",
      "Epoch [2/100], Step [100/1563], Loss: 4.3608, Accuracy: 0.0781\n",
      "Epoch [2/100], Step [200/1563], Loss: 3.9497, Accuracy: 0.1094\n",
      "Epoch [2/100], Step [300/1563], Loss: 4.3590, Accuracy: 0.0938\n",
      "Epoch [2/100], Step [400/1563], Loss: 4.5207, Accuracy: 0.0625\n",
      "Epoch [2/100], Step [500/1563], Loss: 3.8697, Accuracy: 0.1562\n",
      "Epoch [2/100], Step [600/1563], Loss: 4.3544, Accuracy: 0.0781\n",
      "Epoch [2/100], Step [700/1563], Loss: 3.9547, Accuracy: 0.1250\n",
      "Epoch [2/100], Step [800/1563], Loss: 4.0958, Accuracy: 0.0625\n",
      "Epoch [2/100], Step [900/1563], Loss: 4.0418, Accuracy: 0.0781\n",
      "Epoch [2/100], Step [1000/1563], Loss: 3.5663, Accuracy: 0.1719\n",
      "Epoch [2/100], Step [1100/1563], Loss: 3.9164, Accuracy: 0.1406\n",
      "Epoch [2/100], Step [1200/1563], Loss: 4.2766, Accuracy: 0.1094\n",
      "Epoch [2/100], Step [1300/1563], Loss: 3.7355, Accuracy: 0.1719\n",
      "Epoch [2/100], Step [1400/1563], Loss: 3.9939, Accuracy: 0.1094\n",
      "Epoch [2/100], Step [1500/1563], Loss: 4.0121, Accuracy: 0.1719\n",
      "Epoch [2/100] - Average Loss: 4.1043\n",
      "Epoch [3/100], Step [0/1563], Loss: 4.0096, Accuracy: 0.1250\n",
      "Epoch [3/100], Step [100/1563], Loss: 4.1092, Accuracy: 0.1250\n",
      "Epoch [3/100], Step [200/1563], Loss: 3.9312, Accuracy: 0.1406\n",
      "Epoch [3/100], Step [300/1563], Loss: 3.4203, Accuracy: 0.1250\n",
      "Epoch [3/100], Step [400/1563], Loss: 3.9297, Accuracy: 0.0938\n",
      "Epoch [3/100], Step [500/1563], Loss: 4.0508, Accuracy: 0.0625\n",
      "Epoch [3/100], Step [600/1563], Loss: 3.8302, Accuracy: 0.1406\n",
      "Epoch [3/100], Step [700/1563], Loss: 3.8649, Accuracy: 0.1406\n",
      "Epoch [3/100], Step [800/1563], Loss: 3.8942, Accuracy: 0.0938\n",
      "Epoch [3/100], Step [900/1563], Loss: 4.1848, Accuracy: 0.0938\n",
      "Epoch [3/100], Step [1000/1563], Loss: 3.9168, Accuracy: 0.1875\n",
      "Epoch [3/100], Step [1100/1563], Loss: 3.7739, Accuracy: 0.2031\n",
      "Epoch [3/100], Step [1200/1563], Loss: 3.8029, Accuracy: 0.1406\n",
      "Epoch [3/100], Step [1300/1563], Loss: 3.5467, Accuracy: 0.1562\n",
      "Epoch [3/100], Step [1400/1563], Loss: 3.8162, Accuracy: 0.2031\n",
      "Epoch [3/100], Step [1500/1563], Loss: 3.4697, Accuracy: 0.1719\n",
      "Epoch [3/100] - Average Loss: 3.8649\n",
      "Epoch [4/100], Step [0/1563], Loss: 3.4593, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [100/1563], Loss: 3.6323, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [200/1563], Loss: 3.8993, Accuracy: 0.0938\n",
      "Epoch [4/100], Step [300/1563], Loss: 3.8464, Accuracy: 0.2500\n",
      "Epoch [4/100], Step [400/1563], Loss: 3.9841, Accuracy: 0.1094\n",
      "Epoch [4/100], Step [500/1563], Loss: 3.4056, Accuracy: 0.1719\n",
      "Epoch [4/100], Step [600/1563], Loss: 3.3712, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [700/1563], Loss: 3.4531, Accuracy: 0.1875\n",
      "Epoch [4/100], Step [800/1563], Loss: 3.6483, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [900/1563], Loss: 3.6333, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [1000/1563], Loss: 3.7180, Accuracy: 0.1719\n",
      "Epoch [4/100], Step [1100/1563], Loss: 3.6802, Accuracy: 0.1406\n",
      "Epoch [4/100], Step [1200/1563], Loss: 3.4654, Accuracy: 0.2031\n",
      "Epoch [4/100], Step [1300/1563], Loss: 3.5932, Accuracy: 0.1719\n",
      "Epoch [4/100], Step [1400/1563], Loss: 3.6639, Accuracy: 0.2344\n",
      "Epoch [4/100], Step [1500/1563], Loss: 3.7130, Accuracy: 0.1875\n",
      "Epoch [4/100] - Average Loss: 3.6605\n",
      "Epoch [5/100], Step [0/1563], Loss: 3.5303, Accuracy: 0.2500\n",
      "Epoch [5/100], Step [100/1563], Loss: 3.6730, Accuracy: 0.1719\n",
      "Epoch [5/100], Step [200/1563], Loss: 3.6901, Accuracy: 0.1406\n",
      "Epoch [5/100], Step [300/1563], Loss: 3.8099, Accuracy: 0.1094\n",
      "Epoch [5/100], Step [400/1563], Loss: 3.3760, Accuracy: 0.2500\n",
      "Epoch [5/100], Step [500/1563], Loss: 3.5709, Accuracy: 0.1875\n",
      "Epoch [5/100], Step [600/1563], Loss: 3.3859, Accuracy: 0.2188\n",
      "Epoch [5/100], Step [700/1563], Loss: 3.3528, Accuracy: 0.1250\n",
      "Epoch [5/100], Step [800/1563], Loss: 3.2872, Accuracy: 0.2656\n",
      "Epoch [5/100], Step [900/1563], Loss: 3.4646, Accuracy: 0.2031\n",
      "Epoch [5/100], Step [1000/1563], Loss: 3.4877, Accuracy: 0.2188\n",
      "Epoch [5/100], Step [1100/1563], Loss: 3.6829, Accuracy: 0.1719\n",
      "Epoch [5/100], Step [1200/1563], Loss: 3.2623, Accuracy: 0.2344\n",
      "Epoch [5/100], Step [1300/1563], Loss: 3.8319, Accuracy: 0.1094\n",
      "Epoch [5/100], Step [1400/1563], Loss: 3.5664, Accuracy: 0.2188\n",
      "Epoch [5/100], Step [1500/1563], Loss: 3.8886, Accuracy: 0.1562\n",
      "Epoch [5/100] - Average Loss: 3.5321\n",
      "Epoch [6/100], Step [0/1563], Loss: 3.3619, Accuracy: 0.2188\n",
      "Epoch [6/100], Step [100/1563], Loss: 3.6406, Accuracy: 0.2031\n",
      "Epoch [6/100], Step [200/1563], Loss: 3.6300, Accuracy: 0.1719\n",
      "Epoch [6/100], Step [300/1563], Loss: 3.3490, Accuracy: 0.2031\n",
      "Epoch [6/100], Step [400/1563], Loss: 3.3113, Accuracy: 0.2031\n",
      "Epoch [6/100], Step [500/1563], Loss: 3.2949, Accuracy: 0.1875\n",
      "Epoch [6/100], Step [600/1563], Loss: 3.2656, Accuracy: 0.2656\n",
      "Epoch [6/100], Step [700/1563], Loss: 3.4503, Accuracy: 0.2500\n",
      "Epoch [6/100], Step [800/1563], Loss: 3.3655, Accuracy: 0.2188\n",
      "Epoch [6/100], Step [900/1563], Loss: 3.5312, Accuracy: 0.1875\n",
      "Epoch [6/100], Step [1000/1563], Loss: 3.8350, Accuracy: 0.1562\n",
      "Epoch [6/100], Step [1100/1563], Loss: 3.6981, Accuracy: 0.2344\n",
      "Epoch [6/100], Step [1200/1563], Loss: 3.1247, Accuracy: 0.2031\n",
      "Epoch [6/100], Step [1300/1563], Loss: 3.1498, Accuracy: 0.2969\n",
      "Epoch [6/100], Step [1400/1563], Loss: 3.4308, Accuracy: 0.2344\n",
      "Epoch [6/100], Step [1500/1563], Loss: 3.4802, Accuracy: 0.2031\n",
      "Epoch [6/100] - Average Loss: 3.4483\n",
      "Epoch [7/100], Step [0/1563], Loss: 3.2172, Accuracy: 0.2500\n",
      "Epoch [7/100], Step [100/1563], Loss: 3.2471, Accuracy: 0.2812\n",
      "Epoch [7/100], Step [200/1563], Loss: 3.6467, Accuracy: 0.0938\n",
      "Epoch [7/100], Step [300/1563], Loss: 3.1127, Accuracy: 0.2969\n",
      "Epoch [7/100], Step [400/1563], Loss: 3.3273, Accuracy: 0.1875\n",
      "Epoch [7/100], Step [500/1563], Loss: 3.7623, Accuracy: 0.1562\n",
      "Epoch [7/100], Step [600/1563], Loss: 3.3858, Accuracy: 0.2344\n",
      "Epoch [7/100], Step [700/1563], Loss: 3.3764, Accuracy: 0.1875\n",
      "Epoch [7/100], Step [800/1563], Loss: 3.4618, Accuracy: 0.2188\n",
      "Epoch [7/100], Step [900/1563], Loss: 3.3387, Accuracy: 0.2500\n",
      "Epoch [7/100], Step [1000/1563], Loss: 3.6034, Accuracy: 0.1719\n",
      "Epoch [7/100], Step [1100/1563], Loss: 3.8729, Accuracy: 0.0938\n",
      "Epoch [7/100], Step [1200/1563], Loss: 3.4709, Accuracy: 0.1719\n",
      "Epoch [7/100], Step [1300/1563], Loss: 3.3844, Accuracy: 0.1562\n",
      "Epoch [7/100], Step [1400/1563], Loss: 3.3144, Accuracy: 0.2656\n",
      "Epoch [7/100], Step [1500/1563], Loss: 3.7321, Accuracy: 0.2188\n",
      "Epoch [7/100] - Average Loss: 3.4482\n",
      "Epoch [8/100], Step [0/1563], Loss: 3.2949, Accuracy: 0.2188\n",
      "Epoch [8/100], Step [100/1563], Loss: 3.0053, Accuracy: 0.3594\n",
      "Epoch [8/100], Step [200/1563], Loss: 3.0195, Accuracy: 0.3125\n",
      "Epoch [8/100], Step [300/1563], Loss: 3.3076, Accuracy: 0.2656\n",
      "Epoch [8/100], Step [400/1563], Loss: 3.6223, Accuracy: 0.2188\n",
      "Epoch [8/100], Step [500/1563], Loss: 3.3121, Accuracy: 0.2031\n",
      "Epoch [8/100], Step [600/1563], Loss: 3.6110, Accuracy: 0.2500\n",
      "Epoch [8/100], Step [700/1563], Loss: 3.2137, Accuracy: 0.2500\n",
      "Epoch [8/100], Step [800/1563], Loss: 3.3667, Accuracy: 0.2031\n",
      "Epoch [8/100], Step [900/1563], Loss: 3.3535, Accuracy: 0.2031\n",
      "Epoch [8/100], Step [1000/1563], Loss: 3.3476, Accuracy: 0.2188\n",
      "Epoch [8/100], Step [1100/1563], Loss: 3.5440, Accuracy: 0.1875\n",
      "Epoch [8/100], Step [1200/1563], Loss: 3.6357, Accuracy: 0.1875\n",
      "Epoch [8/100], Step [1300/1563], Loss: 3.0461, Accuracy: 0.3125\n",
      "Epoch [8/100], Step [1400/1563], Loss: 3.1779, Accuracy: 0.2656\n",
      "Epoch [8/100], Step [1500/1563], Loss: 3.4181, Accuracy: 0.1719\n",
      "Epoch [8/100] - Average Loss: 3.3042\n",
      "Epoch [9/100], Step [0/1563], Loss: 3.3170, Accuracy: 0.2188\n",
      "Epoch [9/100], Step [100/1563], Loss: 2.8911, Accuracy: 0.2812\n",
      "Epoch [9/100], Step [200/1563], Loss: 2.9955, Accuracy: 0.2812\n",
      "Epoch [9/100], Step [300/1563], Loss: 3.2703, Accuracy: 0.2812\n",
      "Epoch [9/100], Step [400/1563], Loss: 2.9760, Accuracy: 0.2656\n",
      "Epoch [9/100], Step [500/1563], Loss: 3.4924, Accuracy: 0.1562\n",
      "Epoch [9/100], Step [600/1563], Loss: 3.0661, Accuracy: 0.2656\n",
      "Epoch [9/100], Step [700/1563], Loss: 3.4737, Accuracy: 0.2031\n",
      "Epoch [9/100], Step [800/1563], Loss: 3.2517, Accuracy: 0.2969\n",
      "Epoch [9/100], Step [900/1563], Loss: 3.1929, Accuracy: 0.3281\n",
      "Epoch [9/100], Step [1000/1563], Loss: 2.9372, Accuracy: 0.2656\n",
      "Epoch [9/100], Step [1100/1563], Loss: 2.6241, Accuracy: 0.3281\n",
      "Epoch [9/100], Step [1200/1563], Loss: 3.2204, Accuracy: 0.1719\n",
      "Epoch [9/100], Step [1300/1563], Loss: 2.8335, Accuracy: 0.3125\n",
      "Epoch [9/100], Step [1400/1563], Loss: 3.3263, Accuracy: 0.2812\n",
      "Epoch [9/100], Step [1500/1563], Loss: 2.7955, Accuracy: 0.2812\n",
      "Epoch [9/100] - Average Loss: 3.2642\n",
      "Epoch [10/100], Step [0/1563], Loss: 3.3639, Accuracy: 0.2344\n",
      "Epoch [10/100], Step [100/1563], Loss: 2.9215, Accuracy: 0.3750\n",
      "Epoch [10/100], Step [200/1563], Loss: 3.0531, Accuracy: 0.2969\n",
      "Epoch [10/100], Step [300/1563], Loss: 3.0708, Accuracy: 0.2188\n",
      "Epoch [10/100], Step [400/1563], Loss: 2.9769, Accuracy: 0.3438\n",
      "Epoch [10/100], Step [500/1563], Loss: 3.1494, Accuracy: 0.2344\n",
      "Epoch [10/100], Step [600/1563], Loss: 3.0980, Accuracy: 0.2812\n",
      "Epoch [10/100], Step [700/1563], Loss: 2.8218, Accuracy: 0.3125\n",
      "Epoch [10/100], Step [800/1563], Loss: 2.8838, Accuracy: 0.2500\n",
      "Epoch [10/100], Step [900/1563], Loss: 3.4989, Accuracy: 0.1719\n",
      "Epoch [10/100], Step [1000/1563], Loss: 3.2305, Accuracy: 0.2812\n",
      "Epoch [10/100], Step [1100/1563], Loss: 2.8954, Accuracy: 0.2969\n",
      "Epoch [10/100], Step [1200/1563], Loss: 3.0171, Accuracy: 0.2344\n",
      "Epoch [10/100], Step [1300/1563], Loss: 3.1305, Accuracy: 0.2500\n",
      "Epoch [10/100], Step [1400/1563], Loss: 2.9092, Accuracy: 0.2812\n",
      "Epoch [10/100], Step [1500/1563], Loss: 2.9211, Accuracy: 0.3125\n",
      "Epoch [10/100] - Average Loss: 3.1368\n",
      "Epoch [11/100], Step [0/1563], Loss: 2.9574, Accuracy: 0.2812\n",
      "Epoch [11/100], Step [100/1563], Loss: 3.1376, Accuracy: 0.1719\n",
      "Epoch [11/100], Step [200/1563], Loss: 2.9973, Accuracy: 0.2812\n",
      "Epoch [11/100], Step [300/1563], Loss: 3.3350, Accuracy: 0.2656\n",
      "Epoch [11/100], Step [400/1563], Loss: 2.8213, Accuracy: 0.3125\n",
      "Epoch [11/100], Step [500/1563], Loss: 2.9568, Accuracy: 0.2656\n",
      "Epoch [11/100], Step [600/1563], Loss: 3.0331, Accuracy: 0.2969\n",
      "Epoch [11/100], Step [700/1563], Loss: 2.9747, Accuracy: 0.3281\n",
      "Epoch [11/100], Step [800/1563], Loss: 2.9506, Accuracy: 0.2969\n",
      "Epoch [11/100], Step [900/1563], Loss: 3.0667, Accuracy: 0.2812\n",
      "Epoch [11/100], Step [1000/1563], Loss: 3.0519, Accuracy: 0.3438\n",
      "Epoch [11/100], Step [1100/1563], Loss: 2.9753, Accuracy: 0.3281\n",
      "Epoch [11/100], Step [1200/1563], Loss: 3.5022, Accuracy: 0.2812\n",
      "Epoch [11/100], Step [1300/1563], Loss: 2.6965, Accuracy: 0.2969\n",
      "Epoch [11/100], Step [1400/1563], Loss: 2.8070, Accuracy: 0.2969\n",
      "Epoch [11/100], Step [1500/1563], Loss: 3.0684, Accuracy: 0.3125\n",
      "Epoch [11/100] - Average Loss: 3.0557\n",
      "Epoch [12/100], Step [0/1563], Loss: 3.2071, Accuracy: 0.2031\n",
      "Epoch [12/100], Step [100/1563], Loss: 3.1137, Accuracy: 0.2500\n",
      "Epoch [12/100], Step [200/1563], Loss: 2.9999, Accuracy: 0.1875\n",
      "Epoch [12/100], Step [300/1563], Loss: 3.1577, Accuracy: 0.2969\n",
      "Epoch [12/100], Step [400/1563], Loss: 3.1644, Accuracy: 0.2656\n",
      "Epoch [12/100], Step [500/1563], Loss: 2.9559, Accuracy: 0.3125\n",
      "Epoch [12/100], Step [600/1563], Loss: 2.5541, Accuracy: 0.4375\n",
      "Epoch [12/100], Step [700/1563], Loss: 2.9770, Accuracy: 0.2500\n",
      "Epoch [12/100], Step [800/1563], Loss: 2.8670, Accuracy: 0.2969\n",
      "Epoch [12/100], Step [900/1563], Loss: 2.9315, Accuracy: 0.3281\n",
      "Epoch [12/100], Step [1000/1563], Loss: 3.0526, Accuracy: 0.2656\n",
      "Epoch [12/100], Step [1100/1563], Loss: 3.2532, Accuracy: 0.2188\n",
      "Epoch [12/100], Step [1200/1563], Loss: 3.0814, Accuracy: 0.3281\n",
      "Epoch [12/100], Step [1300/1563], Loss: 2.9353, Accuracy: 0.2344\n",
      "Epoch [12/100], Step [1400/1563], Loss: 2.9829, Accuracy: 0.2812\n",
      "Epoch [12/100], Step [1500/1563], Loss: 2.6110, Accuracy: 0.3438\n",
      "Epoch [12/100] - Average Loss: 2.9820\n",
      "Epoch [13/100], Step [0/1563], Loss: 3.0230, Accuracy: 0.2500\n",
      "Epoch [13/100], Step [100/1563], Loss: 2.9000, Accuracy: 0.2812\n",
      "Epoch [13/100], Step [200/1563], Loss: 2.8232, Accuracy: 0.3125\n",
      "Epoch [13/100], Step [300/1563], Loss: 2.8431, Accuracy: 0.3125\n",
      "Epoch [13/100], Step [400/1563], Loss: 3.0380, Accuracy: 0.3125\n",
      "Epoch [13/100], Step [500/1563], Loss: 3.0506, Accuracy: 0.2656\n",
      "Epoch [13/100], Step [600/1563], Loss: 2.9148, Accuracy: 0.4062\n",
      "Epoch [13/100], Step [700/1563], Loss: 3.2318, Accuracy: 0.2656\n",
      "Epoch [13/100], Step [800/1563], Loss: 2.8402, Accuracy: 0.2969\n",
      "Epoch [13/100], Step [900/1563], Loss: 2.5812, Accuracy: 0.3750\n",
      "Epoch [13/100], Step [1000/1563], Loss: 2.5337, Accuracy: 0.3594\n",
      "Epoch [13/100], Step [1100/1563], Loss: 2.9695, Accuracy: 0.2969\n",
      "Epoch [13/100], Step [1200/1563], Loss: 3.0848, Accuracy: 0.3125\n",
      "Epoch [13/100], Step [1300/1563], Loss: 2.8382, Accuracy: 0.3438\n",
      "Epoch [13/100], Step [1400/1563], Loss: 2.8132, Accuracy: 0.2969\n",
      "Epoch [13/100], Step [1500/1563], Loss: 2.8024, Accuracy: 0.3594\n",
      "Epoch [13/100] - Average Loss: 2.9262\n",
      "Epoch [14/100], Step [0/1563], Loss: 2.6743, Accuracy: 0.3594\n",
      "Epoch [14/100], Step [100/1563], Loss: 3.2237, Accuracy: 0.2656\n",
      "Epoch [14/100], Step [200/1563], Loss: 2.8272, Accuracy: 0.2656\n",
      "Epoch [14/100], Step [300/1563], Loss: 2.8078, Accuracy: 0.3438\n",
      "Epoch [14/100], Step [400/1563], Loss: 3.1522, Accuracy: 0.3281\n",
      "Epoch [14/100], Step [500/1563], Loss: 2.7101, Accuracy: 0.3281\n",
      "Epoch [14/100], Step [600/1563], Loss: 2.7238, Accuracy: 0.3281\n",
      "Epoch [14/100], Step [700/1563], Loss: 2.9856, Accuracy: 0.2344\n",
      "Epoch [14/100], Step [800/1563], Loss: 3.0827, Accuracy: 0.2344\n",
      "Epoch [14/100], Step [900/1563], Loss: 2.9432, Accuracy: 0.2344\n",
      "Epoch [14/100], Step [1000/1563], Loss: 3.1053, Accuracy: 0.3281\n",
      "Epoch [14/100], Step [1100/1563], Loss: 2.8130, Accuracy: 0.3906\n",
      "Epoch [14/100], Step [1200/1563], Loss: 3.0785, Accuracy: 0.2812\n",
      "Epoch [14/100], Step [1300/1563], Loss: 3.0411, Accuracy: 0.3125\n",
      "Epoch [14/100], Step [1400/1563], Loss: 2.6878, Accuracy: 0.2344\n",
      "Epoch [14/100], Step [1500/1563], Loss: 3.0764, Accuracy: 0.2656\n",
      "Epoch [14/100] - Average Loss: 2.8617\n",
      "Epoch [15/100], Step [0/1563], Loss: 2.5089, Accuracy: 0.4219\n",
      "Epoch [15/100], Step [100/1563], Loss: 2.7843, Accuracy: 0.2969\n",
      "Epoch [15/100], Step [200/1563], Loss: 3.0651, Accuracy: 0.2188\n",
      "Epoch [15/100], Step [300/1563], Loss: 2.7848, Accuracy: 0.3438\n",
      "Epoch [15/100], Step [400/1563], Loss: 2.9359, Accuracy: 0.3594\n",
      "Epoch [15/100], Step [500/1563], Loss: 2.7321, Accuracy: 0.2500\n",
      "Epoch [15/100], Step [600/1563], Loss: 2.4528, Accuracy: 0.4219\n",
      "Epoch [15/100], Step [700/1563], Loss: 2.5493, Accuracy: 0.3594\n",
      "Epoch [15/100], Step [800/1563], Loss: 2.9660, Accuracy: 0.2500\n",
      "Epoch [15/100], Step [900/1563], Loss: 3.0281, Accuracy: 0.2188\n",
      "Epoch [15/100], Step [1000/1563], Loss: 2.7327, Accuracy: 0.2812\n",
      "Epoch [15/100], Step [1100/1563], Loss: 2.6797, Accuracy: 0.3125\n",
      "Epoch [15/100], Step [1200/1563], Loss: 2.7410, Accuracy: 0.3594\n",
      "Epoch [15/100], Step [1300/1563], Loss: 2.7821, Accuracy: 0.3438\n",
      "Epoch [15/100], Step [1400/1563], Loss: 3.1334, Accuracy: 0.2344\n",
      "Epoch [15/100], Step [1500/1563], Loss: 2.7885, Accuracy: 0.3750\n",
      "Epoch [15/100] - Average Loss: 2.7961\n",
      "Epoch [16/100], Step [0/1563], Loss: 2.4763, Accuracy: 0.4531\n",
      "Epoch [16/100], Step [100/1563], Loss: 2.7417, Accuracy: 0.3750\n",
      "Epoch [16/100], Step [200/1563], Loss: 2.2863, Accuracy: 0.3750\n",
      "Epoch [16/100], Step [300/1563], Loss: 2.3600, Accuracy: 0.4688\n",
      "Epoch [16/100], Step [400/1563], Loss: 2.8303, Accuracy: 0.3906\n",
      "Epoch [16/100], Step [500/1563], Loss: 2.7095, Accuracy: 0.3906\n",
      "Epoch [16/100], Step [600/1563], Loss: 2.8203, Accuracy: 0.3594\n",
      "Epoch [16/100], Step [700/1563], Loss: 2.8384, Accuracy: 0.2969\n",
      "Epoch [16/100], Step [800/1563], Loss: 2.7286, Accuracy: 0.3906\n",
      "Epoch [16/100], Step [900/1563], Loss: 3.0142, Accuracy: 0.3438\n",
      "Epoch [16/100], Step [1000/1563], Loss: 2.8191, Accuracy: 0.3438\n",
      "Epoch [16/100], Step [1100/1563], Loss: 3.0551, Accuracy: 0.3281\n",
      "Epoch [16/100], Step [1200/1563], Loss: 2.5302, Accuracy: 0.3750\n",
      "Epoch [16/100], Step [1300/1563], Loss: 2.6170, Accuracy: 0.4219\n",
      "Epoch [16/100], Step [1400/1563], Loss: 2.5395, Accuracy: 0.4062\n",
      "Epoch [16/100], Step [1500/1563], Loss: 2.8193, Accuracy: 0.2812\n",
      "Epoch [16/100] - Average Loss: 2.7466\n",
      "Epoch [17/100], Step [0/1563], Loss: 2.7965, Accuracy: 0.4062\n",
      "Epoch [17/100], Step [100/1563], Loss: 2.4864, Accuracy: 0.3438\n",
      "Epoch [17/100], Step [200/1563], Loss: 2.2253, Accuracy: 0.5156\n",
      "Epoch [17/100], Step [300/1563], Loss: 2.4044, Accuracy: 0.3438\n",
      "Epoch [17/100], Step [400/1563], Loss: 2.3831, Accuracy: 0.3594\n",
      "Epoch [17/100], Step [500/1563], Loss: 2.8085, Accuracy: 0.3906\n",
      "Epoch [17/100], Step [600/1563], Loss: 2.8957, Accuracy: 0.3281\n",
      "Epoch [17/100], Step [700/1563], Loss: 2.7729, Accuracy: 0.3438\n",
      "Epoch [17/100], Step [800/1563], Loss: 2.6924, Accuracy: 0.3906\n",
      "Epoch [17/100], Step [900/1563], Loss: 2.9285, Accuracy: 0.3438\n",
      "Epoch [17/100], Step [1000/1563], Loss: 2.5953, Accuracy: 0.3906\n",
      "Epoch [17/100], Step [1100/1563], Loss: 2.7455, Accuracy: 0.2969\n",
      "Epoch [17/100], Step [1200/1563], Loss: 2.5403, Accuracy: 0.3125\n",
      "Epoch [17/100], Step [1300/1563], Loss: 2.5789, Accuracy: 0.3125\n",
      "Epoch [17/100], Step [1400/1563], Loss: 2.5726, Accuracy: 0.4062\n",
      "Epoch [17/100], Step [1500/1563], Loss: 2.6148, Accuracy: 0.3438\n",
      "Epoch [17/100] - Average Loss: 2.6748\n",
      "Epoch [18/100], Step [0/1563], Loss: 2.3777, Accuracy: 0.4375\n",
      "Epoch [18/100], Step [100/1563], Loss: 2.2887, Accuracy: 0.3750\n",
      "Epoch [18/100], Step [200/1563], Loss: 2.3330, Accuracy: 0.4375\n",
      "Epoch [18/100], Step [300/1563], Loss: 2.3108, Accuracy: 0.3594\n",
      "Epoch [18/100], Step [400/1563], Loss: 2.8597, Accuracy: 0.2969\n",
      "Epoch [18/100], Step [500/1563], Loss: 2.0757, Accuracy: 0.4688\n",
      "Epoch [18/100], Step [600/1563], Loss: 2.5772, Accuracy: 0.4062\n",
      "Epoch [18/100], Step [700/1563], Loss: 2.3888, Accuracy: 0.3750\n",
      "Epoch [18/100], Step [800/1563], Loss: 2.5803, Accuracy: 0.3125\n",
      "Epoch [18/100], Step [900/1563], Loss: 2.6704, Accuracy: 0.3906\n",
      "Epoch [18/100], Step [1000/1563], Loss: 2.5055, Accuracy: 0.3906\n",
      "Epoch [18/100], Step [1100/1563], Loss: 2.5686, Accuracy: 0.3594\n",
      "Epoch [18/100], Step [1200/1563], Loss: 2.7780, Accuracy: 0.3438\n",
      "Epoch [18/100], Step [1300/1563], Loss: 2.6043, Accuracy: 0.3750\n",
      "Epoch [18/100], Step [1400/1563], Loss: 2.8609, Accuracy: 0.3438\n",
      "Epoch [18/100], Step [1500/1563], Loss: 2.9395, Accuracy: 0.2969\n",
      "Epoch [18/100] - Average Loss: 2.6369\n",
      "Epoch [19/100], Step [0/1563], Loss: 2.9003, Accuracy: 0.3125\n",
      "Epoch [19/100], Step [100/1563], Loss: 2.8944, Accuracy: 0.3281\n",
      "Epoch [19/100], Step [200/1563], Loss: 2.8457, Accuracy: 0.2812\n",
      "Epoch [19/100], Step [300/1563], Loss: 2.9404, Accuracy: 0.2812\n",
      "Epoch [19/100], Step [400/1563], Loss: 2.9735, Accuracy: 0.2969\n",
      "Epoch [19/100], Step [500/1563], Loss: 2.4419, Accuracy: 0.3594\n",
      "Epoch [19/100], Step [600/1563], Loss: 2.6705, Accuracy: 0.3438\n",
      "Epoch [19/100], Step [700/1563], Loss: 2.2116, Accuracy: 0.5000\n",
      "Epoch [19/100], Step [800/1563], Loss: 2.5072, Accuracy: 0.3281\n",
      "Epoch [19/100], Step [900/1563], Loss: 2.6203, Accuracy: 0.4062\n",
      "Epoch [19/100], Step [1000/1563], Loss: 2.4141, Accuracy: 0.4062\n",
      "Epoch [19/100], Step [1100/1563], Loss: 2.5202, Accuracy: 0.3906\n",
      "Epoch [19/100], Step [1200/1563], Loss: 2.9953, Accuracy: 0.3750\n",
      "Epoch [19/100], Step [1300/1563], Loss: 2.5687, Accuracy: 0.3750\n",
      "Epoch [19/100], Step [1400/1563], Loss: 2.8855, Accuracy: 0.3594\n",
      "Epoch [19/100], Step [1500/1563], Loss: 2.5141, Accuracy: 0.3125\n",
      "Epoch [19/100] - Average Loss: 2.5774\n",
      "Epoch [20/100], Step [0/1563], Loss: 2.5700, Accuracy: 0.3594\n",
      "Epoch [20/100], Step [100/1563], Loss: 2.8527, Accuracy: 0.3281\n",
      "Epoch [20/100], Step [200/1563], Loss: 2.0552, Accuracy: 0.4688\n",
      "Epoch [20/100], Step [300/1563], Loss: 2.2133, Accuracy: 0.3906\n",
      "Epoch [20/100], Step [400/1563], Loss: 2.8353, Accuracy: 0.3125\n",
      "Epoch [20/100], Step [500/1563], Loss: 2.5943, Accuracy: 0.3906\n",
      "Epoch [20/100], Step [600/1563], Loss: 2.9149, Accuracy: 0.2969\n",
      "Epoch [20/100], Step [700/1563], Loss: 2.6362, Accuracy: 0.3750\n",
      "Epoch [20/100], Step [800/1563], Loss: 2.4392, Accuracy: 0.3906\n",
      "Epoch [20/100], Step [900/1563], Loss: 2.8956, Accuracy: 0.3594\n",
      "Epoch [20/100], Step [1000/1563], Loss: 3.0922, Accuracy: 0.2344\n",
      "Epoch [20/100], Step [1100/1563], Loss: 2.7119, Accuracy: 0.3906\n",
      "Epoch [20/100], Step [1200/1563], Loss: 2.5488, Accuracy: 0.3594\n",
      "Epoch [20/100], Step [1300/1563], Loss: 2.5805, Accuracy: 0.3750\n",
      "Epoch [20/100], Step [1400/1563], Loss: 2.7632, Accuracy: 0.2500\n",
      "Epoch [20/100], Step [1500/1563], Loss: 2.6357, Accuracy: 0.3281\n",
      "Epoch [20/100] - Average Loss: 2.5487\n",
      "Epoch [21/100], Step [0/1563], Loss: 2.5030, Accuracy: 0.4062\n",
      "Epoch [21/100], Step [100/1563], Loss: 2.4467, Accuracy: 0.4375\n",
      "Epoch [21/100], Step [200/1563], Loss: 2.6354, Accuracy: 0.3594\n",
      "Epoch [21/100], Step [300/1563], Loss: 2.9080, Accuracy: 0.2969\n",
      "Epoch [21/100], Step [400/1563], Loss: 2.5437, Accuracy: 0.2656\n",
      "Epoch [21/100], Step [500/1563], Loss: 2.4981, Accuracy: 0.3594\n",
      "Epoch [21/100], Step [600/1563], Loss: 2.5479, Accuracy: 0.3906\n",
      "Epoch [21/100], Step [700/1563], Loss: 2.6513, Accuracy: 0.3594\n",
      "Epoch [21/100], Step [800/1563], Loss: 2.5646, Accuracy: 0.3906\n",
      "Epoch [21/100], Step [900/1563], Loss: 2.6295, Accuracy: 0.3750\n",
      "Epoch [21/100], Step [1000/1563], Loss: 2.1629, Accuracy: 0.4375\n",
      "Epoch [21/100], Step [1100/1563], Loss: 2.2677, Accuracy: 0.3750\n",
      "Epoch [21/100], Step [1200/1563], Loss: 2.4274, Accuracy: 0.3906\n",
      "Epoch [21/100], Step [1300/1563], Loss: 2.2667, Accuracy: 0.4531\n",
      "Epoch [21/100], Step [1400/1563], Loss: 2.3740, Accuracy: 0.4375\n",
      "Epoch [21/100], Step [1500/1563], Loss: 2.4264, Accuracy: 0.4062\n",
      "Epoch [21/100] - Average Loss: 2.4956\n",
      "Epoch [22/100], Step [0/1563], Loss: 2.2032, Accuracy: 0.4531\n",
      "Epoch [22/100], Step [100/1563], Loss: 2.2436, Accuracy: 0.4375\n",
      "Epoch [22/100], Step [200/1563], Loss: 2.5266, Accuracy: 0.3750\n",
      "Epoch [22/100], Step [300/1563], Loss: 2.6637, Accuracy: 0.3281\n",
      "Epoch [22/100], Step [400/1563], Loss: 1.8525, Accuracy: 0.5156\n",
      "Epoch [22/100], Step [500/1563], Loss: 3.0801, Accuracy: 0.2344\n",
      "Epoch [22/100], Step [600/1563], Loss: 1.8731, Accuracy: 0.5625\n",
      "Epoch [22/100], Step [700/1563], Loss: 2.6143, Accuracy: 0.3594\n",
      "Epoch [22/100], Step [800/1563], Loss: 2.1930, Accuracy: 0.4062\n",
      "Epoch [22/100], Step [900/1563], Loss: 2.3086, Accuracy: 0.4844\n",
      "Epoch [22/100], Step [1000/1563], Loss: 2.3554, Accuracy: 0.4531\n",
      "Epoch [22/100], Step [1100/1563], Loss: 2.6676, Accuracy: 0.4375\n",
      "Epoch [22/100], Step [1200/1563], Loss: 2.3223, Accuracy: 0.3750\n",
      "Epoch [22/100], Step [1300/1563], Loss: 2.4612, Accuracy: 0.4375\n",
      "Epoch [22/100], Step [1400/1563], Loss: 2.5882, Accuracy: 0.4062\n",
      "Epoch [22/100], Step [1500/1563], Loss: 2.5298, Accuracy: 0.3438\n",
      "Epoch [22/100] - Average Loss: 2.4682\n",
      "Epoch [23/100], Step [0/1563], Loss: 2.4970, Accuracy: 0.3594\n",
      "Epoch [23/100], Step [100/1563], Loss: 2.1846, Accuracy: 0.4688\n",
      "Epoch [23/100], Step [200/1563], Loss: 2.2417, Accuracy: 0.4531\n",
      "Epoch [23/100], Step [300/1563], Loss: 2.3566, Accuracy: 0.3750\n",
      "Epoch [23/100], Step [400/1563], Loss: 1.9845, Accuracy: 0.5312\n",
      "Epoch [23/100], Step [500/1563], Loss: 2.5999, Accuracy: 0.3906\n",
      "Epoch [23/100], Step [600/1563], Loss: 2.1996, Accuracy: 0.4062\n",
      "Epoch [23/100], Step [700/1563], Loss: 2.6529, Accuracy: 0.2812\n",
      "Epoch [23/100], Step [800/1563], Loss: 2.5004, Accuracy: 0.4219\n",
      "Epoch [23/100], Step [900/1563], Loss: 1.9673, Accuracy: 0.4219\n",
      "Epoch [23/100], Step [1000/1563], Loss: 2.5184, Accuracy: 0.3281\n",
      "Epoch [23/100], Step [1100/1563], Loss: 2.4687, Accuracy: 0.4375\n",
      "Epoch [23/100], Step [1200/1563], Loss: 2.4428, Accuracy: 0.4062\n",
      "Epoch [23/100], Step [1300/1563], Loss: 2.2919, Accuracy: 0.3438\n",
      "Epoch [23/100], Step [1400/1563], Loss: 2.7397, Accuracy: 0.3594\n",
      "Epoch [23/100], Step [1500/1563], Loss: 2.6171, Accuracy: 0.3906\n",
      "Epoch [23/100] - Average Loss: 2.4116\n",
      "Epoch [24/100], Step [0/1563], Loss: 2.4958, Accuracy: 0.5000\n",
      "Epoch [24/100], Step [100/1563], Loss: 2.1524, Accuracy: 0.4688\n",
      "Epoch [24/100], Step [200/1563], Loss: 2.3203, Accuracy: 0.4062\n",
      "Epoch [24/100], Step [300/1563], Loss: 2.0965, Accuracy: 0.4375\n",
      "Epoch [24/100], Step [400/1563], Loss: 2.3720, Accuracy: 0.3125\n",
      "Epoch [24/100], Step [500/1563], Loss: 2.7684, Accuracy: 0.3281\n",
      "Epoch [24/100], Step [600/1563], Loss: 2.1791, Accuracy: 0.4688\n",
      "Epoch [24/100], Step [700/1563], Loss: 2.1307, Accuracy: 0.5000\n",
      "Epoch [24/100], Step [800/1563], Loss: 2.3244, Accuracy: 0.4375\n",
      "Epoch [24/100], Step [900/1563], Loss: 2.5443, Accuracy: 0.4688\n",
      "Epoch [24/100], Step [1000/1563], Loss: 2.4606, Accuracy: 0.4375\n",
      "Epoch [24/100], Step [1100/1563], Loss: 2.0540, Accuracy: 0.4531\n",
      "Epoch [24/100], Step [1200/1563], Loss: 2.4689, Accuracy: 0.4062\n",
      "Epoch [24/100], Step [1300/1563], Loss: 2.3990, Accuracy: 0.4375\n",
      "Epoch [24/100], Step [1400/1563], Loss: 2.2405, Accuracy: 0.3906\n",
      "Epoch [24/100], Step [1500/1563], Loss: 2.3508, Accuracy: 0.4062\n",
      "Epoch [24/100] - Average Loss: 2.3670\n",
      "Epoch [25/100], Step [0/1563], Loss: 2.1936, Accuracy: 0.5312\n",
      "Epoch [25/100], Step [100/1563], Loss: 2.3188, Accuracy: 0.4219\n",
      "Epoch [25/100], Step [200/1563], Loss: 2.0809, Accuracy: 0.4688\n",
      "Epoch [25/100], Step [300/1563], Loss: 2.1585, Accuracy: 0.4531\n",
      "Epoch [25/100], Step [400/1563], Loss: 2.3189, Accuracy: 0.4062\n",
      "Epoch [25/100], Step [500/1563], Loss: 2.4772, Accuracy: 0.4219\n",
      "Epoch [25/100], Step [600/1563], Loss: 2.4967, Accuracy: 0.4062\n",
      "Epoch [25/100], Step [700/1563], Loss: 2.0874, Accuracy: 0.4688\n",
      "Epoch [25/100], Step [800/1563], Loss: 2.1127, Accuracy: 0.4062\n",
      "Epoch [25/100], Step [900/1563], Loss: 2.0741, Accuracy: 0.5000\n",
      "Epoch [25/100], Step [1000/1563], Loss: 2.5425, Accuracy: 0.3750\n",
      "Epoch [25/100], Step [1100/1563], Loss: 2.0070, Accuracy: 0.5000\n",
      "Epoch [25/100], Step [1200/1563], Loss: 2.5347, Accuracy: 0.3281\n",
      "Epoch [25/100], Step [1300/1563], Loss: 2.5519, Accuracy: 0.3750\n",
      "Epoch [25/100], Step [1400/1563], Loss: 2.3945, Accuracy: 0.3750\n",
      "Epoch [25/100], Step [1500/1563], Loss: 1.9077, Accuracy: 0.4688\n",
      "Epoch [25/100] - Average Loss: 2.3323\n",
      "Epoch [26/100], Step [0/1563], Loss: 1.8027, Accuracy: 0.4844\n",
      "Epoch [26/100], Step [100/1563], Loss: 1.7511, Accuracy: 0.4688\n",
      "Epoch [26/100], Step [200/1563], Loss: 2.1554, Accuracy: 0.3906\n",
      "Epoch [26/100], Step [300/1563], Loss: 2.3574, Accuracy: 0.4844\n",
      "Epoch [26/100], Step [400/1563], Loss: 2.4603, Accuracy: 0.3750\n",
      "Epoch [26/100], Step [500/1563], Loss: 2.1054, Accuracy: 0.4531\n",
      "Epoch [26/100], Step [600/1563], Loss: 2.2068, Accuracy: 0.4531\n",
      "Epoch [26/100], Step [700/1563], Loss: 2.3298, Accuracy: 0.4375\n",
      "Epoch [26/100], Step [800/1563], Loss: 2.6758, Accuracy: 0.3594\n",
      "Epoch [26/100], Step [900/1563], Loss: 2.0498, Accuracy: 0.5000\n",
      "Epoch [26/100], Step [1000/1563], Loss: 2.4415, Accuracy: 0.4219\n",
      "Epoch [26/100], Step [1100/1563], Loss: 2.1058, Accuracy: 0.3906\n",
      "Epoch [26/100], Step [1200/1563], Loss: 1.9607, Accuracy: 0.4844\n",
      "Epoch [26/100], Step [1300/1563], Loss: 2.6711, Accuracy: 0.3750\n",
      "Epoch [26/100], Step [1400/1563], Loss: 2.6250, Accuracy: 0.2969\n",
      "Epoch [26/100], Step [1500/1563], Loss: 2.1797, Accuracy: 0.5469\n",
      "Epoch [26/100] - Average Loss: 2.2874\n",
      "Epoch [27/100], Step [0/1563], Loss: 1.9716, Accuracy: 0.4688\n",
      "Epoch [27/100], Step [100/1563], Loss: 2.2148, Accuracy: 0.4375\n",
      "Epoch [27/100], Step [200/1563], Loss: 2.0800, Accuracy: 0.5312\n",
      "Epoch [27/100], Step [300/1563], Loss: 2.2638, Accuracy: 0.4375\n",
      "Epoch [27/100], Step [400/1563], Loss: 2.6000, Accuracy: 0.3438\n",
      "Epoch [27/100], Step [500/1563], Loss: 2.1218, Accuracy: 0.4688\n",
      "Epoch [27/100], Step [600/1563], Loss: 2.2208, Accuracy: 0.4688\n",
      "Epoch [27/100], Step [700/1563], Loss: 2.2849, Accuracy: 0.4062\n",
      "Epoch [27/100], Step [800/1563], Loss: 2.6113, Accuracy: 0.3281\n",
      "Epoch [27/100], Step [900/1563], Loss: 1.9359, Accuracy: 0.4688\n",
      "Epoch [27/100], Step [1000/1563], Loss: 1.6844, Accuracy: 0.5781\n",
      "Epoch [27/100], Step [1100/1563], Loss: 2.1805, Accuracy: 0.5312\n",
      "Epoch [27/100], Step [1200/1563], Loss: 2.1329, Accuracy: 0.4062\n",
      "Epoch [27/100], Step [1300/1563], Loss: 2.2226, Accuracy: 0.4375\n",
      "Epoch [27/100], Step [1400/1563], Loss: 2.4563, Accuracy: 0.3906\n",
      "Epoch [27/100], Step [1500/1563], Loss: 2.5845, Accuracy: 0.3750\n",
      "Epoch [27/100] - Average Loss: 2.2630\n",
      "Epoch [28/100], Step [0/1563], Loss: 1.6164, Accuracy: 0.5781\n",
      "Epoch [28/100], Step [100/1563], Loss: 2.2281, Accuracy: 0.4688\n",
      "Epoch [28/100], Step [200/1563], Loss: 2.7635, Accuracy: 0.3438\n",
      "Epoch [28/100], Step [300/1563], Loss: 1.9907, Accuracy: 0.4688\n",
      "Epoch [28/100], Step [400/1563], Loss: 2.1076, Accuracy: 0.4219\n",
      "Epoch [28/100], Step [500/1563], Loss: 2.0509, Accuracy: 0.3906\n",
      "Epoch [28/100], Step [600/1563], Loss: 2.2596, Accuracy: 0.5000\n",
      "Epoch [28/100], Step [700/1563], Loss: 2.2398, Accuracy: 0.4688\n",
      "Epoch [28/100], Step [800/1563], Loss: 2.4457, Accuracy: 0.3906\n",
      "Epoch [28/100], Step [900/1563], Loss: 2.4853, Accuracy: 0.4375\n",
      "Epoch [28/100], Step [1000/1563], Loss: 1.8434, Accuracy: 0.5625\n",
      "Epoch [28/100], Step [1100/1563], Loss: 2.2745, Accuracy: 0.4375\n",
      "Epoch [28/100], Step [1200/1563], Loss: 2.0801, Accuracy: 0.5156\n",
      "Epoch [28/100], Step [1300/1563], Loss: 1.8429, Accuracy: 0.5312\n",
      "Epoch [28/100], Step [1400/1563], Loss: 1.8227, Accuracy: 0.5312\n",
      "Epoch [28/100], Step [1500/1563], Loss: 1.9409, Accuracy: 0.5000\n",
      "Epoch [28/100] - Average Loss: 2.2107\n",
      "Epoch [29/100], Step [0/1563], Loss: 2.2153, Accuracy: 0.4375\n",
      "Epoch [29/100], Step [100/1563], Loss: 1.9023, Accuracy: 0.4688\n",
      "Epoch [29/100], Step [200/1563], Loss: 1.7512, Accuracy: 0.5781\n",
      "Epoch [29/100], Step [300/1563], Loss: 1.8591, Accuracy: 0.5000\n",
      "Epoch [29/100], Step [400/1563], Loss: 2.2551, Accuracy: 0.4688\n",
      "Epoch [29/100], Step [500/1563], Loss: 2.3450, Accuracy: 0.4062\n",
      "Epoch [29/100], Step [600/1563], Loss: 2.2142, Accuracy: 0.4062\n",
      "Epoch [29/100], Step [700/1563], Loss: 2.5751, Accuracy: 0.3125\n",
      "Epoch [29/100], Step [800/1563], Loss: 2.3805, Accuracy: 0.4531\n",
      "Epoch [29/100], Step [900/1563], Loss: 2.2806, Accuracy: 0.3750\n",
      "Epoch [29/100], Step [1000/1563], Loss: 2.2567, Accuracy: 0.4062\n",
      "Epoch [29/100], Step [1100/1563], Loss: 1.5018, Accuracy: 0.5938\n",
      "Epoch [29/100], Step [1200/1563], Loss: 2.1475, Accuracy: 0.5000\n",
      "Epoch [29/100], Step [1300/1563], Loss: 2.0105, Accuracy: 0.5156\n",
      "Epoch [29/100], Step [1400/1563], Loss: 2.5753, Accuracy: 0.3125\n",
      "Epoch [29/100], Step [1500/1563], Loss: 2.4077, Accuracy: 0.4531\n",
      "Epoch [29/100] - Average Loss: 2.1928\n",
      "Epoch [30/100], Step [0/1563], Loss: 2.2994, Accuracy: 0.3906\n",
      "Epoch [30/100], Step [100/1563], Loss: 2.0199, Accuracy: 0.4688\n",
      "Epoch [30/100], Step [200/1563], Loss: 2.2376, Accuracy: 0.3594\n",
      "Epoch [30/100], Step [300/1563], Loss: 1.9738, Accuracy: 0.5312\n",
      "Epoch [30/100], Step [400/1563], Loss: 2.2544, Accuracy: 0.4688\n",
      "Epoch [30/100], Step [500/1563], Loss: 2.2775, Accuracy: 0.4062\n",
      "Epoch [30/100], Step [600/1563], Loss: 2.3240, Accuracy: 0.4219\n",
      "Epoch [30/100], Step [700/1563], Loss: 2.3114, Accuracy: 0.4219\n",
      "Epoch [30/100], Step [800/1563], Loss: 1.8608, Accuracy: 0.5156\n",
      "Epoch [30/100], Step [900/1563], Loss: 2.2515, Accuracy: 0.4688\n",
      "Epoch [30/100], Step [1000/1563], Loss: 2.2810, Accuracy: 0.4844\n",
      "Epoch [30/100], Step [1100/1563], Loss: 2.0231, Accuracy: 0.4688\n",
      "Epoch [30/100], Step [1200/1563], Loss: 2.2964, Accuracy: 0.4531\n",
      "Epoch [30/100], Step [1300/1563], Loss: 2.1809, Accuracy: 0.4688\n",
      "Epoch [30/100], Step [1400/1563], Loss: 2.0671, Accuracy: 0.4531\n",
      "Epoch [30/100], Step [1500/1563], Loss: 2.2113, Accuracy: 0.4219\n",
      "Epoch [30/100] - Average Loss: 2.1514\n",
      "Epoch [31/100], Step [0/1563], Loss: 2.4831, Accuracy: 0.4375\n",
      "Epoch [31/100], Step [100/1563], Loss: 1.8526, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [200/1563], Loss: 1.9945, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [300/1563], Loss: 1.7782, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [400/1563], Loss: 1.7009, Accuracy: 0.5312\n",
      "Epoch [31/100], Step [500/1563], Loss: 2.4901, Accuracy: 0.3438\n",
      "Epoch [31/100], Step [600/1563], Loss: 2.2383, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [700/1563], Loss: 2.1636, Accuracy: 0.3750\n",
      "Epoch [31/100], Step [800/1563], Loss: 2.2334, Accuracy: 0.4375\n",
      "Epoch [31/100], Step [900/1563], Loss: 2.3118, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [1000/1563], Loss: 2.6548, Accuracy: 0.3281\n",
      "Epoch [31/100], Step [1100/1563], Loss: 2.3087, Accuracy: 0.4375\n",
      "Epoch [31/100], Step [1200/1563], Loss: 1.9832, Accuracy: 0.4688\n",
      "Epoch [31/100], Step [1300/1563], Loss: 2.2963, Accuracy: 0.4062\n",
      "Epoch [31/100], Step [1400/1563], Loss: 2.6406, Accuracy: 0.3438\n",
      "Epoch [31/100], Step [1500/1563], Loss: 2.3904, Accuracy: 0.4688\n",
      "Epoch [31/100] - Average Loss: 2.1069\n",
      "Epoch [32/100], Step [0/1563], Loss: 1.4854, Accuracy: 0.5781\n",
      "Epoch [32/100], Step [100/1563], Loss: 1.7685, Accuracy: 0.5156\n",
      "Epoch [32/100], Step [200/1563], Loss: 2.3753, Accuracy: 0.4531\n",
      "Epoch [32/100], Step [300/1563], Loss: 1.8212, Accuracy: 0.5000\n",
      "Epoch [32/100], Step [400/1563], Loss: 2.0056, Accuracy: 0.5156\n",
      "Epoch [32/100], Step [500/1563], Loss: 1.6833, Accuracy: 0.5625\n",
      "Epoch [32/100], Step [600/1563], Loss: 1.9661, Accuracy: 0.4531\n",
      "Epoch [32/100], Step [700/1563], Loss: 2.0339, Accuracy: 0.4688\n",
      "Epoch [32/100], Step [800/1563], Loss: 1.7287, Accuracy: 0.5625\n",
      "Epoch [32/100], Step [900/1563], Loss: 1.8426, Accuracy: 0.5000\n",
      "Epoch [32/100], Step [1000/1563], Loss: 2.2012, Accuracy: 0.4219\n",
      "Epoch [32/100], Step [1100/1563], Loss: 2.4681, Accuracy: 0.4375\n",
      "Epoch [32/100], Step [1200/1563], Loss: 2.6016, Accuracy: 0.3438\n",
      "Epoch [32/100], Step [1300/1563], Loss: 1.9685, Accuracy: 0.4844\n",
      "Epoch [32/100], Step [1400/1563], Loss: 2.5334, Accuracy: 0.3906\n",
      "Epoch [32/100], Step [1500/1563], Loss: 2.2524, Accuracy: 0.5000\n",
      "Epoch [32/100] - Average Loss: 2.0832\n",
      "Epoch [33/100], Step [0/1563], Loss: 1.9729, Accuracy: 0.4531\n",
      "Epoch [33/100], Step [100/1563], Loss: 1.8799, Accuracy: 0.5312\n",
      "Epoch [33/100], Step [200/1563], Loss: 1.8631, Accuracy: 0.4062\n",
      "Epoch [33/100], Step [300/1563], Loss: 2.1417, Accuracy: 0.4844\n",
      "Epoch [33/100], Step [400/1563], Loss: 2.3269, Accuracy: 0.3906\n",
      "Epoch [33/100], Step [500/1563], Loss: 2.1652, Accuracy: 0.4688\n",
      "Epoch [33/100], Step [600/1563], Loss: 1.7005, Accuracy: 0.5469\n",
      "Epoch [33/100], Step [700/1563], Loss: 2.2709, Accuracy: 0.4375\n",
      "Epoch [33/100], Step [800/1563], Loss: 2.1639, Accuracy: 0.5000\n",
      "Epoch [33/100], Step [900/1563], Loss: 1.8982, Accuracy: 0.5469\n",
      "Epoch [33/100], Step [1000/1563], Loss: 1.9328, Accuracy: 0.5000\n",
      "Epoch [33/100], Step [1100/1563], Loss: 1.8499, Accuracy: 0.5156\n",
      "Epoch [33/100], Step [1200/1563], Loss: 1.9661, Accuracy: 0.4219\n",
      "Epoch [33/100], Step [1300/1563], Loss: 2.2719, Accuracy: 0.4375\n",
      "Epoch [33/100], Step [1400/1563], Loss: 2.0584, Accuracy: 0.4219\n",
      "Epoch [33/100], Step [1500/1563], Loss: 2.0072, Accuracy: 0.4375\n",
      "Epoch [33/100] - Average Loss: 2.0567\n",
      "Epoch [34/100], Step [0/1563], Loss: 1.7888, Accuracy: 0.5781\n",
      "Epoch [34/100], Step [100/1563], Loss: 1.5228, Accuracy: 0.6250\n",
      "Epoch [34/100], Step [200/1563], Loss: 2.0184, Accuracy: 0.4844\n",
      "Epoch [34/100], Step [300/1563], Loss: 1.8773, Accuracy: 0.5312\n",
      "Epoch [34/100], Step [400/1563], Loss: 1.8794, Accuracy: 0.4688\n",
      "Epoch [34/100], Step [500/1563], Loss: 1.8357, Accuracy: 0.5781\n",
      "Epoch [34/100], Step [600/1563], Loss: 1.5977, Accuracy: 0.6094\n",
      "Epoch [34/100], Step [700/1563], Loss: 1.8646, Accuracy: 0.4844\n",
      "Epoch [34/100], Step [800/1563], Loss: 2.2303, Accuracy: 0.4688\n",
      "Epoch [34/100], Step [900/1563], Loss: 2.4676, Accuracy: 0.4219\n",
      "Epoch [34/100], Step [1000/1563], Loss: 2.0733, Accuracy: 0.4219\n",
      "Epoch [34/100], Step [1100/1563], Loss: 1.8016, Accuracy: 0.4844\n",
      "Epoch [34/100], Step [1200/1563], Loss: 1.8754, Accuracy: 0.5781\n",
      "Epoch [34/100], Step [1300/1563], Loss: 2.1002, Accuracy: 0.4062\n",
      "Epoch [34/100], Step [1400/1563], Loss: 2.3228, Accuracy: 0.3906\n",
      "Epoch [34/100], Step [1500/1563], Loss: 2.2508, Accuracy: 0.4219\n",
      "Epoch [34/100] - Average Loss: 2.0378\n",
      "Epoch [35/100], Step [0/1563], Loss: 1.9487, Accuracy: 0.4688\n",
      "Epoch [35/100], Step [100/1563], Loss: 2.1310, Accuracy: 0.4844\n",
      "Epoch [35/100], Step [200/1563], Loss: 2.3386, Accuracy: 0.4531\n",
      "Epoch [35/100], Step [300/1563], Loss: 1.9777, Accuracy: 0.5000\n",
      "Epoch [35/100], Step [400/1563], Loss: 1.7055, Accuracy: 0.5781\n",
      "Epoch [35/100], Step [500/1563], Loss: 2.1295, Accuracy: 0.4844\n",
      "Epoch [35/100], Step [600/1563], Loss: 1.9319, Accuracy: 0.4844\n",
      "Epoch [35/100], Step [700/1563], Loss: 2.0819, Accuracy: 0.4688\n",
      "Epoch [35/100], Step [800/1563], Loss: 1.9515, Accuracy: 0.4375\n",
      "Epoch [35/100], Step [900/1563], Loss: 2.2298, Accuracy: 0.4531\n",
      "Epoch [35/100], Step [1000/1563], Loss: 1.9933, Accuracy: 0.5156\n",
      "Epoch [35/100], Step [1100/1563], Loss: 2.4346, Accuracy: 0.4062\n",
      "Epoch [35/100], Step [1200/1563], Loss: 1.7901, Accuracy: 0.4688\n",
      "Epoch [35/100], Step [1300/1563], Loss: 1.8805, Accuracy: 0.4531\n",
      "Epoch [35/100], Step [1400/1563], Loss: 2.2447, Accuracy: 0.5312\n",
      "Epoch [35/100], Step [1500/1563], Loss: 1.7966, Accuracy: 0.5156\n",
      "Epoch [35/100] - Average Loss: 1.9920\n",
      "Epoch [36/100], Step [0/1563], Loss: 2.0691, Accuracy: 0.4688\n",
      "Epoch [36/100], Step [100/1563], Loss: 2.0632, Accuracy: 0.4844\n",
      "Epoch [36/100], Step [200/1563], Loss: 1.8999, Accuracy: 0.4531\n",
      "Epoch [36/100], Step [300/1563], Loss: 1.9868, Accuracy: 0.5781\n",
      "Epoch [36/100], Step [400/1563], Loss: 1.8964, Accuracy: 0.5156\n",
      "Epoch [36/100], Step [500/1563], Loss: 2.3491, Accuracy: 0.4375\n",
      "Epoch [36/100], Step [600/1563], Loss: 2.6751, Accuracy: 0.3750\n",
      "Epoch [36/100], Step [700/1563], Loss: 2.2450, Accuracy: 0.5156\n",
      "Epoch [36/100], Step [800/1563], Loss: 2.1409, Accuracy: 0.3281\n",
      "Epoch [36/100], Step [900/1563], Loss: 1.6931, Accuracy: 0.5156\n",
      "Epoch [36/100], Step [1000/1563], Loss: 2.0782, Accuracy: 0.4688\n",
      "Epoch [36/100], Step [1100/1563], Loss: 2.1591, Accuracy: 0.5000\n",
      "Epoch [36/100], Step [1200/1563], Loss: 2.2954, Accuracy: 0.4688\n",
      "Epoch [36/100], Step [1300/1563], Loss: 1.7606, Accuracy: 0.5625\n",
      "Epoch [36/100], Step [1400/1563], Loss: 2.1851, Accuracy: 0.5000\n",
      "Epoch [36/100], Step [1500/1563], Loss: 2.0979, Accuracy: 0.4375\n",
      "Epoch [36/100] - Average Loss: 1.9966\n",
      "Epoch [37/100], Step [0/1563], Loss: 2.0765, Accuracy: 0.3438\n",
      "Epoch [37/100], Step [100/1563], Loss: 1.9274, Accuracy: 0.5156\n",
      "Epoch [37/100], Step [200/1563], Loss: 2.1961, Accuracy: 0.4688\n",
      "Epoch [37/100], Step [300/1563], Loss: 2.1736, Accuracy: 0.4844\n",
      "Epoch [37/100], Step [400/1563], Loss: 1.5981, Accuracy: 0.5469\n",
      "Epoch [37/100], Step [500/1563], Loss: 1.9163, Accuracy: 0.5000\n",
      "Epoch [37/100], Step [600/1563], Loss: 2.0980, Accuracy: 0.4688\n",
      "Epoch [37/100], Step [700/1563], Loss: 1.4206, Accuracy: 0.5625\n",
      "Epoch [37/100], Step [800/1563], Loss: 1.7668, Accuracy: 0.5000\n",
      "Epoch [37/100], Step [900/1563], Loss: 2.1321, Accuracy: 0.4062\n",
      "Epoch [37/100], Step [1000/1563], Loss: 1.8726, Accuracy: 0.5469\n",
      "Epoch [37/100], Step [1100/1563], Loss: 1.7060, Accuracy: 0.5312\n",
      "Epoch [37/100], Step [1200/1563], Loss: 1.3851, Accuracy: 0.6094\n",
      "Epoch [37/100], Step [1300/1563], Loss: 1.7257, Accuracy: 0.5625\n",
      "Epoch [37/100], Step [1400/1563], Loss: 2.1239, Accuracy: 0.4375\n",
      "Epoch [37/100], Step [1500/1563], Loss: 2.2845, Accuracy: 0.4375\n",
      "Epoch [37/100] - Average Loss: 1.9287\n",
      "Epoch [38/100], Step [0/1563], Loss: 1.8960, Accuracy: 0.5156\n",
      "Epoch [38/100], Step [100/1563], Loss: 1.9033, Accuracy: 0.5781\n",
      "Epoch [38/100], Step [200/1563], Loss: 1.8905, Accuracy: 0.4688\n",
      "Epoch [38/100], Step [300/1563], Loss: 1.5308, Accuracy: 0.5938\n",
      "Epoch [38/100], Step [400/1563], Loss: 2.0659, Accuracy: 0.4844\n",
      "Epoch [38/100], Step [500/1563], Loss: 2.1042, Accuracy: 0.4531\n",
      "Epoch [38/100], Step [600/1563], Loss: 1.8797, Accuracy: 0.5625\n",
      "Epoch [38/100], Step [700/1563], Loss: 1.7665, Accuracy: 0.5625\n",
      "Epoch [38/100], Step [800/1563], Loss: 1.9509, Accuracy: 0.5000\n",
      "Epoch [38/100], Step [900/1563], Loss: 1.8427, Accuracy: 0.5938\n",
      "Epoch [38/100], Step [1000/1563], Loss: 2.3454, Accuracy: 0.3906\n",
      "Epoch [38/100], Step [1100/1563], Loss: 1.4512, Accuracy: 0.5938\n",
      "Epoch [38/100], Step [1200/1563], Loss: 1.9780, Accuracy: 0.4375\n",
      "Epoch [38/100], Step [1300/1563], Loss: 1.5823, Accuracy: 0.5781\n",
      "Epoch [38/100], Step [1400/1563], Loss: 2.2926, Accuracy: 0.3750\n",
      "Epoch [38/100], Step [1500/1563], Loss: 1.8682, Accuracy: 0.4375\n",
      "Epoch [38/100] - Average Loss: 1.9219\n",
      "Epoch [39/100], Step [0/1563], Loss: 2.1868, Accuracy: 0.5000\n",
      "Epoch [39/100], Step [100/1563], Loss: 2.0608, Accuracy: 0.5000\n",
      "Epoch [39/100], Step [200/1563], Loss: 1.6881, Accuracy: 0.5781\n",
      "Epoch [39/100], Step [300/1563], Loss: 1.6298, Accuracy: 0.6562\n",
      "Epoch [39/100], Step [400/1563], Loss: 1.7164, Accuracy: 0.5781\n",
      "Epoch [39/100], Step [500/1563], Loss: 2.0241, Accuracy: 0.4375\n",
      "Epoch [39/100], Step [600/1563], Loss: 1.3403, Accuracy: 0.5938\n",
      "Epoch [39/100], Step [700/1563], Loss: 1.6757, Accuracy: 0.5781\n",
      "Epoch [39/100], Step [800/1563], Loss: 1.7983, Accuracy: 0.4531\n",
      "Epoch [39/100], Step [900/1563], Loss: 1.6144, Accuracy: 0.5000\n",
      "Epoch [39/100], Step [1000/1563], Loss: 1.7198, Accuracy: 0.5625\n",
      "Epoch [39/100], Step [1100/1563], Loss: 2.2660, Accuracy: 0.4375\n",
      "Epoch [39/100], Step [1200/1563], Loss: 1.8195, Accuracy: 0.5469\n",
      "Epoch [39/100], Step [1300/1563], Loss: 1.8380, Accuracy: 0.4688\n",
      "Epoch [39/100], Step [1400/1563], Loss: 2.0634, Accuracy: 0.4688\n",
      "Epoch [39/100], Step [1500/1563], Loss: 1.9256, Accuracy: 0.5312\n",
      "Epoch [39/100] - Average Loss: 1.9089\n",
      "Epoch [40/100], Step [0/1563], Loss: 1.5783, Accuracy: 0.5781\n",
      "Epoch [40/100], Step [100/1563], Loss: 1.8684, Accuracy: 0.5625\n",
      "Epoch [40/100], Step [200/1563], Loss: 1.3416, Accuracy: 0.5938\n",
      "Epoch [40/100], Step [300/1563], Loss: 1.9365, Accuracy: 0.5625\n",
      "Epoch [40/100], Step [400/1563], Loss: 1.7532, Accuracy: 0.5000\n",
      "Epoch [40/100], Step [500/1563], Loss: 1.9182, Accuracy: 0.5312\n",
      "Epoch [40/100], Step [600/1563], Loss: 1.8127, Accuracy: 0.4844\n",
      "Epoch [40/100], Step [700/1563], Loss: 2.0196, Accuracy: 0.4844\n",
      "Epoch [40/100], Step [800/1563], Loss: 1.6108, Accuracy: 0.5625\n",
      "Epoch [40/100], Step [900/1563], Loss: 2.1533, Accuracy: 0.4531\n",
      "Epoch [40/100], Step [1000/1563], Loss: 1.8168, Accuracy: 0.5469\n",
      "Epoch [40/100], Step [1100/1563], Loss: 1.8651, Accuracy: 0.5000\n",
      "Epoch [40/100], Step [1200/1563], Loss: 2.1652, Accuracy: 0.4531\n",
      "Epoch [40/100], Step [1300/1563], Loss: 1.3478, Accuracy: 0.5781\n",
      "Epoch [40/100], Step [1400/1563], Loss: 1.7050, Accuracy: 0.5469\n",
      "Epoch [40/100], Step [1500/1563], Loss: 1.7766, Accuracy: 0.5781\n",
      "Epoch [40/100] - Average Loss: 1.8693\n",
      "Epoch [41/100], Step [0/1563], Loss: 1.6340, Accuracy: 0.5625\n",
      "Epoch [41/100], Step [100/1563], Loss: 1.4241, Accuracy: 0.6250\n",
      "Epoch [41/100], Step [200/1563], Loss: 1.4969, Accuracy: 0.6094\n",
      "Epoch [41/100], Step [300/1563], Loss: 2.2888, Accuracy: 0.3906\n",
      "Epoch [41/100], Step [400/1563], Loss: 2.0487, Accuracy: 0.4688\n",
      "Epoch [41/100], Step [500/1563], Loss: 1.8499, Accuracy: 0.4531\n",
      "Epoch [41/100], Step [600/1563], Loss: 1.9656, Accuracy: 0.4062\n",
      "Epoch [41/100], Step [700/1563], Loss: 2.1525, Accuracy: 0.5000\n",
      "Epoch [41/100], Step [800/1563], Loss: 2.1304, Accuracy: 0.4531\n",
      "Epoch [41/100], Step [900/1563], Loss: 1.6811, Accuracy: 0.5938\n",
      "Epoch [41/100], Step [1000/1563], Loss: 2.0702, Accuracy: 0.4688\n",
      "Epoch [41/100], Step [1100/1563], Loss: 1.9585, Accuracy: 0.4844\n",
      "Epoch [41/100], Step [1200/1563], Loss: 1.6475, Accuracy: 0.5312\n",
      "Epoch [41/100], Step [1300/1563], Loss: 2.4313, Accuracy: 0.3750\n",
      "Epoch [41/100], Step [1400/1563], Loss: 2.2870, Accuracy: 0.4062\n",
      "Epoch [41/100], Step [1500/1563], Loss: 1.7371, Accuracy: 0.5938\n",
      "Epoch [41/100] - Average Loss: 1.8468\n",
      "Epoch [42/100], Step [0/1563], Loss: 1.4804, Accuracy: 0.5625\n",
      "Epoch [42/100], Step [100/1563], Loss: 2.1536, Accuracy: 0.4531\n",
      "Epoch [42/100], Step [200/1563], Loss: 2.0524, Accuracy: 0.4219\n",
      "Epoch [42/100], Step [300/1563], Loss: 1.4750, Accuracy: 0.6094\n",
      "Epoch [42/100], Step [400/1563], Loss: 1.7928, Accuracy: 0.5625\n",
      "Epoch [42/100], Step [500/1563], Loss: 1.6719, Accuracy: 0.5781\n",
      "Epoch [42/100], Step [600/1563], Loss: 2.0935, Accuracy: 0.5000\n",
      "Epoch [42/100], Step [700/1563], Loss: 2.0071, Accuracy: 0.4688\n",
      "Epoch [42/100], Step [800/1563], Loss: 2.2224, Accuracy: 0.4375\n",
      "Epoch [42/100], Step [900/1563], Loss: 2.0479, Accuracy: 0.4844\n",
      "Epoch [42/100], Step [1000/1563], Loss: 1.8672, Accuracy: 0.5156\n",
      "Epoch [42/100], Step [1100/1563], Loss: 1.8016, Accuracy: 0.3906\n",
      "Epoch [42/100], Step [1200/1563], Loss: 1.7745, Accuracy: 0.5312\n",
      "Epoch [42/100], Step [1300/1563], Loss: 2.3057, Accuracy: 0.4375\n",
      "Epoch [42/100], Step [1400/1563], Loss: 2.0169, Accuracy: 0.4375\n",
      "Epoch [42/100], Step [1500/1563], Loss: 2.1511, Accuracy: 0.4531\n",
      "Epoch [42/100] - Average Loss: 1.8527\n",
      "Epoch [43/100], Step [0/1563], Loss: 1.6213, Accuracy: 0.5312\n",
      "Epoch [43/100], Step [100/1563], Loss: 1.9217, Accuracy: 0.4688\n",
      "Epoch [43/100], Step [200/1563], Loss: 1.6819, Accuracy: 0.5781\n",
      "Epoch [43/100], Step [300/1563], Loss: 1.7195, Accuracy: 0.5469\n",
      "Epoch [43/100], Step [400/1563], Loss: 1.9592, Accuracy: 0.4688\n",
      "Epoch [43/100], Step [500/1563], Loss: 1.8250, Accuracy: 0.4688\n",
      "Epoch [43/100], Step [600/1563], Loss: 1.5243, Accuracy: 0.6094\n",
      "Epoch [43/100], Step [700/1563], Loss: 2.5066, Accuracy: 0.4219\n",
      "Epoch [43/100], Step [800/1563], Loss: 1.8476, Accuracy: 0.5000\n",
      "Epoch [43/100], Step [900/1563], Loss: 1.9314, Accuracy: 0.4531\n",
      "Epoch [43/100], Step [1000/1563], Loss: 1.7485, Accuracy: 0.5312\n",
      "Epoch [43/100], Step [1100/1563], Loss: 2.1188, Accuracy: 0.4531\n",
      "Epoch [43/100], Step [1200/1563], Loss: 1.9730, Accuracy: 0.4688\n",
      "Epoch [43/100], Step [1300/1563], Loss: 1.6197, Accuracy: 0.5625\n",
      "Epoch [43/100], Step [1400/1563], Loss: 2.1825, Accuracy: 0.5156\n",
      "Epoch [43/100], Step [1500/1563], Loss: 2.4268, Accuracy: 0.3906\n",
      "Epoch [43/100] - Average Loss: 1.8330\n",
      "Epoch [44/100], Step [0/1563], Loss: 1.6380, Accuracy: 0.5469\n",
      "Epoch [44/100], Step [100/1563], Loss: 1.7463, Accuracy: 0.5312\n",
      "Epoch [44/100], Step [200/1563], Loss: 1.4539, Accuracy: 0.6094\n",
      "Epoch [44/100], Step [300/1563], Loss: 1.4615, Accuracy: 0.5625\n",
      "Epoch [44/100], Step [400/1563], Loss: 1.8267, Accuracy: 0.5000\n",
      "Epoch [44/100], Step [500/1563], Loss: 2.1594, Accuracy: 0.5156\n",
      "Epoch [44/100], Step [600/1563], Loss: 1.5484, Accuracy: 0.5781\n",
      "Epoch [44/100], Step [700/1563], Loss: 1.7885, Accuracy: 0.5000\n",
      "Epoch [44/100], Step [800/1563], Loss: 1.8921, Accuracy: 0.5156\n",
      "Epoch [44/100], Step [900/1563], Loss: 1.6116, Accuracy: 0.6250\n",
      "Epoch [44/100], Step [1000/1563], Loss: 1.8677, Accuracy: 0.4688\n",
      "Epoch [44/100], Step [1100/1563], Loss: 1.4921, Accuracy: 0.5938\n",
      "Epoch [44/100], Step [1200/1563], Loss: 2.2649, Accuracy: 0.3906\n",
      "Epoch [44/100], Step [1300/1563], Loss: 1.4586, Accuracy: 0.5938\n",
      "Epoch [44/100], Step [1400/1563], Loss: 1.7335, Accuracy: 0.5000\n",
      "Epoch [44/100], Step [1500/1563], Loss: 2.0077, Accuracy: 0.4375\n",
      "Epoch [44/100] - Average Loss: 1.7950\n",
      "Epoch [45/100], Step [0/1563], Loss: 1.4181, Accuracy: 0.6406\n",
      "Epoch [45/100], Step [100/1563], Loss: 1.6137, Accuracy: 0.5938\n",
      "Epoch [45/100], Step [200/1563], Loss: 1.4250, Accuracy: 0.6562\n",
      "Epoch [45/100], Step [300/1563], Loss: 2.0578, Accuracy: 0.4219\n",
      "Epoch [45/100], Step [400/1563], Loss: 1.6694, Accuracy: 0.5469\n",
      "Epoch [45/100], Step [500/1563], Loss: 1.6793, Accuracy: 0.5469\n",
      "Epoch [45/100], Step [600/1563], Loss: 1.6460, Accuracy: 0.5938\n",
      "Epoch [45/100], Step [700/1563], Loss: 1.5682, Accuracy: 0.5625\n",
      "Epoch [45/100], Step [800/1563], Loss: 1.6835, Accuracy: 0.6250\n",
      "Epoch [45/100], Step [900/1563], Loss: 1.9791, Accuracy: 0.5469\n",
      "Epoch [45/100], Step [1000/1563], Loss: 2.2046, Accuracy: 0.4219\n",
      "Epoch [45/100], Step [1100/1563], Loss: 1.9481, Accuracy: 0.5312\n",
      "Epoch [45/100], Step [1200/1563], Loss: 1.7838, Accuracy: 0.5938\n",
      "Epoch [45/100], Step [1300/1563], Loss: 2.7316, Accuracy: 0.2969\n",
      "Epoch [45/100], Step [1400/1563], Loss: 1.8497, Accuracy: 0.5938\n",
      "Epoch [45/100], Step [1500/1563], Loss: 1.7651, Accuracy: 0.5000\n",
      "Epoch [45/100] - Average Loss: 1.7855\n",
      "Epoch [46/100], Step [0/1563], Loss: 1.4871, Accuracy: 0.5938\n",
      "Epoch [46/100], Step [100/1563], Loss: 1.4428, Accuracy: 0.6406\n",
      "Epoch [46/100], Step [200/1563], Loss: 1.5761, Accuracy: 0.5000\n",
      "Epoch [46/100], Step [300/1563], Loss: 1.8127, Accuracy: 0.5156\n",
      "Epoch [46/100], Step [400/1563], Loss: 2.0736, Accuracy: 0.4688\n",
      "Epoch [46/100], Step [500/1563], Loss: 1.6950, Accuracy: 0.5469\n",
      "Epoch [46/100], Step [600/1563], Loss: 1.4488, Accuracy: 0.5312\n",
      "Epoch [46/100], Step [700/1563], Loss: 1.5715, Accuracy: 0.4688\n",
      "Epoch [46/100], Step [800/1563], Loss: 2.2088, Accuracy: 0.4219\n",
      "Epoch [46/100], Step [900/1563], Loss: 1.8081, Accuracy: 0.4844\n",
      "Epoch [46/100], Step [1000/1563], Loss: 1.9381, Accuracy: 0.4844\n",
      "Epoch [46/100], Step [1100/1563], Loss: 1.8871, Accuracy: 0.5469\n",
      "Epoch [46/100], Step [1200/1563], Loss: 1.8595, Accuracy: 0.5156\n",
      "Epoch [46/100], Step [1300/1563], Loss: 2.3246, Accuracy: 0.4062\n",
      "Epoch [46/100], Step [1400/1563], Loss: 1.9071, Accuracy: 0.5312\n",
      "Epoch [46/100], Step [1500/1563], Loss: 2.0287, Accuracy: 0.5000\n",
      "Epoch [46/100] - Average Loss: 1.7771\n",
      "Epoch [47/100], Step [0/1563], Loss: 1.7605, Accuracy: 0.5156\n",
      "Epoch [47/100], Step [100/1563], Loss: 1.5822, Accuracy: 0.6250\n",
      "Epoch [47/100], Step [200/1563], Loss: 1.9977, Accuracy: 0.4531\n",
      "Epoch [47/100], Step [300/1563], Loss: 1.7506, Accuracy: 0.6094\n",
      "Epoch [47/100], Step [400/1563], Loss: 1.8358, Accuracy: 0.5156\n",
      "Epoch [47/100], Step [500/1563], Loss: 2.0533, Accuracy: 0.4688\n",
      "Epoch [47/100], Step [600/1563], Loss: 1.8355, Accuracy: 0.4844\n",
      "Epoch [47/100], Step [700/1563], Loss: 1.9174, Accuracy: 0.4688\n",
      "Epoch [47/100], Step [800/1563], Loss: 1.8261, Accuracy: 0.5156\n",
      "Epoch [47/100], Step [900/1563], Loss: 1.9607, Accuracy: 0.5000\n",
      "Epoch [47/100], Step [1000/1563], Loss: 1.8710, Accuracy: 0.5156\n",
      "Epoch [47/100], Step [1100/1563], Loss: 1.8517, Accuracy: 0.5000\n",
      "Epoch [47/100], Step [1200/1563], Loss: 2.1646, Accuracy: 0.4375\n",
      "Epoch [47/100], Step [1300/1563], Loss: 1.9104, Accuracy: 0.5469\n",
      "Epoch [47/100], Step [1400/1563], Loss: 1.8393, Accuracy: 0.4844\n",
      "Epoch [47/100], Step [1500/1563], Loss: 1.6206, Accuracy: 0.5312\n",
      "Epoch [47/100] - Average Loss: 1.8480\n",
      "Epoch [48/100], Step [0/1563], Loss: 1.3132, Accuracy: 0.5781\n",
      "Epoch [48/100], Step [100/1563], Loss: 1.4954, Accuracy: 0.5625\n",
      "Epoch [48/100], Step [200/1563], Loss: 1.5178, Accuracy: 0.5781\n",
      "Epoch [48/100], Step [300/1563], Loss: 2.2738, Accuracy: 0.3594\n",
      "Epoch [48/100], Step [400/1563], Loss: 1.9044, Accuracy: 0.5000\n",
      "Epoch [48/100], Step [500/1563], Loss: 1.7839, Accuracy: 0.5156\n",
      "Epoch [48/100], Step [600/1563], Loss: 1.7211, Accuracy: 0.4844\n",
      "Epoch [48/100], Step [700/1563], Loss: 1.9282, Accuracy: 0.4844\n",
      "Epoch [48/100], Step [800/1563], Loss: 1.6899, Accuracy: 0.5312\n",
      "Epoch [48/100], Step [900/1563], Loss: 1.5068, Accuracy: 0.5781\n",
      "Epoch [48/100], Step [1000/1563], Loss: 1.8263, Accuracy: 0.5469\n",
      "Epoch [48/100], Step [1100/1563], Loss: 1.3779, Accuracy: 0.5625\n",
      "Epoch [48/100], Step [1200/1563], Loss: 1.6018, Accuracy: 0.5938\n",
      "Epoch [48/100], Step [1300/1563], Loss: 1.6769, Accuracy: 0.5781\n",
      "Epoch [48/100], Step [1400/1563], Loss: 1.7464, Accuracy: 0.5625\n",
      "Epoch [48/100], Step [1500/1563], Loss: 1.6210, Accuracy: 0.5625\n",
      "Epoch [48/100] - Average Loss: 1.7353\n",
      "Epoch [49/100], Step [0/1563], Loss: 1.5068, Accuracy: 0.5781\n",
      "Epoch [49/100], Step [100/1563], Loss: 1.3688, Accuracy: 0.6250\n",
      "Epoch [49/100], Step [200/1563], Loss: 1.4362, Accuracy: 0.6094\n",
      "Epoch [49/100], Step [300/1563], Loss: 1.5589, Accuracy: 0.5625\n",
      "Epoch [49/100], Step [400/1563], Loss: 1.7325, Accuracy: 0.5312\n",
      "Epoch [49/100], Step [500/1563], Loss: 1.4493, Accuracy: 0.6094\n",
      "Epoch [49/100], Step [600/1563], Loss: 1.6844, Accuracy: 0.5625\n",
      "Epoch [49/100], Step [700/1563], Loss: 1.3504, Accuracy: 0.6562\n",
      "Epoch [49/100], Step [800/1563], Loss: 2.1767, Accuracy: 0.4375\n",
      "Epoch [49/100], Step [900/1563], Loss: 1.6092, Accuracy: 0.5781\n",
      "Epoch [49/100], Step [1000/1563], Loss: 1.8254, Accuracy: 0.5156\n",
      "Epoch [49/100], Step [1100/1563], Loss: 2.0264, Accuracy: 0.4844\n",
      "Epoch [49/100], Step [1200/1563], Loss: 2.0933, Accuracy: 0.4062\n",
      "Epoch [49/100], Step [1300/1563], Loss: 2.0101, Accuracy: 0.4688\n",
      "Epoch [49/100], Step [1400/1563], Loss: 1.8535, Accuracy: 0.5156\n",
      "Epoch [49/100], Step [1500/1563], Loss: 1.5343, Accuracy: 0.5625\n",
      "Epoch [49/100] - Average Loss: 1.7198\n",
      "Epoch [50/100], Step [0/1563], Loss: 1.1484, Accuracy: 0.7031\n",
      "Epoch [50/100], Step [100/1563], Loss: 1.5385, Accuracy: 0.6250\n",
      "Epoch [50/100], Step [200/1563], Loss: 1.2620, Accuracy: 0.6875\n",
      "Epoch [50/100], Step [300/1563], Loss: 1.8999, Accuracy: 0.5312\n",
      "Epoch [50/100], Step [400/1563], Loss: 1.7735, Accuracy: 0.5312\n",
      "Epoch [50/100], Step [500/1563], Loss: 1.7555, Accuracy: 0.5156\n",
      "Epoch [50/100], Step [600/1563], Loss: 1.7777, Accuracy: 0.4844\n",
      "Epoch [50/100], Step [700/1563], Loss: 2.1418, Accuracy: 0.4688\n",
      "Epoch [50/100], Step [800/1563], Loss: 1.9380, Accuracy: 0.5000\n",
      "Epoch [50/100], Step [900/1563], Loss: 1.7946, Accuracy: 0.5000\n",
      "Epoch [50/100], Step [1000/1563], Loss: 1.9038, Accuracy: 0.4375\n",
      "Epoch [50/100], Step [1100/1563], Loss: 1.3331, Accuracy: 0.6719\n",
      "Epoch [50/100], Step [1200/1563], Loss: 1.9795, Accuracy: 0.4844\n",
      "Epoch [50/100], Step [1300/1563], Loss: 1.9048, Accuracy: 0.5000\n",
      "Epoch [50/100], Step [1400/1563], Loss: 1.7794, Accuracy: 0.5625\n",
      "Epoch [50/100], Step [1500/1563], Loss: 1.9056, Accuracy: 0.4844\n",
      "Epoch [50/100] - Average Loss: 1.6820\n",
      "Epoch [51/100], Step [0/1563], Loss: 1.7725, Accuracy: 0.5312\n",
      "Epoch [51/100], Step [100/1563], Loss: 1.1784, Accuracy: 0.6719\n",
      "Epoch [51/100], Step [200/1563], Loss: 1.2827, Accuracy: 0.6094\n",
      "Epoch [51/100], Step [300/1563], Loss: 1.7668, Accuracy: 0.5156\n",
      "Epoch [51/100], Step [400/1563], Loss: 1.4503, Accuracy: 0.5938\n",
      "Epoch [51/100], Step [500/1563], Loss: 1.5048, Accuracy: 0.5781\n",
      "Epoch [51/100], Step [600/1563], Loss: 1.7275, Accuracy: 0.5625\n",
      "Epoch [51/100], Step [700/1563], Loss: 1.6375, Accuracy: 0.5312\n",
      "Epoch [51/100], Step [800/1563], Loss: 1.6577, Accuracy: 0.5781\n",
      "Epoch [51/100], Step [900/1563], Loss: 1.6122, Accuracy: 0.5156\n",
      "Epoch [51/100], Step [1000/1563], Loss: 2.0890, Accuracy: 0.4219\n",
      "Epoch [51/100], Step [1100/1563], Loss: 2.0253, Accuracy: 0.5156\n",
      "Epoch [51/100], Step [1200/1563], Loss: 1.8145, Accuracy: 0.5156\n",
      "Epoch [51/100], Step [1300/1563], Loss: 1.9686, Accuracy: 0.5000\n",
      "Epoch [51/100], Step [1400/1563], Loss: 1.4454, Accuracy: 0.5625\n",
      "Epoch [51/100], Step [1500/1563], Loss: 1.4185, Accuracy: 0.5781\n",
      "Epoch [51/100] - Average Loss: 1.7214\n",
      "Epoch [52/100], Step [0/1563], Loss: 1.6134, Accuracy: 0.5156\n",
      "Epoch [52/100], Step [100/1563], Loss: 1.3316, Accuracy: 0.6094\n",
      "Epoch [52/100], Step [200/1563], Loss: 1.8106, Accuracy: 0.5312\n",
      "Epoch [52/100], Step [300/1563], Loss: 1.6036, Accuracy: 0.5625\n",
      "Epoch [52/100], Step [400/1563], Loss: 1.3990, Accuracy: 0.5938\n",
      "Epoch [52/100], Step [500/1563], Loss: 1.5609, Accuracy: 0.6250\n",
      "Epoch [52/100], Step [600/1563], Loss: 1.5495, Accuracy: 0.5781\n",
      "Epoch [52/100], Step [700/1563], Loss: 1.3271, Accuracy: 0.6250\n",
      "Epoch [52/100], Step [800/1563], Loss: 1.7914, Accuracy: 0.5156\n",
      "Epoch [52/100], Step [900/1563], Loss: 1.6025, Accuracy: 0.5938\n",
      "Epoch [52/100], Step [1000/1563], Loss: 2.5302, Accuracy: 0.3594\n",
      "Epoch [52/100], Step [1100/1563], Loss: 1.7979, Accuracy: 0.5000\n",
      "Epoch [52/100], Step [1200/1563], Loss: 1.7825, Accuracy: 0.5312\n",
      "Epoch [52/100], Step [1300/1563], Loss: 1.6089, Accuracy: 0.6094\n",
      "Epoch [52/100], Step [1400/1563], Loss: 1.7914, Accuracy: 0.4844\n",
      "Epoch [52/100], Step [1500/1563], Loss: 1.8147, Accuracy: 0.5000\n",
      "Epoch [52/100] - Average Loss: 1.6944\n",
      "Epoch [53/100], Step [0/1563], Loss: 1.9273, Accuracy: 0.5469\n",
      "Epoch [53/100], Step [100/1563], Loss: 1.4159, Accuracy: 0.5938\n",
      "Epoch [53/100], Step [200/1563], Loss: 1.6825, Accuracy: 0.4688\n",
      "Epoch [53/100], Step [300/1563], Loss: 1.4538, Accuracy: 0.6094\n",
      "Epoch [53/100], Step [400/1563], Loss: 1.9395, Accuracy: 0.4219\n",
      "Epoch [53/100], Step [500/1563], Loss: 1.4230, Accuracy: 0.5938\n",
      "Epoch [53/100], Step [600/1563], Loss: 1.7320, Accuracy: 0.5625\n",
      "Epoch [53/100], Step [700/1563], Loss: 1.4374, Accuracy: 0.6094\n",
      "Epoch [53/100], Step [800/1563], Loss: 1.3575, Accuracy: 0.7031\n",
      "Epoch [53/100], Step [900/1563], Loss: 1.8182, Accuracy: 0.5312\n",
      "Epoch [53/100], Step [1000/1563], Loss: 2.1136, Accuracy: 0.4531\n",
      "Epoch [53/100], Step [1100/1563], Loss: 1.5114, Accuracy: 0.5625\n",
      "Epoch [53/100], Step [1200/1563], Loss: 1.5086, Accuracy: 0.5469\n",
      "Epoch [53/100], Step [1300/1563], Loss: 1.7123, Accuracy: 0.5156\n",
      "Epoch [53/100], Step [1400/1563], Loss: 2.1267, Accuracy: 0.4375\n",
      "Epoch [53/100], Step [1500/1563], Loss: 1.6525, Accuracy: 0.5781\n",
      "Epoch [53/100] - Average Loss: 1.7144\n",
      "Epoch [54/100], Step [0/1563], Loss: 2.0076, Accuracy: 0.4688\n",
      "Epoch [54/100], Step [100/1563], Loss: 1.4497, Accuracy: 0.6875\n",
      "Epoch [54/100], Step [200/1563], Loss: 1.6520, Accuracy: 0.5781\n",
      "Epoch [54/100], Step [300/1563], Loss: 1.3167, Accuracy: 0.5469\n",
      "Epoch [54/100], Step [400/1563], Loss: 1.2280, Accuracy: 0.6719\n",
      "Epoch [54/100], Step [500/1563], Loss: 1.5954, Accuracy: 0.5938\n",
      "Epoch [54/100], Step [600/1563], Loss: 1.5775, Accuracy: 0.5625\n",
      "Epoch [54/100], Step [700/1563], Loss: 1.6463, Accuracy: 0.5469\n",
      "Epoch [54/100], Step [800/1563], Loss: 1.7055, Accuracy: 0.5938\n",
      "Epoch [54/100], Step [900/1563], Loss: 1.0847, Accuracy: 0.6875\n",
      "Epoch [54/100], Step [1000/1563], Loss: 1.6543, Accuracy: 0.4688\n",
      "Epoch [54/100], Step [1100/1563], Loss: 1.5392, Accuracy: 0.5156\n",
      "Epoch [54/100], Step [1200/1563], Loss: 1.6431, Accuracy: 0.5781\n",
      "Epoch [54/100], Step [1300/1563], Loss: 1.8176, Accuracy: 0.5312\n",
      "Epoch [54/100], Step [1400/1563], Loss: 1.6342, Accuracy: 0.5312\n",
      "Epoch [54/100], Step [1500/1563], Loss: 1.4092, Accuracy: 0.5469\n",
      "Epoch [54/100] - Average Loss: 1.6537\n",
      "Epoch [55/100], Step [0/1563], Loss: 1.1895, Accuracy: 0.6875\n",
      "Epoch [55/100], Step [100/1563], Loss: 1.1028, Accuracy: 0.6719\n",
      "Epoch [55/100], Step [200/1563], Loss: 1.1534, Accuracy: 0.6875\n",
      "Epoch [55/100], Step [300/1563], Loss: 1.3686, Accuracy: 0.6094\n",
      "Epoch [55/100], Step [400/1563], Loss: 1.7365, Accuracy: 0.4688\n",
      "Epoch [55/100], Step [500/1563], Loss: 1.7857, Accuracy: 0.5625\n",
      "Epoch [55/100], Step [600/1563], Loss: 1.3726, Accuracy: 0.6250\n",
      "Epoch [55/100], Step [700/1563], Loss: 1.5282, Accuracy: 0.5156\n",
      "Epoch [55/100], Step [800/1563], Loss: 1.6044, Accuracy: 0.5156\n",
      "Epoch [55/100], Step [900/1563], Loss: 2.0364, Accuracy: 0.5156\n",
      "Epoch [55/100], Step [1000/1563], Loss: 1.3653, Accuracy: 0.5938\n",
      "Epoch [55/100], Step [1100/1563], Loss: 1.7582, Accuracy: 0.4844\n",
      "Epoch [55/100], Step [1200/1563], Loss: 1.4675, Accuracy: 0.5781\n",
      "Epoch [55/100], Step [1300/1563], Loss: 2.1698, Accuracy: 0.4219\n",
      "Epoch [55/100], Step [1400/1563], Loss: 1.9607, Accuracy: 0.4531\n",
      "Epoch [55/100], Step [1500/1563], Loss: 1.6902, Accuracy: 0.5312\n",
      "Epoch [55/100] - Average Loss: 1.6745\n",
      "Epoch [56/100], Step [0/1563], Loss: 1.8939, Accuracy: 0.5000\n",
      "Epoch [56/100], Step [100/1563], Loss: 1.2832, Accuracy: 0.6094\n",
      "Epoch [56/100], Step [200/1563], Loss: 1.9194, Accuracy: 0.5469\n",
      "Epoch [56/100], Step [300/1563], Loss: 1.3759, Accuracy: 0.6719\n",
      "Epoch [56/100], Step [400/1563], Loss: 1.6688, Accuracy: 0.5469\n",
      "Epoch [56/100], Step [500/1563], Loss: 1.5126, Accuracy: 0.5938\n",
      "Epoch [56/100], Step [600/1563], Loss: 1.5643, Accuracy: 0.5781\n",
      "Epoch [56/100], Step [700/1563], Loss: 1.4171, Accuracy: 0.6406\n",
      "Epoch [56/100], Step [800/1563], Loss: 1.7896, Accuracy: 0.5000\n",
      "Epoch [56/100], Step [900/1563], Loss: 1.4208, Accuracy: 0.5938\n",
      "Epoch [56/100], Step [1000/1563], Loss: 1.4497, Accuracy: 0.6562\n",
      "Epoch [56/100], Step [1100/1563], Loss: 1.7300, Accuracy: 0.4375\n",
      "Epoch [56/100], Step [1200/1563], Loss: 1.5175, Accuracy: 0.6719\n",
      "Epoch [56/100], Step [1300/1563], Loss: 2.0765, Accuracy: 0.4375\n",
      "Epoch [56/100], Step [1400/1563], Loss: 1.3411, Accuracy: 0.6094\n",
      "Epoch [56/100], Step [1500/1563], Loss: 1.8057, Accuracy: 0.5000\n",
      "Epoch [56/100] - Average Loss: 1.6199\n",
      "Epoch [57/100], Step [0/1563], Loss: 1.1082, Accuracy: 0.6250\n",
      "Epoch [57/100], Step [100/1563], Loss: 1.4883, Accuracy: 0.6562\n",
      "Epoch [57/100], Step [200/1563], Loss: 1.5128, Accuracy: 0.5938\n",
      "Epoch [57/100], Step [300/1563], Loss: 1.9275, Accuracy: 0.5312\n",
      "Epoch [57/100], Step [400/1563], Loss: 1.3009, Accuracy: 0.6406\n",
      "Epoch [57/100], Step [500/1563], Loss: 1.6804, Accuracy: 0.5312\n",
      "Epoch [57/100], Step [600/1563], Loss: 1.6574, Accuracy: 0.5156\n",
      "Epoch [57/100], Step [700/1563], Loss: 2.2562, Accuracy: 0.4219\n",
      "Epoch [57/100], Step [800/1563], Loss: 2.1932, Accuracy: 0.4531\n",
      "Epoch [57/100], Step [900/1563], Loss: 1.7268, Accuracy: 0.4844\n",
      "Epoch [57/100], Step [1000/1563], Loss: 1.9969, Accuracy: 0.4844\n",
      "Epoch [57/100], Step [1100/1563], Loss: 1.3298, Accuracy: 0.6562\n",
      "Epoch [57/100], Step [1200/1563], Loss: 1.6914, Accuracy: 0.4844\n",
      "Epoch [57/100], Step [1300/1563], Loss: 1.9258, Accuracy: 0.5156\n",
      "Epoch [57/100], Step [1400/1563], Loss: 1.6023, Accuracy: 0.5469\n",
      "Epoch [57/100], Step [1500/1563], Loss: 1.2825, Accuracy: 0.7031\n",
      "Epoch [57/100] - Average Loss: 1.6757\n",
      "Epoch [58/100], Step [0/1563], Loss: 1.2509, Accuracy: 0.5625\n",
      "Epoch [58/100], Step [100/1563], Loss: 1.5741, Accuracy: 0.5781\n",
      "Epoch [58/100], Step [200/1563], Loss: 1.8423, Accuracy: 0.4844\n",
      "Epoch [58/100], Step [300/1563], Loss: 1.5397, Accuracy: 0.5156\n",
      "Epoch [58/100], Step [400/1563], Loss: 1.6158, Accuracy: 0.6094\n",
      "Epoch [58/100], Step [500/1563], Loss: 1.3447, Accuracy: 0.6562\n",
      "Epoch [58/100], Step [600/1563], Loss: 1.6812, Accuracy: 0.5156\n",
      "Epoch [58/100], Step [700/1563], Loss: 1.5558, Accuracy: 0.6250\n",
      "Epoch [58/100], Step [800/1563], Loss: 1.6621, Accuracy: 0.5625\n",
      "Epoch [58/100], Step [900/1563], Loss: 1.7808, Accuracy: 0.5000\n",
      "Epoch [58/100], Step [1000/1563], Loss: 1.3067, Accuracy: 0.6719\n",
      "Epoch [58/100], Step [1100/1563], Loss: 1.7522, Accuracy: 0.5312\n",
      "Epoch [58/100], Step [1200/1563], Loss: 1.6578, Accuracy: 0.5156\n",
      "Epoch [58/100], Step [1300/1563], Loss: 1.0953, Accuracy: 0.6875\n",
      "Epoch [58/100], Step [1400/1563], Loss: 1.6052, Accuracy: 0.6094\n",
      "Epoch [58/100], Step [1500/1563], Loss: 1.6051, Accuracy: 0.5781\n",
      "Epoch [58/100] - Average Loss: 1.6167\n",
      "Epoch [59/100], Step [0/1563], Loss: 1.4744, Accuracy: 0.6094\n",
      "Epoch [59/100], Step [100/1563], Loss: 1.3535, Accuracy: 0.6406\n",
      "Epoch [59/100], Step [200/1563], Loss: 2.0684, Accuracy: 0.4688\n",
      "Epoch [59/100], Step [300/1563], Loss: 1.4824, Accuracy: 0.5156\n",
      "Epoch [59/100], Step [400/1563], Loss: 1.4336, Accuracy: 0.6406\n",
      "Epoch [59/100], Step [500/1563], Loss: 1.6469, Accuracy: 0.5312\n",
      "Epoch [59/100], Step [600/1563], Loss: 1.8239, Accuracy: 0.5625\n",
      "Epoch [59/100], Step [700/1563], Loss: 1.2757, Accuracy: 0.6562\n",
      "Epoch [59/100], Step [800/1563], Loss: 1.7585, Accuracy: 0.5625\n",
      "Epoch [59/100], Step [900/1563], Loss: 1.4530, Accuracy: 0.6094\n",
      "Epoch [59/100], Step [1000/1563], Loss: 1.7956, Accuracy: 0.5312\n",
      "Epoch [59/100], Step [1100/1563], Loss: 1.7363, Accuracy: 0.4219\n",
      "Epoch [59/100], Step [1200/1563], Loss: 1.4699, Accuracy: 0.5938\n",
      "Epoch [59/100], Step [1300/1563], Loss: 1.7375, Accuracy: 0.4375\n",
      "Epoch [59/100], Step [1400/1563], Loss: 1.3231, Accuracy: 0.5938\n",
      "Epoch [59/100], Step [1500/1563], Loss: 1.7814, Accuracy: 0.4688\n",
      "Epoch [59/100] - Average Loss: 1.5967\n",
      "Epoch [60/100], Step [0/1563], Loss: 1.4108, Accuracy: 0.6250\n",
      "Epoch [60/100], Step [100/1563], Loss: 1.4862, Accuracy: 0.4844\n",
      "Epoch [60/100], Step [200/1563], Loss: 1.4039, Accuracy: 0.5938\n",
      "Epoch [60/100], Step [300/1563], Loss: 1.4193, Accuracy: 0.5469\n",
      "Epoch [60/100], Step [400/1563], Loss: 1.8499, Accuracy: 0.5469\n",
      "Epoch [60/100], Step [500/1563], Loss: 1.6393, Accuracy: 0.6250\n",
      "Epoch [60/100], Step [600/1563], Loss: 1.8997, Accuracy: 0.4688\n",
      "Epoch [60/100], Step [700/1563], Loss: 1.2599, Accuracy: 0.6562\n",
      "Epoch [60/100], Step [800/1563], Loss: 1.3344, Accuracy: 0.6406\n",
      "Epoch [60/100], Step [900/1563], Loss: 1.6193, Accuracy: 0.5625\n",
      "Epoch [60/100], Step [1000/1563], Loss: 1.3287, Accuracy: 0.6719\n",
      "Epoch [60/100], Step [1100/1563], Loss: 2.2859, Accuracy: 0.4688\n",
      "Epoch [60/100], Step [1200/1563], Loss: 1.8763, Accuracy: 0.5000\n",
      "Epoch [60/100], Step [1300/1563], Loss: 1.5814, Accuracy: 0.6406\n",
      "Epoch [60/100], Step [1400/1563], Loss: 1.6727, Accuracy: 0.5312\n",
      "Epoch [60/100], Step [1500/1563], Loss: 1.9933, Accuracy: 0.5000\n",
      "Epoch [60/100] - Average Loss: 1.5745\n",
      "Epoch [61/100], Step [0/1563], Loss: 1.5574, Accuracy: 0.6094\n",
      "Epoch [61/100], Step [100/1563], Loss: 1.1333, Accuracy: 0.6719\n",
      "Epoch [61/100], Step [200/1563], Loss: 1.2765, Accuracy: 0.7031\n",
      "Epoch [61/100], Step [300/1563], Loss: 1.7738, Accuracy: 0.5781\n",
      "Epoch [61/100], Step [400/1563], Loss: 1.8086, Accuracy: 0.5000\n",
      "Epoch [61/100], Step [500/1563], Loss: 1.1516, Accuracy: 0.6406\n",
      "Epoch [61/100], Step [600/1563], Loss: 1.4854, Accuracy: 0.5625\n",
      "Epoch [61/100], Step [700/1563], Loss: 1.3877, Accuracy: 0.6562\n",
      "Epoch [61/100], Step [800/1563], Loss: 1.6608, Accuracy: 0.5938\n",
      "Epoch [61/100], Step [900/1563], Loss: 1.5615, Accuracy: 0.6719\n",
      "Epoch [61/100], Step [1000/1563], Loss: 1.6017, Accuracy: 0.5469\n",
      "Epoch [61/100], Step [1100/1563], Loss: 1.6956, Accuracy: 0.5625\n",
      "Epoch [61/100], Step [1200/1563], Loss: 1.9989, Accuracy: 0.4531\n",
      "Epoch [61/100], Step [1300/1563], Loss: 1.3569, Accuracy: 0.6250\n",
      "Epoch [61/100], Step [1400/1563], Loss: 1.3765, Accuracy: 0.5625\n",
      "Epoch [61/100], Step [1500/1563], Loss: 1.9124, Accuracy: 0.4375\n",
      "Epoch [61/100] - Average Loss: 1.5288\n",
      "Epoch [62/100], Step [0/1563], Loss: 1.0816, Accuracy: 0.7031\n",
      "Epoch [62/100], Step [100/1563], Loss: 1.2731, Accuracy: 0.6562\n",
      "Epoch [62/100], Step [200/1563], Loss: 1.2240, Accuracy: 0.6406\n",
      "Epoch [62/100], Step [300/1563], Loss: 1.5436, Accuracy: 0.6094\n",
      "Epoch [62/100], Step [400/1563], Loss: 1.2428, Accuracy: 0.6875\n",
      "Epoch [62/100], Step [500/1563], Loss: 1.9315, Accuracy: 0.4844\n",
      "Epoch [62/100], Step [600/1563], Loss: 1.2726, Accuracy: 0.5938\n",
      "Epoch [62/100], Step [700/1563], Loss: 1.5825, Accuracy: 0.5781\n",
      "Epoch [62/100], Step [800/1563], Loss: 1.3917, Accuracy: 0.6250\n",
      "Epoch [62/100], Step [900/1563], Loss: 1.6808, Accuracy: 0.5156\n",
      "Epoch [62/100], Step [1000/1563], Loss: 1.6356, Accuracy: 0.5781\n",
      "Epoch [62/100], Step [1100/1563], Loss: 1.8207, Accuracy: 0.4531\n",
      "Epoch [62/100], Step [1200/1563], Loss: 1.5873, Accuracy: 0.5312\n",
      "Epoch [62/100], Step [1300/1563], Loss: 1.4069, Accuracy: 0.5469\n",
      "Epoch [62/100], Step [1400/1563], Loss: 1.8721, Accuracy: 0.6094\n",
      "Epoch [62/100], Step [1500/1563], Loss: 1.6856, Accuracy: 0.5625\n",
      "Epoch [62/100] - Average Loss: 1.4999\n",
      "Epoch [63/100], Step [0/1563], Loss: 1.2888, Accuracy: 0.6094\n",
      "Epoch [63/100], Step [100/1563], Loss: 1.2487, Accuracy: 0.6875\n",
      "Epoch [63/100], Step [200/1563], Loss: 1.1504, Accuracy: 0.6250\n",
      "Epoch [63/100], Step [300/1563], Loss: 1.5495, Accuracy: 0.6094\n",
      "Epoch [63/100], Step [400/1563], Loss: 1.3201, Accuracy: 0.6406\n",
      "Epoch [63/100], Step [500/1563], Loss: 1.2137, Accuracy: 0.6719\n",
      "Epoch [63/100], Step [600/1563], Loss: 2.1178, Accuracy: 0.4219\n",
      "Epoch [63/100], Step [700/1563], Loss: 1.5443, Accuracy: 0.5625\n",
      "Epoch [63/100], Step [800/1563], Loss: 1.8585, Accuracy: 0.5312\n",
      "Epoch [63/100], Step [900/1563], Loss: 1.4843, Accuracy: 0.5469\n",
      "Epoch [63/100], Step [1000/1563], Loss: 1.3380, Accuracy: 0.5625\n",
      "Epoch [63/100], Step [1100/1563], Loss: 1.3438, Accuracy: 0.6250\n",
      "Epoch [63/100], Step [1200/1563], Loss: 1.5748, Accuracy: 0.5312\n",
      "Epoch [63/100], Step [1300/1563], Loss: 1.4807, Accuracy: 0.5312\n",
      "Epoch [63/100], Step [1400/1563], Loss: 1.9077, Accuracy: 0.4844\n",
      "Epoch [63/100], Step [1500/1563], Loss: 1.1848, Accuracy: 0.6719\n",
      "Epoch [63/100] - Average Loss: 1.5282\n",
      "Epoch [64/100], Step [0/1563], Loss: 1.7294, Accuracy: 0.5312\n",
      "Epoch [64/100], Step [100/1563], Loss: 1.3968, Accuracy: 0.5938\n",
      "Epoch [64/100], Step [200/1563], Loss: 1.0998, Accuracy: 0.6406\n",
      "Epoch [64/100], Step [300/1563], Loss: 1.1571, Accuracy: 0.6562\n",
      "Epoch [64/100], Step [400/1563], Loss: 1.9837, Accuracy: 0.4531\n",
      "Epoch [64/100], Step [500/1563], Loss: 1.3717, Accuracy: 0.6250\n",
      "Epoch [64/100], Step [600/1563], Loss: 1.2080, Accuracy: 0.6719\n",
      "Epoch [64/100], Step [700/1563], Loss: 1.2866, Accuracy: 0.6250\n",
      "Epoch [64/100], Step [800/1563], Loss: 1.7704, Accuracy: 0.5469\n",
      "Epoch [64/100], Step [900/1563], Loss: 1.5771, Accuracy: 0.5938\n",
      "Epoch [64/100], Step [1000/1563], Loss: 1.9070, Accuracy: 0.5469\n",
      "Epoch [64/100], Step [1100/1563], Loss: 1.8892, Accuracy: 0.4531\n",
      "Epoch [64/100], Step [1200/1563], Loss: 1.5515, Accuracy: 0.5781\n",
      "Epoch [64/100], Step [1300/1563], Loss: 1.6123, Accuracy: 0.5000\n",
      "Epoch [64/100], Step [1400/1563], Loss: 1.1482, Accuracy: 0.6250\n",
      "Epoch [64/100], Step [1500/1563], Loss: 1.5057, Accuracy: 0.5781\n",
      "Epoch [64/100] - Average Loss: 1.4920\n",
      "Epoch [65/100], Step [0/1563], Loss: 1.5993, Accuracy: 0.5469\n",
      "Epoch [65/100], Step [100/1563], Loss: 1.6036, Accuracy: 0.5625\n",
      "Epoch [65/100], Step [200/1563], Loss: 1.1483, Accuracy: 0.6875\n",
      "Epoch [65/100], Step [300/1563], Loss: 1.5068, Accuracy: 0.4844\n",
      "Epoch [65/100], Step [400/1563], Loss: 1.1028, Accuracy: 0.7031\n",
      "Epoch [65/100], Step [500/1563], Loss: 1.4740, Accuracy: 0.6094\n",
      "Epoch [65/100], Step [600/1563], Loss: 1.5582, Accuracy: 0.5938\n",
      "Epoch [65/100], Step [700/1563], Loss: 1.5720, Accuracy: 0.5625\n",
      "Epoch [65/100], Step [800/1563], Loss: 1.4457, Accuracy: 0.5625\n",
      "Epoch [65/100], Step [900/1563], Loss: 1.6677, Accuracy: 0.5469\n",
      "Epoch [65/100], Step [1000/1563], Loss: 1.7249, Accuracy: 0.5312\n",
      "Epoch [65/100], Step [1100/1563], Loss: 1.0965, Accuracy: 0.6719\n",
      "Epoch [65/100], Step [1200/1563], Loss: 1.1297, Accuracy: 0.6719\n",
      "Epoch [65/100], Step [1300/1563], Loss: 1.4384, Accuracy: 0.5938\n",
      "Epoch [65/100], Step [1400/1563], Loss: 1.4830, Accuracy: 0.6094\n",
      "Epoch [65/100], Step [1500/1563], Loss: 2.0518, Accuracy: 0.5312\n",
      "Epoch [65/100] - Average Loss: 1.4868\n",
      "Epoch [66/100], Step [0/1563], Loss: 1.1707, Accuracy: 0.6406\n",
      "Epoch [66/100], Step [100/1563], Loss: 1.3129, Accuracy: 0.6094\n",
      "Epoch [66/100], Step [200/1563], Loss: 1.3340, Accuracy: 0.5625\n",
      "Epoch [66/100], Step [300/1563], Loss: 1.5550, Accuracy: 0.5625\n",
      "Epoch [66/100], Step [400/1563], Loss: 1.4784, Accuracy: 0.5312\n",
      "Epoch [66/100], Step [500/1563], Loss: 1.5100, Accuracy: 0.6094\n",
      "Epoch [66/100], Step [600/1563], Loss: 1.7089, Accuracy: 0.5625\n",
      "Epoch [66/100], Step [700/1563], Loss: 1.7923, Accuracy: 0.4688\n",
      "Epoch [66/100], Step [800/1563], Loss: 1.6806, Accuracy: 0.4688\n",
      "Epoch [66/100], Step [900/1563], Loss: 1.3471, Accuracy: 0.5938\n",
      "Epoch [66/100], Step [1000/1563], Loss: 1.8222, Accuracy: 0.5000\n",
      "Epoch [66/100], Step [1100/1563], Loss: 1.3631, Accuracy: 0.5312\n",
      "Epoch [66/100], Step [1200/1563], Loss: 1.7218, Accuracy: 0.6094\n",
      "Epoch [66/100], Step [1300/1563], Loss: 1.2634, Accuracy: 0.7188\n",
      "Epoch [66/100], Step [1400/1563], Loss: 1.1971, Accuracy: 0.6406\n",
      "Epoch [66/100], Step [1500/1563], Loss: 1.4302, Accuracy: 0.5312\n",
      "Epoch [66/100] - Average Loss: 1.4654\n",
      "Epoch [67/100], Step [0/1563], Loss: 1.0337, Accuracy: 0.6406\n",
      "Epoch [67/100], Step [100/1563], Loss: 1.1799, Accuracy: 0.6875\n",
      "Epoch [67/100], Step [200/1563], Loss: 1.4547, Accuracy: 0.5781\n",
      "Epoch [67/100], Step [300/1563], Loss: 0.9894, Accuracy: 0.7500\n",
      "Epoch [67/100], Step [400/1563], Loss: 1.5553, Accuracy: 0.5000\n",
      "Epoch [67/100], Step [500/1563], Loss: 1.5514, Accuracy: 0.5625\n",
      "Epoch [67/100], Step [600/1563], Loss: 1.2562, Accuracy: 0.6250\n",
      "Epoch [67/100], Step [700/1563], Loss: 1.2754, Accuracy: 0.6250\n",
      "Epoch [67/100], Step [800/1563], Loss: 1.3237, Accuracy: 0.5781\n",
      "Epoch [67/100], Step [900/1563], Loss: 1.2551, Accuracy: 0.6406\n",
      "Epoch [67/100], Step [1000/1563], Loss: 1.5930, Accuracy: 0.5625\n",
      "Epoch [67/100], Step [1100/1563], Loss: 1.4226, Accuracy: 0.6094\n",
      "Epoch [67/100], Step [1200/1563], Loss: 1.5106, Accuracy: 0.5469\n",
      "Epoch [67/100], Step [1300/1563], Loss: 1.5022, Accuracy: 0.5938\n",
      "Epoch [67/100], Step [1400/1563], Loss: 1.9272, Accuracy: 0.4219\n",
      "Epoch [67/100], Step [1500/1563], Loss: 1.6987, Accuracy: 0.5781\n",
      "Epoch [67/100] - Average Loss: 1.4943\n",
      "Epoch [68/100], Step [0/1563], Loss: 1.1983, Accuracy: 0.6250\n",
      "Epoch [68/100], Step [100/1563], Loss: 1.4573, Accuracy: 0.6250\n",
      "Epoch [68/100], Step [200/1563], Loss: 0.9051, Accuracy: 0.6719\n",
      "Epoch [68/100], Step [300/1563], Loss: 1.2324, Accuracy: 0.6562\n",
      "Epoch [68/100], Step [400/1563], Loss: 1.7533, Accuracy: 0.6250\n",
      "Epoch [68/100], Step [500/1563], Loss: 1.1516, Accuracy: 0.6875\n",
      "Epoch [68/100], Step [600/1563], Loss: 1.5543, Accuracy: 0.6094\n",
      "Epoch [68/100], Step [700/1563], Loss: 1.3568, Accuracy: 0.5781\n",
      "Epoch [68/100], Step [800/1563], Loss: 1.8291, Accuracy: 0.4688\n",
      "Epoch [68/100], Step [900/1563], Loss: 1.6811, Accuracy: 0.6094\n",
      "Epoch [68/100], Step [1000/1563], Loss: 1.3696, Accuracy: 0.5781\n",
      "Epoch [68/100], Step [1100/1563], Loss: 1.4960, Accuracy: 0.5781\n",
      "Epoch [68/100], Step [1200/1563], Loss: 1.2831, Accuracy: 0.6719\n",
      "Epoch [68/100], Step [1300/1563], Loss: 1.5596, Accuracy: 0.5781\n",
      "Epoch [68/100], Step [1400/1563], Loss: 1.3848, Accuracy: 0.5312\n",
      "Epoch [68/100], Step [1500/1563], Loss: 1.5843, Accuracy: 0.6094\n",
      "Epoch [68/100] - Average Loss: 1.4272\n",
      "Epoch [69/100], Step [0/1563], Loss: 1.4515, Accuracy: 0.6094\n",
      "Epoch [69/100], Step [100/1563], Loss: 1.2089, Accuracy: 0.6875\n",
      "Epoch [69/100], Step [200/1563], Loss: 0.9991, Accuracy: 0.7812\n",
      "Epoch [69/100], Step [300/1563], Loss: 1.0909, Accuracy: 0.6875\n",
      "Epoch [69/100], Step [400/1563], Loss: 1.4544, Accuracy: 0.5625\n",
      "Epoch [69/100], Step [500/1563], Loss: 1.2982, Accuracy: 0.6250\n",
      "Epoch [69/100], Step [600/1563], Loss: 1.1016, Accuracy: 0.7344\n",
      "Epoch [69/100], Step [700/1563], Loss: 1.2568, Accuracy: 0.6406\n",
      "Epoch [69/100], Step [800/1563], Loss: 1.0858, Accuracy: 0.5938\n",
      "Epoch [69/100], Step [900/1563], Loss: 1.2918, Accuracy: 0.6250\n",
      "Epoch [69/100], Step [1000/1563], Loss: 1.7347, Accuracy: 0.5625\n",
      "Epoch [69/100], Step [1100/1563], Loss: 1.5595, Accuracy: 0.5312\n",
      "Epoch [69/100], Step [1200/1563], Loss: 1.6143, Accuracy: 0.5156\n",
      "Epoch [69/100], Step [1300/1563], Loss: 1.4207, Accuracy: 0.6250\n",
      "Epoch [69/100], Step [1400/1563], Loss: 1.1934, Accuracy: 0.7031\n",
      "Epoch [69/100], Step [1500/1563], Loss: 1.9457, Accuracy: 0.4531\n",
      "Epoch [69/100] - Average Loss: 1.4113\n",
      "Epoch [70/100], Step [0/1563], Loss: 1.5677, Accuracy: 0.5156\n",
      "Epoch [70/100], Step [100/1563], Loss: 1.0786, Accuracy: 0.7188\n",
      "Epoch [70/100], Step [200/1563], Loss: 0.8942, Accuracy: 0.7188\n",
      "Epoch [70/100], Step [300/1563], Loss: 1.1824, Accuracy: 0.6406\n",
      "Epoch [70/100], Step [400/1563], Loss: 1.2280, Accuracy: 0.7344\n",
      "Epoch [70/100], Step [500/1563], Loss: 1.5556, Accuracy: 0.6250\n",
      "Epoch [70/100], Step [600/1563], Loss: 1.5804, Accuracy: 0.5312\n",
      "Epoch [70/100], Step [700/1563], Loss: 1.3791, Accuracy: 0.6719\n",
      "Epoch [70/100], Step [800/1563], Loss: 1.3090, Accuracy: 0.5625\n",
      "Epoch [70/100], Step [900/1563], Loss: 1.1808, Accuracy: 0.6406\n",
      "Epoch [70/100], Step [1000/1563], Loss: 1.5361, Accuracy: 0.5781\n",
      "Epoch [70/100], Step [1100/1563], Loss: 1.1510, Accuracy: 0.5781\n",
      "Epoch [70/100], Step [1200/1563], Loss: 1.5573, Accuracy: 0.5938\n",
      "Epoch [70/100], Step [1300/1563], Loss: 1.5553, Accuracy: 0.5156\n",
      "Epoch [70/100], Step [1400/1563], Loss: 1.3606, Accuracy: 0.6719\n",
      "Epoch [70/100], Step [1500/1563], Loss: 1.6333, Accuracy: 0.5156\n",
      "Epoch [70/100] - Average Loss: 1.3976\n",
      "Epoch [71/100], Step [0/1563], Loss: 1.2561, Accuracy: 0.6719\n",
      "Epoch [71/100], Step [100/1563], Loss: 1.0385, Accuracy: 0.7188\n",
      "Epoch [71/100], Step [200/1563], Loss: 1.6343, Accuracy: 0.5781\n",
      "Epoch [71/100], Step [300/1563], Loss: 1.2655, Accuracy: 0.5625\n",
      "Epoch [71/100], Step [400/1563], Loss: 1.2112, Accuracy: 0.6094\n",
      "Epoch [71/100], Step [500/1563], Loss: 1.5692, Accuracy: 0.6094\n",
      "Epoch [71/100], Step [600/1563], Loss: 1.4111, Accuracy: 0.5938\n",
      "Epoch [71/100], Step [700/1563], Loss: 1.3808, Accuracy: 0.5625\n",
      "Epoch [71/100], Step [800/1563], Loss: 1.7190, Accuracy: 0.5781\n",
      "Epoch [71/100], Step [900/1563], Loss: 0.9602, Accuracy: 0.7500\n",
      "Epoch [71/100], Step [1000/1563], Loss: 0.9653, Accuracy: 0.7344\n",
      "Epoch [71/100], Step [1100/1563], Loss: 1.9386, Accuracy: 0.5781\n",
      "Epoch [71/100], Step [1200/1563], Loss: 1.3302, Accuracy: 0.5938\n",
      "Epoch [71/100], Step [1300/1563], Loss: 1.1998, Accuracy: 0.6562\n",
      "Epoch [71/100], Step [1400/1563], Loss: 1.1483, Accuracy: 0.6719\n",
      "Epoch [71/100], Step [1500/1563], Loss: 1.3931, Accuracy: 0.6094\n",
      "Epoch [71/100] - Average Loss: 1.4010\n",
      "Epoch [72/100], Step [0/1563], Loss: 1.6015, Accuracy: 0.5938\n",
      "Epoch [72/100], Step [100/1563], Loss: 1.0303, Accuracy: 0.7344\n",
      "Epoch [72/100], Step [200/1563], Loss: 1.2458, Accuracy: 0.5625\n",
      "Epoch [72/100], Step [300/1563], Loss: 1.4133, Accuracy: 0.5938\n",
      "Epoch [72/100], Step [400/1563], Loss: 2.0470, Accuracy: 0.4688\n",
      "Epoch [72/100], Step [500/1563], Loss: 1.2122, Accuracy: 0.6562\n",
      "Epoch [72/100], Step [600/1563], Loss: 1.5598, Accuracy: 0.6406\n",
      "Epoch [72/100], Step [700/1563], Loss: 1.1914, Accuracy: 0.6562\n",
      "Epoch [72/100], Step [800/1563], Loss: 1.2228, Accuracy: 0.6406\n",
      "Epoch [72/100], Step [900/1563], Loss: 1.4803, Accuracy: 0.5625\n",
      "Epoch [72/100], Step [1000/1563], Loss: 1.9442, Accuracy: 0.5156\n",
      "Epoch [72/100], Step [1100/1563], Loss: 1.5091, Accuracy: 0.5469\n",
      "Epoch [72/100], Step [1200/1563], Loss: 1.4890, Accuracy: 0.5312\n",
      "Epoch [72/100], Step [1300/1563], Loss: 1.9174, Accuracy: 0.5312\n",
      "Epoch [72/100], Step [1400/1563], Loss: 1.9635, Accuracy: 0.4844\n",
      "Epoch [72/100], Step [1500/1563], Loss: 1.2849, Accuracy: 0.5781\n",
      "Epoch [72/100] - Average Loss: 1.4925\n",
      "Epoch [73/100], Step [0/1563], Loss: 1.9281, Accuracy: 0.4688\n",
      "Epoch [73/100], Step [100/1563], Loss: 1.3163, Accuracy: 0.5781\n",
      "Epoch [73/100], Step [200/1563], Loss: 1.1331, Accuracy: 0.5938\n",
      "Epoch [73/100], Step [300/1563], Loss: 1.2669, Accuracy: 0.6719\n",
      "Epoch [73/100], Step [400/1563], Loss: 1.3594, Accuracy: 0.6094\n",
      "Epoch [73/100], Step [500/1563], Loss: 1.6007, Accuracy: 0.5469\n",
      "Epoch [73/100], Step [600/1563], Loss: 1.5134, Accuracy: 0.5938\n",
      "Epoch [73/100], Step [700/1563], Loss: 1.3978, Accuracy: 0.6562\n",
      "Epoch [73/100], Step [800/1563], Loss: 1.1980, Accuracy: 0.6406\n",
      "Epoch [73/100], Step [900/1563], Loss: 1.0526, Accuracy: 0.7188\n",
      "Epoch [73/100], Step [1000/1563], Loss: 1.4394, Accuracy: 0.5781\n",
      "Epoch [73/100], Step [1100/1563], Loss: 1.3721, Accuracy: 0.5625\n",
      "Epoch [73/100], Step [1200/1563], Loss: 0.9621, Accuracy: 0.7031\n",
      "Epoch [73/100], Step [1300/1563], Loss: 1.5708, Accuracy: 0.5000\n",
      "Epoch [73/100], Step [1400/1563], Loss: 1.2400, Accuracy: 0.6406\n",
      "Epoch [73/100], Step [1500/1563], Loss: 1.0921, Accuracy: 0.6562\n",
      "Epoch [73/100] - Average Loss: 1.3829\n",
      "Epoch [74/100], Step [0/1563], Loss: 1.0565, Accuracy: 0.7188\n",
      "Epoch [74/100], Step [100/1563], Loss: 1.3998, Accuracy: 0.5469\n",
      "Epoch [74/100], Step [200/1563], Loss: 1.3919, Accuracy: 0.6094\n",
      "Epoch [74/100], Step [300/1563], Loss: 1.6177, Accuracy: 0.5469\n",
      "Epoch [74/100], Step [400/1563], Loss: 1.1752, Accuracy: 0.7031\n",
      "Epoch [74/100], Step [500/1563], Loss: 1.3216, Accuracy: 0.5938\n",
      "Epoch [74/100], Step [600/1563], Loss: 1.5108, Accuracy: 0.5625\n",
      "Epoch [74/100], Step [700/1563], Loss: 1.1518, Accuracy: 0.5938\n",
      "Epoch [74/100], Step [800/1563], Loss: 1.2056, Accuracy: 0.7188\n",
      "Epoch [74/100], Step [900/1563], Loss: 1.5710, Accuracy: 0.5625\n",
      "Epoch [74/100], Step [1000/1563], Loss: 1.3400, Accuracy: 0.6094\n",
      "Epoch [74/100], Step [1100/1563], Loss: 1.1971, Accuracy: 0.7188\n",
      "Epoch [74/100], Step [1200/1563], Loss: 1.6190, Accuracy: 0.5781\n",
      "Epoch [74/100], Step [1300/1563], Loss: 1.3781, Accuracy: 0.5781\n",
      "Epoch [74/100], Step [1400/1563], Loss: 1.4529, Accuracy: 0.5312\n",
      "Epoch [74/100], Step [1500/1563], Loss: 1.4879, Accuracy: 0.5625\n",
      "Epoch [74/100] - Average Loss: 1.3524\n",
      "Epoch [75/100], Step [0/1563], Loss: 1.5813, Accuracy: 0.4844\n",
      "Epoch [75/100], Step [100/1563], Loss: 1.3572, Accuracy: 0.5938\n",
      "Epoch [75/100], Step [200/1563], Loss: 1.4039, Accuracy: 0.6406\n",
      "Epoch [75/100], Step [300/1563], Loss: 1.3687, Accuracy: 0.6250\n",
      "Epoch [75/100], Step [400/1563], Loss: 1.4700, Accuracy: 0.6094\n",
      "Epoch [75/100], Step [500/1563], Loss: 1.2816, Accuracy: 0.6250\n",
      "Epoch [75/100], Step [600/1563], Loss: 1.3211, Accuracy: 0.5938\n",
      "Epoch [75/100], Step [700/1563], Loss: 1.5366, Accuracy: 0.5781\n",
      "Epoch [75/100], Step [800/1563], Loss: 1.2546, Accuracy: 0.6562\n",
      "Epoch [75/100], Step [900/1563], Loss: 1.2401, Accuracy: 0.6094\n",
      "Epoch [75/100], Step [1000/1563], Loss: 1.5767, Accuracy: 0.5625\n",
      "Epoch [75/100], Step [1100/1563], Loss: 1.5027, Accuracy: 0.5469\n",
      "Epoch [75/100], Step [1200/1563], Loss: 1.1461, Accuracy: 0.6562\n",
      "Epoch [75/100], Step [1300/1563], Loss: 1.5293, Accuracy: 0.5469\n",
      "Epoch [75/100], Step [1400/1563], Loss: 1.2950, Accuracy: 0.6406\n",
      "Epoch [75/100], Step [1500/1563], Loss: 1.4818, Accuracy: 0.5625\n",
      "Epoch [75/100] - Average Loss: 1.3696\n",
      "Epoch [76/100], Step [0/1563], Loss: 1.6249, Accuracy: 0.6562\n",
      "Epoch [76/100], Step [100/1563], Loss: 1.1827, Accuracy: 0.6719\n",
      "Epoch [76/100], Step [200/1563], Loss: 0.9890, Accuracy: 0.7188\n",
      "Epoch [76/100], Step [300/1563], Loss: 1.5025, Accuracy: 0.5938\n",
      "Epoch [76/100], Step [400/1563], Loss: 1.3803, Accuracy: 0.5938\n",
      "Epoch [76/100], Step [500/1563], Loss: 1.0844, Accuracy: 0.6875\n",
      "Epoch [76/100], Step [600/1563], Loss: 1.2891, Accuracy: 0.6250\n",
      "Epoch [76/100], Step [700/1563], Loss: 1.3606, Accuracy: 0.5625\n",
      "Epoch [76/100], Step [800/1563], Loss: 1.3199, Accuracy: 0.6094\n",
      "Epoch [76/100], Step [900/1563], Loss: 1.2530, Accuracy: 0.6250\n",
      "Epoch [76/100], Step [1000/1563], Loss: 1.4126, Accuracy: 0.6875\n",
      "Epoch [76/100], Step [1100/1563], Loss: 1.3677, Accuracy: 0.6719\n",
      "Epoch [76/100], Step [1200/1563], Loss: 1.6785, Accuracy: 0.5000\n",
      "Epoch [76/100], Step [1300/1563], Loss: 1.5814, Accuracy: 0.5781\n",
      "Epoch [76/100], Step [1400/1563], Loss: 1.3086, Accuracy: 0.6094\n",
      "Epoch [76/100], Step [1500/1563], Loss: 1.2584, Accuracy: 0.6250\n",
      "Epoch [76/100] - Average Loss: 1.3621\n",
      "Epoch [77/100], Step [0/1563], Loss: 0.8332, Accuracy: 0.7812\n",
      "Epoch [77/100], Step [100/1563], Loss: 1.2788, Accuracy: 0.6562\n",
      "Epoch [77/100], Step [200/1563], Loss: 1.0694, Accuracy: 0.7188\n",
      "Epoch [77/100], Step [300/1563], Loss: 1.4809, Accuracy: 0.6562\n",
      "Epoch [77/100], Step [400/1563], Loss: 1.0593, Accuracy: 0.7031\n",
      "Epoch [77/100], Step [500/1563], Loss: 1.1368, Accuracy: 0.6875\n",
      "Epoch [77/100], Step [600/1563], Loss: 1.0953, Accuracy: 0.6875\n",
      "Epoch [77/100], Step [700/1563], Loss: 0.9853, Accuracy: 0.7344\n",
      "Epoch [77/100], Step [800/1563], Loss: 1.3060, Accuracy: 0.6406\n",
      "Epoch [77/100], Step [900/1563], Loss: 1.4776, Accuracy: 0.6250\n",
      "Epoch [77/100], Step [1000/1563], Loss: 1.0061, Accuracy: 0.7188\n",
      "Epoch [77/100], Step [1100/1563], Loss: 1.5475, Accuracy: 0.5781\n",
      "Epoch [77/100], Step [1200/1563], Loss: 1.3615, Accuracy: 0.6406\n",
      "Epoch [77/100], Step [1300/1563], Loss: 1.3899, Accuracy: 0.5625\n",
      "Epoch [77/100], Step [1400/1563], Loss: 1.2683, Accuracy: 0.6094\n",
      "Epoch [77/100], Step [1500/1563], Loss: 1.6221, Accuracy: 0.5938\n",
      "Epoch [77/100] - Average Loss: 1.3129\n",
      "Epoch [78/100], Step [0/1563], Loss: 1.2072, Accuracy: 0.6562\n",
      "Epoch [78/100], Step [100/1563], Loss: 1.9509, Accuracy: 0.5469\n",
      "Epoch [78/100], Step [200/1563], Loss: 1.3417, Accuracy: 0.5000\n",
      "Epoch [78/100], Step [300/1563], Loss: 1.6928, Accuracy: 0.5312\n",
      "Epoch [78/100], Step [400/1563], Loss: 1.6137, Accuracy: 0.5156\n",
      "Epoch [78/100], Step [500/1563], Loss: 1.8942, Accuracy: 0.4375\n",
      "Epoch [78/100], Step [600/1563], Loss: 1.2853, Accuracy: 0.6406\n",
      "Epoch [78/100], Step [700/1563], Loss: 1.4848, Accuracy: 0.6562\n",
      "Epoch [78/100], Step [800/1563], Loss: 1.3494, Accuracy: 0.5938\n",
      "Epoch [78/100], Step [900/1563], Loss: 1.3355, Accuracy: 0.6562\n",
      "Epoch [78/100], Step [1000/1563], Loss: 1.2782, Accuracy: 0.5938\n",
      "Epoch [78/100], Step [1100/1563], Loss: 1.0680, Accuracy: 0.6719\n",
      "Epoch [78/100], Step [1200/1563], Loss: 1.4818, Accuracy: 0.5469\n",
      "Epoch [78/100], Step [1300/1563], Loss: 1.5949, Accuracy: 0.5781\n",
      "Epoch [78/100], Step [1400/1563], Loss: 1.6151, Accuracy: 0.5938\n",
      "Epoch [78/100], Step [1500/1563], Loss: 1.3893, Accuracy: 0.5781\n",
      "Epoch [78/100] - Average Loss: 1.3606\n",
      "Epoch [79/100], Step [0/1563], Loss: 1.1516, Accuracy: 0.6875\n",
      "Epoch [79/100], Step [100/1563], Loss: 0.8562, Accuracy: 0.6875\n",
      "Epoch [79/100], Step [200/1563], Loss: 1.2861, Accuracy: 0.6562\n",
      "Epoch [79/100], Step [300/1563], Loss: 1.2367, Accuracy: 0.6406\n",
      "Epoch [79/100], Step [400/1563], Loss: 1.0761, Accuracy: 0.5781\n",
      "Epoch [79/100], Step [500/1563], Loss: 1.5386, Accuracy: 0.6250\n",
      "Epoch [79/100], Step [600/1563], Loss: 1.2184, Accuracy: 0.6250\n",
      "Epoch [79/100], Step [700/1563], Loss: 1.5004, Accuracy: 0.6250\n",
      "Epoch [79/100], Step [800/1563], Loss: 0.8765, Accuracy: 0.7969\n",
      "Epoch [79/100], Step [900/1563], Loss: 1.3331, Accuracy: 0.6719\n",
      "Epoch [79/100], Step [1000/1563], Loss: 1.3076, Accuracy: 0.6562\n",
      "Epoch [79/100], Step [1100/1563], Loss: 1.2439, Accuracy: 0.6250\n",
      "Epoch [79/100], Step [1200/1563], Loss: 0.9659, Accuracy: 0.7031\n",
      "Epoch [79/100], Step [1300/1563], Loss: 1.0981, Accuracy: 0.7031\n",
      "Epoch [79/100], Step [1400/1563], Loss: 1.2684, Accuracy: 0.5938\n",
      "Epoch [79/100], Step [1500/1563], Loss: 1.5987, Accuracy: 0.5469\n",
      "Epoch [79/100] - Average Loss: 1.2783\n",
      "Epoch [80/100], Step [0/1563], Loss: 1.3596, Accuracy: 0.5938\n",
      "Epoch [80/100], Step [100/1563], Loss: 0.9482, Accuracy: 0.7500\n",
      "Epoch [80/100], Step [200/1563], Loss: 1.1943, Accuracy: 0.5938\n",
      "Epoch [80/100], Step [300/1563], Loss: 1.4250, Accuracy: 0.6562\n",
      "Epoch [80/100], Step [400/1563], Loss: 1.2449, Accuracy: 0.6250\n",
      "Epoch [80/100], Step [500/1563], Loss: 1.3583, Accuracy: 0.6562\n",
      "Epoch [80/100], Step [600/1563], Loss: 1.2962, Accuracy: 0.6094\n",
      "Epoch [80/100], Step [700/1563], Loss: 1.1482, Accuracy: 0.6094\n",
      "Epoch [80/100], Step [800/1563], Loss: 1.3055, Accuracy: 0.5781\n",
      "Epoch [80/100], Step [900/1563], Loss: 1.1877, Accuracy: 0.6562\n",
      "Epoch [80/100], Step [1000/1563], Loss: 1.0821, Accuracy: 0.7031\n",
      "Epoch [80/100], Step [1100/1563], Loss: 1.1310, Accuracy: 0.7500\n",
      "Epoch [80/100], Step [1200/1563], Loss: 1.4314, Accuracy: 0.6250\n",
      "Epoch [80/100], Step [1300/1563], Loss: 1.1573, Accuracy: 0.7031\n",
      "Epoch [80/100], Step [1400/1563], Loss: 1.4158, Accuracy: 0.6562\n",
      "Epoch [80/100], Step [1500/1563], Loss: 1.1098, Accuracy: 0.7031\n",
      "Epoch [80/100] - Average Loss: 1.2614\n",
      "Epoch [81/100], Step [0/1563], Loss: 1.1216, Accuracy: 0.6094\n",
      "Epoch [81/100], Step [100/1563], Loss: 0.9726, Accuracy: 0.7031\n",
      "Epoch [81/100], Step [200/1563], Loss: 0.4919, Accuracy: 0.8750\n",
      "Epoch [81/100], Step [300/1563], Loss: 0.9912, Accuracy: 0.6719\n",
      "Epoch [81/100], Step [400/1563], Loss: 0.8961, Accuracy: 0.7188\n",
      "Epoch [81/100], Step [500/1563], Loss: 1.4177, Accuracy: 0.5312\n",
      "Epoch [81/100], Step [600/1563], Loss: 1.3144, Accuracy: 0.5781\n",
      "Epoch [81/100], Step [700/1563], Loss: 0.9619, Accuracy: 0.7812\n",
      "Epoch [81/100], Step [800/1563], Loss: 1.3678, Accuracy: 0.5781\n",
      "Epoch [81/100], Step [900/1563], Loss: 1.6911, Accuracy: 0.5312\n",
      "Epoch [81/100], Step [1000/1563], Loss: 1.3789, Accuracy: 0.5312\n",
      "Epoch [81/100], Step [1100/1563], Loss: 1.4227, Accuracy: 0.5469\n",
      "Epoch [81/100], Step [1200/1563], Loss: 1.2965, Accuracy: 0.6094\n",
      "Epoch [81/100], Step [1300/1563], Loss: 1.2387, Accuracy: 0.5469\n",
      "Epoch [81/100], Step [1400/1563], Loss: 1.3155, Accuracy: 0.6875\n",
      "Epoch [81/100], Step [1500/1563], Loss: 1.2337, Accuracy: 0.6250\n",
      "Epoch [81/100] - Average Loss: 1.2756\n",
      "Epoch [82/100], Step [0/1563], Loss: 0.8369, Accuracy: 0.7656\n",
      "Epoch [82/100], Step [100/1563], Loss: 1.2003, Accuracy: 0.6719\n",
      "Epoch [82/100], Step [200/1563], Loss: 1.2798, Accuracy: 0.5938\n",
      "Epoch [82/100], Step [300/1563], Loss: 1.1265, Accuracy: 0.6719\n",
      "Epoch [82/100], Step [400/1563], Loss: 1.3936, Accuracy: 0.6250\n",
      "Epoch [82/100], Step [500/1563], Loss: 1.7783, Accuracy: 0.4531\n",
      "Epoch [82/100], Step [600/1563], Loss: 1.3663, Accuracy: 0.6250\n",
      "Epoch [82/100], Step [700/1563], Loss: 1.4230, Accuracy: 0.4844\n",
      "Epoch [82/100], Step [800/1563], Loss: 0.9954, Accuracy: 0.7500\n",
      "Epoch [82/100], Step [900/1563], Loss: 1.2119, Accuracy: 0.7031\n",
      "Epoch [82/100], Step [1000/1563], Loss: 1.6561, Accuracy: 0.5469\n",
      "Epoch [82/100], Step [1100/1563], Loss: 0.9481, Accuracy: 0.7188\n",
      "Epoch [82/100], Step [1200/1563], Loss: 1.2089, Accuracy: 0.6094\n",
      "Epoch [82/100], Step [1300/1563], Loss: 1.8363, Accuracy: 0.5000\n",
      "Epoch [82/100], Step [1400/1563], Loss: 1.4583, Accuracy: 0.5938\n",
      "Epoch [82/100], Step [1500/1563], Loss: 1.7873, Accuracy: 0.4844\n",
      "Epoch [82/100] - Average Loss: 1.2682\n",
      "Epoch [83/100], Step [0/1563], Loss: 1.1535, Accuracy: 0.6719\n",
      "Epoch [83/100], Step [100/1563], Loss: 0.8300, Accuracy: 0.7500\n",
      "Epoch [83/100], Step [200/1563], Loss: 0.9733, Accuracy: 0.6719\n",
      "Epoch [83/100], Step [300/1563], Loss: 1.0717, Accuracy: 0.7188\n",
      "Epoch [83/100], Step [400/1563], Loss: 1.2745, Accuracy: 0.6406\n",
      "Epoch [83/100], Step [500/1563], Loss: 1.2599, Accuracy: 0.6875\n",
      "Epoch [83/100], Step [600/1563], Loss: 1.4560, Accuracy: 0.6094\n",
      "Epoch [83/100], Step [700/1563], Loss: 1.2064, Accuracy: 0.7031\n",
      "Epoch [83/100], Step [800/1563], Loss: 1.3915, Accuracy: 0.6250\n",
      "Epoch [83/100], Step [900/1563], Loss: 1.2190, Accuracy: 0.6562\n",
      "Epoch [83/100], Step [1000/1563], Loss: 1.4033, Accuracy: 0.5781\n",
      "Epoch [83/100], Step [1100/1563], Loss: 1.1780, Accuracy: 0.6406\n",
      "Epoch [83/100], Step [1200/1563], Loss: 1.3234, Accuracy: 0.5938\n",
      "Epoch [83/100], Step [1300/1563], Loss: 1.2427, Accuracy: 0.6719\n",
      "Epoch [83/100], Step [1400/1563], Loss: 1.3587, Accuracy: 0.6094\n",
      "Epoch [83/100], Step [1500/1563], Loss: 1.2166, Accuracy: 0.7031\n",
      "Epoch [83/100] - Average Loss: 1.2434\n",
      "Epoch [84/100], Step [0/1563], Loss: 1.5467, Accuracy: 0.5625\n",
      "Epoch [84/100], Step [100/1563], Loss: 1.1062, Accuracy: 0.6094\n",
      "Epoch [84/100], Step [200/1563], Loss: 1.0270, Accuracy: 0.6875\n",
      "Epoch [84/100], Step [300/1563], Loss: 1.3985, Accuracy: 0.5625\n",
      "Epoch [84/100], Step [400/1563], Loss: 0.8749, Accuracy: 0.7031\n",
      "Epoch [84/100], Step [500/1563], Loss: 1.0746, Accuracy: 0.7344\n",
      "Epoch [84/100], Step [600/1563], Loss: 1.1341, Accuracy: 0.6562\n",
      "Epoch [84/100], Step [700/1563], Loss: 1.6448, Accuracy: 0.5469\n",
      "Epoch [84/100], Step [800/1563], Loss: 1.3107, Accuracy: 0.6094\n",
      "Epoch [84/100], Step [900/1563], Loss: 1.3745, Accuracy: 0.6250\n",
      "Epoch [84/100], Step [1000/1563], Loss: 1.2313, Accuracy: 0.6562\n",
      "Epoch [84/100], Step [1100/1563], Loss: 1.2958, Accuracy: 0.5938\n",
      "Epoch [84/100], Step [1200/1563], Loss: 1.2635, Accuracy: 0.6562\n",
      "Epoch [84/100], Step [1300/1563], Loss: 1.0158, Accuracy: 0.7344\n",
      "Epoch [84/100], Step [1400/1563], Loss: 1.4844, Accuracy: 0.5000\n",
      "Epoch [84/100], Step [1500/1563], Loss: 1.2640, Accuracy: 0.5938\n",
      "Epoch [84/100] - Average Loss: 1.2556\n",
      "Epoch [85/100], Step [0/1563], Loss: 1.1656, Accuracy: 0.7031\n",
      "Epoch [85/100], Step [100/1563], Loss: 1.0741, Accuracy: 0.7344\n",
      "Epoch [85/100], Step [200/1563], Loss: 1.5388, Accuracy: 0.5938\n",
      "Epoch [85/100], Step [300/1563], Loss: 1.1187, Accuracy: 0.7188\n",
      "Epoch [85/100], Step [400/1563], Loss: 0.8297, Accuracy: 0.7812\n",
      "Epoch [85/100], Step [500/1563], Loss: 0.9410, Accuracy: 0.7031\n",
      "Epoch [85/100], Step [600/1563], Loss: 0.9744, Accuracy: 0.6875\n",
      "Epoch [85/100], Step [700/1563], Loss: 1.1017, Accuracy: 0.6562\n",
      "Epoch [85/100], Step [800/1563], Loss: 0.9309, Accuracy: 0.6406\n",
      "Epoch [85/100], Step [900/1563], Loss: 1.0348, Accuracy: 0.7344\n",
      "Epoch [85/100], Step [1000/1563], Loss: 1.0968, Accuracy: 0.6875\n",
      "Epoch [85/100], Step [1100/1563], Loss: 1.2162, Accuracy: 0.6406\n",
      "Epoch [85/100], Step [1200/1563], Loss: 1.5712, Accuracy: 0.5625\n",
      "Epoch [85/100], Step [1300/1563], Loss: 0.8875, Accuracy: 0.7656\n",
      "Epoch [85/100], Step [1400/1563], Loss: 1.7848, Accuracy: 0.5781\n",
      "Epoch [85/100], Step [1500/1563], Loss: 1.2711, Accuracy: 0.6406\n",
      "Epoch [85/100] - Average Loss: 1.2713\n",
      "Epoch [86/100], Step [0/1563], Loss: 0.7862, Accuracy: 0.7812\n",
      "Epoch [86/100], Step [100/1563], Loss: 0.9886, Accuracy: 0.7500\n",
      "Epoch [86/100], Step [200/1563], Loss: 0.9712, Accuracy: 0.7188\n",
      "Epoch [86/100], Step [300/1563], Loss: 1.3666, Accuracy: 0.6250\n",
      "Epoch [86/100], Step [400/1563], Loss: 1.0466, Accuracy: 0.6719\n",
      "Epoch [86/100], Step [500/1563], Loss: 1.1187, Accuracy: 0.6875\n",
      "Epoch [86/100], Step [600/1563], Loss: 1.3235, Accuracy: 0.5938\n",
      "Epoch [86/100], Step [700/1563], Loss: 1.3634, Accuracy: 0.5625\n",
      "Epoch [86/100], Step [800/1563], Loss: 1.2185, Accuracy: 0.6562\n",
      "Epoch [86/100], Step [900/1563], Loss: 1.1990, Accuracy: 0.7031\n",
      "Epoch [86/100], Step [1000/1563], Loss: 0.9731, Accuracy: 0.7188\n",
      "Epoch [86/100], Step [1100/1563], Loss: 1.0019, Accuracy: 0.6719\n",
      "Epoch [86/100], Step [1200/1563], Loss: 1.1032, Accuracy: 0.6562\n",
      "Epoch [86/100], Step [1300/1563], Loss: 1.2713, Accuracy: 0.6250\n",
      "Epoch [86/100], Step [1400/1563], Loss: 1.3991, Accuracy: 0.6094\n",
      "Epoch [86/100], Step [1500/1563], Loss: 1.4270, Accuracy: 0.5938\n",
      "Epoch [86/100] - Average Loss: 1.1933\n",
      "Epoch [87/100], Step [0/1563], Loss: 1.1175, Accuracy: 0.6875\n",
      "Epoch [87/100], Step [100/1563], Loss: 0.8148, Accuracy: 0.8438\n",
      "Epoch [87/100], Step [200/1563], Loss: 1.1368, Accuracy: 0.6562\n",
      "Epoch [87/100], Step [300/1563], Loss: 0.8260, Accuracy: 0.7188\n",
      "Epoch [87/100], Step [400/1563], Loss: 0.7946, Accuracy: 0.7344\n",
      "Epoch [87/100], Step [500/1563], Loss: 0.7994, Accuracy: 0.7188\n",
      "Epoch [87/100], Step [600/1563], Loss: 1.0515, Accuracy: 0.7500\n",
      "Epoch [87/100], Step [700/1563], Loss: 1.4063, Accuracy: 0.6562\n",
      "Epoch [87/100], Step [800/1563], Loss: 1.3040, Accuracy: 0.5938\n",
      "Epoch [87/100], Step [900/1563], Loss: 1.3979, Accuracy: 0.6562\n",
      "Epoch [87/100], Step [1000/1563], Loss: 1.3537, Accuracy: 0.6250\n",
      "Epoch [87/100], Step [1100/1563], Loss: 0.9515, Accuracy: 0.7656\n",
      "Epoch [87/100], Step [1200/1563], Loss: 1.0799, Accuracy: 0.6719\n",
      "Epoch [87/100], Step [1300/1563], Loss: 1.3596, Accuracy: 0.6875\n",
      "Epoch [87/100], Step [1400/1563], Loss: 1.1900, Accuracy: 0.6406\n",
      "Epoch [87/100], Step [1500/1563], Loss: 1.6375, Accuracy: 0.5000\n",
      "Epoch [87/100] - Average Loss: 1.1912\n",
      "Epoch [88/100], Step [0/1563], Loss: 0.7831, Accuracy: 0.8281\n",
      "Epoch [88/100], Step [100/1563], Loss: 1.0125, Accuracy: 0.6406\n",
      "Epoch [88/100], Step [200/1563], Loss: 1.0121, Accuracy: 0.7188\n",
      "Epoch [88/100], Step [300/1563], Loss: 1.3906, Accuracy: 0.6406\n",
      "Epoch [88/100], Step [400/1563], Loss: 1.0138, Accuracy: 0.7031\n",
      "Epoch [88/100], Step [500/1563], Loss: 1.1168, Accuracy: 0.7031\n",
      "Epoch [88/100], Step [600/1563], Loss: 0.8517, Accuracy: 0.7188\n",
      "Epoch [88/100], Step [700/1563], Loss: 1.0784, Accuracy: 0.6719\n",
      "Epoch [88/100], Step [800/1563], Loss: 1.2949, Accuracy: 0.6719\n",
      "Epoch [88/100], Step [900/1563], Loss: 1.2793, Accuracy: 0.6406\n",
      "Epoch [88/100], Step [1000/1563], Loss: 0.7632, Accuracy: 0.7812\n",
      "Epoch [88/100], Step [1100/1563], Loss: 1.0545, Accuracy: 0.7188\n",
      "Epoch [88/100], Step [1200/1563], Loss: 1.3369, Accuracy: 0.5781\n",
      "Epoch [88/100], Step [1300/1563], Loss: 1.0702, Accuracy: 0.7188\n",
      "Epoch [88/100], Step [1400/1563], Loss: 1.3227, Accuracy: 0.6562\n",
      "Epoch [88/100], Step [1500/1563], Loss: 1.1047, Accuracy: 0.7188\n",
      "Epoch [88/100] - Average Loss: 1.1865\n",
      "Epoch [89/100], Step [0/1563], Loss: 0.8902, Accuracy: 0.6562\n",
      "Epoch [89/100], Step [100/1563], Loss: 1.1270, Accuracy: 0.6562\n",
      "Epoch [89/100], Step [200/1563], Loss: 1.2189, Accuracy: 0.6094\n",
      "Epoch [89/100], Step [300/1563], Loss: 1.0010, Accuracy: 0.7031\n",
      "Epoch [89/100], Step [400/1563], Loss: 1.1306, Accuracy: 0.6875\n",
      "Epoch [89/100], Step [500/1563], Loss: 1.2786, Accuracy: 0.5625\n",
      "Epoch [89/100], Step [600/1563], Loss: 1.2646, Accuracy: 0.6406\n",
      "Epoch [89/100], Step [700/1563], Loss: 1.2888, Accuracy: 0.6875\n",
      "Epoch [89/100], Step [800/1563], Loss: 1.3944, Accuracy: 0.5781\n",
      "Epoch [89/100], Step [900/1563], Loss: 1.5455, Accuracy: 0.6250\n",
      "Epoch [89/100], Step [1000/1563], Loss: 1.2638, Accuracy: 0.5938\n",
      "Epoch [89/100], Step [1100/1563], Loss: 1.2973, Accuracy: 0.6406\n",
      "Epoch [89/100], Step [1200/1563], Loss: 1.0150, Accuracy: 0.7188\n",
      "Epoch [89/100], Step [1300/1563], Loss: 1.5658, Accuracy: 0.5469\n",
      "Epoch [89/100], Step [1400/1563], Loss: 1.5851, Accuracy: 0.5312\n",
      "Epoch [89/100], Step [1500/1563], Loss: 1.3145, Accuracy: 0.5469\n",
      "Epoch [89/100] - Average Loss: 1.1781\n",
      "Epoch [90/100], Step [0/1563], Loss: 0.8794, Accuracy: 0.7812\n",
      "Epoch [90/100], Step [100/1563], Loss: 0.9179, Accuracy: 0.7188\n",
      "Epoch [90/100], Step [200/1563], Loss: 1.0291, Accuracy: 0.6719\n",
      "Epoch [90/100], Step [300/1563], Loss: 1.0647, Accuracy: 0.6719\n",
      "Epoch [90/100], Step [400/1563], Loss: 1.3493, Accuracy: 0.5938\n",
      "Epoch [90/100], Step [500/1563], Loss: 0.7459, Accuracy: 0.7344\n",
      "Epoch [90/100], Step [600/1563], Loss: 1.4539, Accuracy: 0.6562\n",
      "Epoch [90/100], Step [700/1563], Loss: 0.8782, Accuracy: 0.6875\n",
      "Epoch [90/100], Step [800/1563], Loss: 0.7658, Accuracy: 0.7188\n",
      "Epoch [90/100], Step [900/1563], Loss: 1.0063, Accuracy: 0.7188\n",
      "Epoch [90/100], Step [1000/1563], Loss: 1.1666, Accuracy: 0.6719\n",
      "Epoch [90/100], Step [1100/1563], Loss: 1.3526, Accuracy: 0.5469\n",
      "Epoch [90/100], Step [1200/1563], Loss: 1.3747, Accuracy: 0.6719\n",
      "Epoch [90/100], Step [1300/1563], Loss: 1.2393, Accuracy: 0.7188\n",
      "Epoch [90/100], Step [1400/1563], Loss: 1.1290, Accuracy: 0.6562\n",
      "Epoch [90/100], Step [1500/1563], Loss: 1.3082, Accuracy: 0.6250\n",
      "Epoch [90/100] - Average Loss: 1.1590\n",
      "Epoch [91/100], Step [0/1563], Loss: 1.0897, Accuracy: 0.6250\n",
      "Epoch [91/100], Step [100/1563], Loss: 1.1054, Accuracy: 0.7188\n",
      "Epoch [91/100], Step [200/1563], Loss: 1.1333, Accuracy: 0.6875\n",
      "Epoch [91/100], Step [300/1563], Loss: 0.8916, Accuracy: 0.7188\n",
      "Epoch [91/100], Step [400/1563], Loss: 0.9884, Accuracy: 0.7031\n",
      "Epoch [91/100], Step [500/1563], Loss: 1.2023, Accuracy: 0.6875\n",
      "Epoch [91/100], Step [600/1563], Loss: 1.3157, Accuracy: 0.5938\n",
      "Epoch [91/100], Step [700/1563], Loss: 1.2897, Accuracy: 0.6250\n",
      "Epoch [91/100], Step [800/1563], Loss: 1.0163, Accuracy: 0.6562\n",
      "Epoch [91/100], Step [900/1563], Loss: 1.0062, Accuracy: 0.6875\n",
      "Epoch [91/100], Step [1000/1563], Loss: 1.0245, Accuracy: 0.6719\n",
      "Epoch [91/100], Step [1100/1563], Loss: 1.1984, Accuracy: 0.6562\n",
      "Epoch [91/100], Step [1200/1563], Loss: 1.5422, Accuracy: 0.5469\n",
      "Epoch [91/100], Step [1300/1563], Loss: 0.9589, Accuracy: 0.7188\n",
      "Epoch [91/100], Step [1400/1563], Loss: 1.0593, Accuracy: 0.6875\n",
      "Epoch [91/100], Step [1500/1563], Loss: 1.0260, Accuracy: 0.6562\n",
      "Epoch [91/100] - Average Loss: 1.1748\n",
      "Epoch [92/100], Step [0/1563], Loss: 0.9580, Accuracy: 0.7344\n",
      "Epoch [92/100], Step [100/1563], Loss: 1.0843, Accuracy: 0.7188\n",
      "Epoch [92/100], Step [200/1563], Loss: 0.7741, Accuracy: 0.7500\n",
      "Epoch [92/100], Step [300/1563], Loss: 0.9831, Accuracy: 0.7500\n",
      "Epoch [92/100], Step [400/1563], Loss: 0.8825, Accuracy: 0.7188\n",
      "Epoch [92/100], Step [500/1563], Loss: 0.9895, Accuracy: 0.7500\n",
      "Epoch [92/100], Step [600/1563], Loss: 1.2182, Accuracy: 0.6719\n",
      "Epoch [92/100], Step [700/1563], Loss: 0.9596, Accuracy: 0.7031\n",
      "Epoch [92/100], Step [800/1563], Loss: 1.3885, Accuracy: 0.5938\n",
      "Epoch [92/100], Step [900/1563], Loss: 1.1311, Accuracy: 0.6719\n",
      "Epoch [92/100], Step [1000/1563], Loss: 1.2560, Accuracy: 0.6250\n",
      "Epoch [92/100], Step [1100/1563], Loss: 1.2128, Accuracy: 0.6094\n",
      "Epoch [92/100], Step [1200/1563], Loss: 1.3128, Accuracy: 0.6094\n",
      "Epoch [92/100], Step [1300/1563], Loss: 1.5812, Accuracy: 0.5781\n",
      "Epoch [92/100], Step [1400/1563], Loss: 1.1546, Accuracy: 0.6250\n",
      "Epoch [92/100], Step [1500/1563], Loss: 1.6497, Accuracy: 0.5625\n",
      "Epoch [92/100] - Average Loss: 1.1606\n",
      "Epoch [93/100], Step [0/1563], Loss: 1.3709, Accuracy: 0.6250\n",
      "Epoch [93/100], Step [100/1563], Loss: 1.3137, Accuracy: 0.6406\n",
      "Epoch [93/100], Step [200/1563], Loss: 0.9333, Accuracy: 0.7188\n",
      "Epoch [93/100], Step [300/1563], Loss: 1.0029, Accuracy: 0.5625\n",
      "Epoch [93/100], Step [400/1563], Loss: 1.2087, Accuracy: 0.7500\n",
      "Epoch [93/100], Step [500/1563], Loss: 1.0606, Accuracy: 0.7188\n",
      "Epoch [93/100], Step [600/1563], Loss: 0.8881, Accuracy: 0.7188\n",
      "Epoch [93/100], Step [700/1563], Loss: 0.8570, Accuracy: 0.7500\n",
      "Epoch [93/100], Step [800/1563], Loss: 1.1263, Accuracy: 0.6250\n",
      "Epoch [93/100], Step [900/1563], Loss: 1.3359, Accuracy: 0.6406\n",
      "Epoch [93/100], Step [1000/1563], Loss: 1.0064, Accuracy: 0.7031\n",
      "Epoch [93/100], Step [1100/1563], Loss: 1.6585, Accuracy: 0.6094\n",
      "Epoch [93/100], Step [1200/1563], Loss: 1.1685, Accuracy: 0.5938\n",
      "Epoch [93/100], Step [1300/1563], Loss: 1.1649, Accuracy: 0.6562\n",
      "Epoch [93/100], Step [1400/1563], Loss: 1.2805, Accuracy: 0.5469\n",
      "Epoch [93/100], Step [1500/1563], Loss: 0.9932, Accuracy: 0.7188\n",
      "Epoch [93/100] - Average Loss: 1.1594\n",
      "Epoch [94/100], Step [0/1563], Loss: 0.8206, Accuracy: 0.7656\n",
      "Epoch [94/100], Step [100/1563], Loss: 1.1180, Accuracy: 0.6562\n",
      "Epoch [94/100], Step [200/1563], Loss: 0.9426, Accuracy: 0.6875\n",
      "Epoch [94/100], Step [300/1563], Loss: 0.8672, Accuracy: 0.7344\n",
      "Epoch [94/100], Step [400/1563], Loss: 0.8915, Accuracy: 0.7031\n",
      "Epoch [94/100], Step [500/1563], Loss: 1.0677, Accuracy: 0.7188\n",
      "Epoch [94/100], Step [600/1563], Loss: 0.8495, Accuracy: 0.7344\n",
      "Epoch [94/100], Step [700/1563], Loss: 0.7219, Accuracy: 0.7812\n",
      "Epoch [94/100], Step [800/1563], Loss: 1.0785, Accuracy: 0.6875\n",
      "Epoch [94/100], Step [900/1563], Loss: 0.9818, Accuracy: 0.7500\n",
      "Epoch [94/100], Step [1000/1563], Loss: 1.1509, Accuracy: 0.6094\n",
      "Epoch [94/100], Step [1100/1563], Loss: 1.3123, Accuracy: 0.6250\n",
      "Epoch [94/100], Step [1200/1563], Loss: 2.3955, Accuracy: 0.5000\n",
      "Epoch [94/100], Step [1300/1563], Loss: 1.0402, Accuracy: 0.7344\n",
      "Epoch [94/100], Step [1400/1563], Loss: 1.3370, Accuracy: 0.5469\n",
      "Epoch [94/100], Step [1500/1563], Loss: 0.9781, Accuracy: 0.7812\n",
      "Epoch [94/100] - Average Loss: 1.1672\n",
      "Epoch [95/100], Step [0/1563], Loss: 0.6945, Accuracy: 0.8281\n",
      "Epoch [95/100], Step [100/1563], Loss: 1.3680, Accuracy: 0.5938\n",
      "Epoch [95/100], Step [200/1563], Loss: 1.2526, Accuracy: 0.6719\n",
      "Epoch [95/100], Step [300/1563], Loss: 1.0562, Accuracy: 0.7344\n",
      "Epoch [95/100], Step [400/1563], Loss: 1.2317, Accuracy: 0.7031\n",
      "Epoch [95/100], Step [500/1563], Loss: 0.8955, Accuracy: 0.7344\n",
      "Epoch [95/100], Step [600/1563], Loss: 1.2992, Accuracy: 0.5938\n",
      "Epoch [95/100], Step [700/1563], Loss: 0.8952, Accuracy: 0.7812\n",
      "Epoch [95/100], Step [800/1563], Loss: 1.2952, Accuracy: 0.6094\n",
      "Epoch [95/100], Step [900/1563], Loss: 1.2056, Accuracy: 0.6094\n",
      "Epoch [95/100], Step [1000/1563], Loss: 1.2791, Accuracy: 0.6406\n",
      "Epoch [95/100], Step [1100/1563], Loss: 1.1935, Accuracy: 0.6094\n",
      "Epoch [95/100], Step [1200/1563], Loss: 1.2419, Accuracy: 0.6094\n",
      "Epoch [95/100], Step [1300/1563], Loss: 1.1677, Accuracy: 0.6250\n",
      "Epoch [95/100], Step [1400/1563], Loss: 1.0066, Accuracy: 0.6719\n",
      "Epoch [95/100], Step [1500/1563], Loss: 1.0961, Accuracy: 0.6875\n",
      "Epoch [95/100] - Average Loss: 1.1486\n",
      "Epoch [96/100], Step [0/1563], Loss: 0.9635, Accuracy: 0.7500\n",
      "Epoch [96/100], Step [100/1563], Loss: 1.0563, Accuracy: 0.6875\n",
      "Epoch [96/100], Step [200/1563], Loss: 1.0919, Accuracy: 0.6406\n",
      "Epoch [96/100], Step [300/1563], Loss: 1.1255, Accuracy: 0.6875\n",
      "Epoch [96/100], Step [400/1563], Loss: 1.1668, Accuracy: 0.6094\n",
      "Epoch [96/100], Step [500/1563], Loss: 0.9996, Accuracy: 0.6719\n",
      "Epoch [96/100], Step [600/1563], Loss: 0.8069, Accuracy: 0.7500\n",
      "Epoch [96/100], Step [700/1563], Loss: 1.1172, Accuracy: 0.6719\n",
      "Epoch [96/100], Step [800/1563], Loss: 0.8627, Accuracy: 0.6719\n",
      "Epoch [96/100], Step [900/1563], Loss: 1.3109, Accuracy: 0.6875\n",
      "Epoch [96/100], Step [1000/1563], Loss: 0.9466, Accuracy: 0.7188\n",
      "Epoch [96/100], Step [1100/1563], Loss: 0.9796, Accuracy: 0.6250\n",
      "Epoch [96/100], Step [1200/1563], Loss: 0.9969, Accuracy: 0.6719\n",
      "Epoch [96/100], Step [1300/1563], Loss: 1.0562, Accuracy: 0.6875\n",
      "Epoch [96/100], Step [1400/1563], Loss: 1.3694, Accuracy: 0.6094\n",
      "Epoch [96/100], Step [1500/1563], Loss: 0.8330, Accuracy: 0.7344\n",
      "Epoch [96/100] - Average Loss: 1.1158\n",
      "Epoch [97/100], Step [0/1563], Loss: 0.9733, Accuracy: 0.7344\n",
      "Epoch [97/100], Step [100/1563], Loss: 0.9306, Accuracy: 0.7188\n",
      "Epoch [97/100], Step [200/1563], Loss: 1.1167, Accuracy: 0.6719\n",
      "Epoch [97/100], Step [300/1563], Loss: 1.2680, Accuracy: 0.6719\n",
      "Epoch [97/100], Step [400/1563], Loss: 1.2620, Accuracy: 0.6562\n",
      "Epoch [97/100], Step [500/1563], Loss: 1.1171, Accuracy: 0.6406\n",
      "Epoch [97/100], Step [600/1563], Loss: 1.0622, Accuracy: 0.6562\n",
      "Epoch [97/100], Step [700/1563], Loss: 1.1570, Accuracy: 0.6719\n",
      "Epoch [97/100], Step [800/1563], Loss: 1.3088, Accuracy: 0.6562\n",
      "Epoch [97/100], Step [900/1563], Loss: 1.0205, Accuracy: 0.6562\n",
      "Epoch [97/100], Step [1000/1563], Loss: 1.0410, Accuracy: 0.6719\n",
      "Epoch [97/100], Step [1100/1563], Loss: 0.7577, Accuracy: 0.7344\n",
      "Epoch [97/100], Step [1200/1563], Loss: 1.1182, Accuracy: 0.6719\n",
      "Epoch [97/100], Step [1300/1563], Loss: 1.0495, Accuracy: 0.7031\n",
      "Epoch [97/100], Step [1400/1563], Loss: 0.9537, Accuracy: 0.6875\n",
      "Epoch [97/100], Step [1500/1563], Loss: 0.9910, Accuracy: 0.7344\n",
      "Epoch [97/100] - Average Loss: 1.1018\n",
      "Epoch [98/100], Step [0/1563], Loss: 0.9546, Accuracy: 0.7500\n",
      "Epoch [98/100], Step [100/1563], Loss: 1.1238, Accuracy: 0.6406\n",
      "Epoch [98/100], Step [200/1563], Loss: 0.9265, Accuracy: 0.7656\n",
      "Epoch [98/100], Step [300/1563], Loss: 0.6569, Accuracy: 0.8594\n",
      "Epoch [98/100], Step [400/1563], Loss: 0.8803, Accuracy: 0.7500\n",
      "Epoch [98/100], Step [500/1563], Loss: 1.5271, Accuracy: 0.5469\n",
      "Epoch [98/100], Step [600/1563], Loss: 1.2276, Accuracy: 0.6406\n",
      "Epoch [98/100], Step [700/1563], Loss: 0.8661, Accuracy: 0.7031\n",
      "Epoch [98/100], Step [800/1563], Loss: 1.3441, Accuracy: 0.6719\n",
      "Epoch [98/100], Step [900/1563], Loss: 0.9597, Accuracy: 0.7031\n",
      "Epoch [98/100], Step [1000/1563], Loss: 0.7644, Accuracy: 0.7656\n",
      "Epoch [98/100], Step [1100/1563], Loss: 1.1916, Accuracy: 0.7031\n",
      "Epoch [98/100], Step [1200/1563], Loss: 1.1400, Accuracy: 0.6719\n",
      "Epoch [98/100], Step [1300/1563], Loss: 0.8342, Accuracy: 0.7500\n",
      "Epoch [98/100], Step [1400/1563], Loss: 1.0614, Accuracy: 0.6719\n",
      "Epoch [98/100], Step [1500/1563], Loss: 1.0201, Accuracy: 0.7031\n",
      "Epoch [98/100] - Average Loss: 1.0857\n",
      "Epoch [99/100], Step [0/1563], Loss: 1.0606, Accuracy: 0.6562\n",
      "Epoch [99/100], Step [100/1563], Loss: 0.6923, Accuracy: 0.7969\n",
      "Epoch [99/100], Step [200/1563], Loss: 1.3796, Accuracy: 0.6094\n",
      "Epoch [99/100], Step [300/1563], Loss: 1.3391, Accuracy: 0.6562\n",
      "Epoch [99/100], Step [400/1563], Loss: 0.7727, Accuracy: 0.7656\n",
      "Epoch [99/100], Step [500/1563], Loss: 0.9781, Accuracy: 0.7188\n",
      "Epoch [99/100], Step [600/1563], Loss: 1.2830, Accuracy: 0.7188\n",
      "Epoch [99/100], Step [700/1563], Loss: 0.9716, Accuracy: 0.7656\n",
      "Epoch [99/100], Step [800/1563], Loss: 1.0156, Accuracy: 0.6875\n",
      "Epoch [99/100], Step [900/1563], Loss: 1.3156, Accuracy: 0.5000\n",
      "Epoch [99/100], Step [1000/1563], Loss: 1.3478, Accuracy: 0.5625\n",
      "Epoch [99/100], Step [1100/1563], Loss: 1.2762, Accuracy: 0.6875\n",
      "Epoch [99/100], Step [1200/1563], Loss: 0.9656, Accuracy: 0.7188\n",
      "Epoch [99/100], Step [1300/1563], Loss: 1.5160, Accuracy: 0.5312\n",
      "Epoch [99/100], Step [1400/1563], Loss: 1.4260, Accuracy: 0.6094\n",
      "Epoch [99/100], Step [1500/1563], Loss: 0.9019, Accuracy: 0.7656\n",
      "Epoch [99/100] - Average Loss: 1.0820\n",
      "Epoch [100/100], Step [0/1563], Loss: 1.3050, Accuracy: 0.6562\n",
      "Epoch [100/100], Step [100/1563], Loss: 0.4620, Accuracy: 0.8438\n",
      "Epoch [100/100], Step [200/1563], Loss: 1.1055, Accuracy: 0.6562\n",
      "Epoch [100/100], Step [300/1563], Loss: 0.9884, Accuracy: 0.6719\n",
      "Epoch [100/100], Step [400/1563], Loss: 1.1169, Accuracy: 0.5938\n",
      "Epoch [100/100], Step [500/1563], Loss: 1.1354, Accuracy: 0.6719\n",
      "Epoch [100/100], Step [600/1563], Loss: 0.9047, Accuracy: 0.7188\n",
      "Epoch [100/100], Step [700/1563], Loss: 1.0529, Accuracy: 0.6875\n",
      "Epoch [100/100], Step [800/1563], Loss: 1.1930, Accuracy: 0.6094\n",
      "Epoch [100/100], Step [900/1563], Loss: 0.9347, Accuracy: 0.7031\n",
      "Epoch [100/100], Step [1000/1563], Loss: 1.2322, Accuracy: 0.6406\n",
      "Epoch [100/100], Step [1100/1563], Loss: 1.0493, Accuracy: 0.7344\n",
      "Epoch [100/100], Step [1200/1563], Loss: 1.0495, Accuracy: 0.6719\n",
      "Epoch [100/100], Step [1300/1563], Loss: 1.0693, Accuracy: 0.6562\n",
      "Epoch [100/100], Step [1400/1563], Loss: 1.3612, Accuracy: 0.6250\n",
      "Epoch [100/100], Step [1500/1563], Loss: 1.5005, Accuracy: 0.5781\n",
      "Epoch [100/100] - Average Loss: 1.0865\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# model = SimpleCnn().to(device)\n",
    "model = mobilenet_v3_small().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    trainLoss = 0.0\n",
    "    trainAcc = 0.0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainLoader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        trainLoss += loss.item()\n",
    "        trainAcc += acc.item()\n",
    "\n",
    "        # Print every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{n_epochs}], Step [{batch_idx}/{len(trainLoader)}], Loss: {loss.item():.4f}, Accuracy: {acc.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{n_epochs}] - Average Loss: {trainLoss / len(trainLoader):.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
